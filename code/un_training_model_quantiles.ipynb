{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, math, gc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import pickle as pkl\n",
    "from utils.utils import merge_eval_sold_on_df, sort_df_on_d, WRMSSE, RMSSE, _down_cast, data_preprocessing, diff_lists, log_status\n",
    "from utils.utils import customIter, cross_validation_on_validation_set, ensemble_submissions, ensemble_submissions_uncertainty\n",
    "from utils.metrics import WSPL\n",
    "from utils.configure_logger import configure_logger\n",
    "from utils import constants\n",
    "\n",
    "configure_logger()\n",
    "from logging import getLogger\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_PATH = constants.DATA_BASE_PATH #'../data/m5-forecasting-accuracy/'\n",
    "DATA_BASE_PATH_UNCERTAINTY = constants.DATA_BASE_PATH_UNCERTAINTY #'../data/m5-forecasting-uncertainty/'\n",
    "SALES_EVALUATION = constants.SALES_EVALUATION #'sales_train_evaluation.csv'\n",
    "SALES_VALIDATION = constants.SALES_VALIDATION #'sales_train_validation.csv'\n",
    "CALENDAR = constants.CALENDAR #'calendar.csv'\n",
    "SAMPLE_SUBMISSION = constants.SAMPLE_SUBMISSION #'sample_submission.csv'\n",
    "SELL_PRICES = constants.SELL_PRICES #'sell_prices.csv'\n",
    "\n",
    "PRECOMPUTED_BASE_PATH = constants.PRECOMPUTED_BASE_PATH #'../data/uncertainty/features/'\n",
    "\n",
    "DAYS: int = constants.DAYS #28\n",
    "QUANTILES: int = constants.QUANTILES #[0.005, 0.025, 0.165, 0.25, 0.50, 0.75, 0.835, 0.975, 0.995]\n",
    "\n",
    "AGG_LEVEL_COLUMNS = constants.AGG_LEVEL_COLUMNS\n",
    "D_CROSS_VAL_START_LIST = constants.D_CROSS_VAL_START_LIST #[1802, 1830, 1858, 1886, 1914]\n",
    "\n",
    "# to simple get the precomputed name\n",
    "precomputed_name = lambda store, eval_val: f'processed_{store}_{eval_val}.pkl'\n",
    "\n",
    "TEST_PATH = constants.TEST_PATH#'test/'\n",
    "PREDICTION_BASE_PATH = constants.PREDICTION_BASE_PATH #'../data/uncertainty/temp_submissions/'\n",
    "SUBMISSION_BASE_PATH = constants.SUBMISSION_BASE_PATH #'../data/uncertainty/final_submissions/'\n",
    "\n",
    "SUB_D_START_VAL: int = constants.SUB_D_START_VAL #1914\n",
    "SUB_D_START_EVAL: int = constants.SUB_D_START_EVAL #1914 + 28\n",
    "\n",
    "# the columns are always included after feature processing\n",
    "# because they are required in the training and submission format\n",
    "DROP_FEATURE_COLUMNS: list = constants.DROP_FEATURE_COLUMNS #['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'd', 'sold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GridSearch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_status\n",
    "def grid_search(params: dict, param_grid: dict, features, targets, n_folds: int = 1):\n",
    "    \"\"\" \n",
    "    Given a grid with parameters, train lgb model for all possible combinations.\n",
    "    Returns the parameter set with the best score and the dictionary with all results.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    # to be sure\n",
    "    features = features.reset_index(drop=True)\n",
    "    targets = targets.reset_index(drop=True)\n",
    "\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "    results = {}\n",
    "    for i, param_combination in enumerate(param_combinations,1):\n",
    "        \n",
    "        # create dictionary with all parameters\n",
    "        param_combination = {k:v for k,v in zip(param_grid.keys(), param_combination)}\n",
    "        param_combination.update(params)\n",
    "        \n",
    "        # init dict\n",
    "        results[f\"combination_{i}\"] = {\n",
    "            'params': param_combination,\n",
    "            'res': []\n",
    "        }\n",
    "        \n",
    "        # perform n_folds\n",
    "        # from sklearn.model_selection import KFold\n",
    "        # kfold = KFold(n_splits=n_folds)\n",
    "        # for j, (train_idx, validation_idx) in enumerate(kfold.split(features)):\n",
    "        \n",
    "        for j in range(n_folds):\n",
    "            \n",
    "            # kfold\n",
    "            features_train, features_validation, targets_train, targets_validation =\\\n",
    "                train_test_split(features, targets, train_size = .8, shuffle=True, random_state=42)\n",
    "        \n",
    "            # # split data for fold\n",
    "            # features_train, features_validation = features.loc[train_idx], features.loc[validation_idx]\n",
    "            # targets_train, targets_validation = targets.loc[train_idx], targets.loc[validation_idx]\n",
    "\n",
    "            # normalize\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            \n",
    "            targets_train = scaler\\\n",
    "                .fit_transform(targets_train.values.reshape(-1,1))\\\n",
    "                .reshape(-1)\n",
    "            targets_validation = scaler\\\n",
    "                .transform(targets_validation.values.reshape(-1,1))\\\n",
    "                .reshape(-1)\n",
    "\n",
    "            # train lgb model        \n",
    "            temp_dict = {} # this dict object will be used to add all (intermediate) evaluation scores during the training process\n",
    "            mod: lgb.Booster = lgb.train(param_combination, \n",
    "                train_set = lgb.Dataset(features_train, targets_train),\n",
    "                valid_sets = lgb.Dataset(features_validation, targets_validation),\n",
    "                evals_result = temp_dict\n",
    "            )\n",
    "            \n",
    "            # store results\n",
    "            results[f\"combination_{i}\"]['res']\\\n",
    "                .append(temp_dict[\"valid_0\"][\"quantile\"][-1],\n",
    "            )\n",
    "\n",
    "        # compute average results\n",
    "        results[f\"combination_{i}\"]['validation_score'] = \\\n",
    "            np.mean(results[f\"combination_{i}\"]['res'])\n",
    "        \n",
    "    # sort the results based on evaluation score\n",
    "    sorted_results = dict(sorted(results.items(), key=lambda item: item[1][\"validation_score\"]))\n",
    "    return list(sorted_results.values())[-1], results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData:\n",
    "    def __init__(self):\n",
    "        self.level = None\n",
    "        \n",
    "    def prep_data(self,level):\n",
    "        \"\"\" read the precomputed features and targets for specified aggregation level,  \"\"\"\n",
    "        # define params\n",
    "        agg_level = level\n",
    "        sub_d_start: int = int(1886)\n",
    "        exclude_columns = []\n",
    "        test = False\n",
    "        type_of = 'val'\n",
    "\n",
    "        # read file\n",
    "        agg_columns = AGG_LEVEL_COLUMNS[agg_level]\n",
    "        if len(agg_columns) == 0:\n",
    "            agg_str: str = 'Total_X'\n",
    "        elif len(agg_columns) == 1:\n",
    "            agg_str: str = f'{agg_columns[0]}_X'\n",
    "        else:\n",
    "            agg_str: str = '_'.join(agg_columns)\n",
    "\n",
    "        if self.level == level:\n",
    "            pass\n",
    "        else:\n",
    "            logger.info('(re)loading features')\n",
    "            features = pd.read_parquet(f'../data/uncertainty/fold_{sub_d_start}/features/' + (TEST_PATH if test else '') + f'features_{type_of}_{agg_str}.parquet')\n",
    "            features = _down_cast(features)\n",
    "\n",
    "        group_columns = agg_columns\n",
    "        exclude_prefix_list = exclude_columns # unconditional, auto, momentum, seasonal\n",
    "\n",
    "        features_gr = features.copy()\n",
    "        features_gr = features_gr[[c for c in features_gr if c.split('_')[0] not in exclude_prefix_list]]\n",
    "\n",
    "        # preparations\n",
    "        train_idx = features_gr['sold'].notna() & features_gr['d'].isin([f'd_{sub_d_start - 1 - i}' for i in range(1460)])\n",
    "        df_train = features_gr[train_idx]\n",
    "        features_train: pd.DataFrame = df_train.drop(DROP_FEATURE_COLUMNS, axis = 1, errors = 'ignore')\n",
    "        targets_train: pd.Series = df_train['sold']\n",
    "        return features_train, targets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:29:01 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto_sold_7</th>\n",
       "      <th>auto_sold_14</th>\n",
       "      <th>auto_sold_2</th>\n",
       "      <th>auto_sold_1</th>\n",
       "      <th>auto_sold_21</th>\n",
       "      <th>auto_sold_ma_180</th>\n",
       "      <th>auto_sold_ma_60</th>\n",
       "      <th>auto_sold_ma_28</th>\n",
       "      <th>auto_sold_ma_std_7</th>\n",
       "      <th>auto_sold_ma_std_60</th>\n",
       "      <th>...</th>\n",
       "      <th>seasonal_3</th>\n",
       "      <th>seasonal_9</th>\n",
       "      <th>seasonal_2</th>\n",
       "      <th>seasonal_5</th>\n",
       "      <th>seasonal_Monday</th>\n",
       "      <th>seasonal_Wednesday</th>\n",
       "      <th>seasonal_Tuesday</th>\n",
       "      <th>seasonal_12</th>\n",
       "      <th>seasonal_Saturday</th>\n",
       "      <th>seasonal_d_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13337</th>\n",
       "      <td>1247.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1567.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>342.50</td>\n",
       "      <td>280.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13338</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>346.75</td>\n",
       "      <td>282.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13339</th>\n",
       "      <td>1272.0</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>352.50</td>\n",
       "      <td>285.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13340</th>\n",
       "      <td>1511.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>1832.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>358.00</td>\n",
       "      <td>280.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13341</th>\n",
       "      <td>1887.0</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>1904.0</td>\n",
       "      <td>1567.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>291.00</td>\n",
       "      <td>278.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10220 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       auto_sold_7  auto_sold_14  auto_sold_2  auto_sold_1  auto_sold_21  \\\n",
       "2              NaN           NaN          NaN          NaN           NaN   \n",
       "3              NaN           NaN          NaN          NaN           NaN   \n",
       "4              NaN           NaN          NaN          NaN           NaN   \n",
       "5              NaN           NaN          NaN          NaN           NaN   \n",
       "6              NaN           NaN          NaN          NaN           NaN   \n",
       "...            ...           ...          ...          ...           ...   \n",
       "13337       1247.0        1280.0       1963.0       1192.0        1260.0   \n",
       "13338       1257.0        1304.0       1192.0       1117.0        1309.0   \n",
       "13339       1272.0        1431.0       1117.0       1217.0        1412.0   \n",
       "13340       1511.0        1171.0       1217.0       1213.0        1832.0   \n",
       "13341       1887.0        1812.0       1213.0       1246.0        1904.0   \n",
       "\n",
       "       auto_sold_ma_180  auto_sold_ma_60  auto_sold_ma_28  auto_sold_ma_std_7  \\\n",
       "2                   NaN              NaN              NaN                 NaN   \n",
       "3                   NaN              NaN              NaN                 NaN   \n",
       "4                   NaN              NaN              NaN                 NaN   \n",
       "5                   NaN              NaN              NaN                 NaN   \n",
       "6                   NaN              NaN              NaN                 NaN   \n",
       "...                 ...              ...              ...                 ...   \n",
       "13337            1567.0           1535.0           1496.0              342.50   \n",
       "13338            1566.0           1528.0           1484.0              346.75   \n",
       "13339            1565.0           1521.0           1456.0              352.50   \n",
       "13340            1566.0           1509.0           1435.0              358.00   \n",
       "13341            1567.0           1503.0           1420.0              291.00   \n",
       "\n",
       "       auto_sold_ma_std_60  ...  seasonal_3  seasonal_9  seasonal_2  \\\n",
       "2                      NaN  ...         0.0         0.0         0.0   \n",
       "3                      NaN  ...         0.0         0.0         0.0   \n",
       "4                      NaN  ...         0.0         0.0         0.0   \n",
       "5                      NaN  ...         0.0         0.0         0.0   \n",
       "6                      NaN  ...         0.0         0.0         0.0   \n",
       "...                    ...  ...         ...         ...         ...   \n",
       "13337               280.00  ...         0.0         0.0         0.0   \n",
       "13338               282.50  ...         0.0         0.0         0.0   \n",
       "13339               285.00  ...         0.0         0.0         0.0   \n",
       "13340               280.50  ...         0.0         0.0         0.0   \n",
       "13341               278.25  ...         0.0         0.0         0.0   \n",
       "\n",
       "       seasonal_5  seasonal_Monday  seasonal_Wednesday  seasonal_Tuesday  \\\n",
       "2             0.0              0.0                 0.0               0.0   \n",
       "3             0.0              0.0                 0.0               0.0   \n",
       "4             0.0              0.0                 0.0               0.0   \n",
       "5             0.0              0.0                 0.0               0.0   \n",
       "6             0.0              1.0                 0.0               0.0   \n",
       "...           ...              ...                 ...               ...   \n",
       "13337         0.0              0.0                 0.0               0.0   \n",
       "13338         0.0              0.0                 0.0               0.0   \n",
       "13339         0.0              1.0                 0.0               0.0   \n",
       "13340         0.0              0.0                 0.0               1.0   \n",
       "13341         0.0              0.0                 1.0               0.0   \n",
       "\n",
       "       seasonal_12  seasonal_Saturday  seasonal_d_int  \n",
       "2              0.0                0.0          1000.0  \n",
       "3              0.0                0.0          1001.0  \n",
       "4              0.0                1.0          1002.0  \n",
       "5              0.0                0.0          1003.0  \n",
       "6              0.0                0.0          1004.0  \n",
       "...            ...                ...             ...  \n",
       "13337          0.0                1.0           995.0  \n",
       "13338          0.0                0.0           996.0  \n",
       "13339          0.0                0.0           997.0  \n",
       "13340          0.0                0.0           998.0  \n",
       "13341          0.0                0.0           999.0  \n",
       "\n",
       "[10220 rows x 63 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level = 'Level5'\n",
    "q = .025\n",
    "n_est = 50 # 200\n",
    "lr = .1 #.2\n",
    "\n",
    "def prefixes_in_column(column, prefixes):\n",
    "    s = 0\n",
    "    for prefix in prefixes:\n",
    "        s += prefix_in_column(column, prefix)\n",
    "    return True if s>0 else False\n",
    "\n",
    "def prefix_in_column(column, prefix):\n",
    "    return 1 if prefix in column else 0\n",
    "\n",
    "dataLoader = LoadData()\n",
    "features, targets = dataLoader.prep_data(level)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autoquantiles_sold_ma_180_0.25</th>\n",
       "      <th>autoquantiles_sold_ma_180_0.995</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.995</th>\n",
       "      <th>autoquantiles_sold_ma_180_0.005</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.025</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.75</th>\n",
       "      <th>autoquantiles_sold_ma_180_0.75</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.995</th>\n",
       "      <th>autoquantiles_sold_ma_180_0.975</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.005</th>\n",
       "      <th>...</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.5</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.025</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.165</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.5</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.25</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.25</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.975</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.005</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.835</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.835</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13337</th>\n",
       "      <td>1357.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>1872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13338</th>\n",
       "      <td>1357.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>1872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13339</th>\n",
       "      <td>1355.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>1872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13340</th>\n",
       "      <td>1355.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>1842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13341</th>\n",
       "      <td>1357.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>1842.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10220 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       autoquantiles_sold_ma_180_0.25  autoquantiles_sold_ma_180_0.995  \\\n",
       "2                                 NaN                              NaN   \n",
       "3                                 NaN                              NaN   \n",
       "4                                 NaN                              NaN   \n",
       "5                                 NaN                              NaN   \n",
       "6                                 NaN                              NaN   \n",
       "...                               ...                              ...   \n",
       "13337                          1357.0                           2194.0   \n",
       "13338                          1357.0                           2194.0   \n",
       "13339                          1355.0                           2194.0   \n",
       "13340                          1355.0                           2194.0   \n",
       "13341                          1357.0                           2194.0   \n",
       "\n",
       "       autoquantiles_sold_ma_60_0.995  autoquantiles_sold_ma_180_0.005  \\\n",
       "2                                 NaN                              NaN   \n",
       "3                                 NaN                              NaN   \n",
       "4                                 NaN                              NaN   \n",
       "5                                 NaN                              NaN   \n",
       "6                                 NaN                              NaN   \n",
       "...                               ...                              ...   \n",
       "13337                          2084.0                           1075.0   \n",
       "13338                          2084.0                           1075.0   \n",
       "13339                          2084.0                           1075.0   \n",
       "13340                          2084.0                           1078.0   \n",
       "13341                          2084.0                           1078.0   \n",
       "\n",
       "       autoquantiles_sold_ma_30_0.025  autoquantiles_sold_ma_30_0.75  \\\n",
       "2                                 NaN                            NaN   \n",
       "3                                 NaN                            NaN   \n",
       "4                                 NaN                            NaN   \n",
       "5                                 NaN                            NaN   \n",
       "6                                 NaN                            NaN   \n",
       "...                               ...                            ...   \n",
       "13337                          1156.0                         1827.0   \n",
       "13338                          1156.0                         1827.0   \n",
       "13339                          1156.0                         1827.0   \n",
       "13340                          1156.0                         1827.0   \n",
       "13341                          1156.0                         1737.0   \n",
       "\n",
       "       autoquantiles_sold_ma_180_0.75  autoquantiles_sold_ma_30_0.995  \\\n",
       "2                                 NaN                             NaN   \n",
       "3                                 NaN                             NaN   \n",
       "4                                 NaN                             NaN   \n",
       "5                                 NaN                             NaN   \n",
       "6                                 NaN                             NaN   \n",
       "...                               ...                             ...   \n",
       "13337                          1760.0                          2013.0   \n",
       "13338                          1760.0                          2013.0   \n",
       "13339                          1760.0                          2013.0   \n",
       "13340                          1760.0                          2013.0   \n",
       "13341                          1760.0                          2011.0   \n",
       "\n",
       "       autoquantiles_sold_ma_180_0.975  autoquantiles_sold_ma_60_0.005  ...  \\\n",
       "2                                  NaN                             NaN  ...   \n",
       "3                                  NaN                             NaN  ...   \n",
       "4                                  NaN                             NaN  ...   \n",
       "5                                  NaN                             NaN  ...   \n",
       "6                                  NaN                             NaN  ...   \n",
       "...                                ...                             ...  ...   \n",
       "13337                           2096.0                          1133.0  ...   \n",
       "13338                           2096.0                          1133.0  ...   \n",
       "13339                           2096.0                          1133.0  ...   \n",
       "13340                           2096.0                          1133.0  ...   \n",
       "13341                           2096.0                          1133.0  ...   \n",
       "\n",
       "       autoquantiles_sold_ma_60_0.5  autoquantiles_sold_ma_60_0.025  \\\n",
       "2                               NaN                             NaN   \n",
       "3                               NaN                             NaN   \n",
       "4                               NaN                             NaN   \n",
       "5                               NaN                             NaN   \n",
       "6                               NaN                             NaN   \n",
       "...                             ...                             ...   \n",
       "13337                        1458.0                          1181.0   \n",
       "13338                        1442.0                          1181.0   \n",
       "13339                        1430.0                          1181.0   \n",
       "13340                        1420.0                          1181.0   \n",
       "13341                        1420.0                          1181.0   \n",
       "\n",
       "       autoquantiles_sold_ma_60_0.165  autoquantiles_sold_ma_30_0.5  \\\n",
       "2                                 NaN                           NaN   \n",
       "3                                 NaN                           NaN   \n",
       "4                                 NaN                           NaN   \n",
       "5                                 NaN                           NaN   \n",
       "6                                 NaN                           NaN   \n",
       "...                               ...                           ...   \n",
       "13337                          1262.0                        1319.0   \n",
       "13338                          1259.0                        1319.0   \n",
       "13339                          1256.0                        1307.0   \n",
       "13340                          1252.0                        1304.0   \n",
       "13341                          1252.0                        1304.0   \n",
       "\n",
       "       autoquantiles_sold_ma_60_0.25  autoquantiles_sold_ma_30_0.25  \\\n",
       "2                                NaN                            NaN   \n",
       "3                                NaN                            NaN   \n",
       "4                                NaN                            NaN   \n",
       "5                                NaN                            NaN   \n",
       "6                                NaN                            NaN   \n",
       "...                              ...                            ...   \n",
       "13337                         1296.0                         1263.0   \n",
       "13338                         1279.0                         1263.0   \n",
       "13339                         1276.0                         1258.0   \n",
       "13340                         1270.0                         1250.0   \n",
       "13341                         1270.0                         1250.0   \n",
       "\n",
       "       autoquantiles_sold_ma_60_0.975  autoquantiles_sold_ma_30_0.005  \\\n",
       "2                                 NaN                             NaN   \n",
       "3                                 NaN                             NaN   \n",
       "4                                 NaN                             NaN   \n",
       "5                                 NaN                             NaN   \n",
       "6                                 NaN                             NaN   \n",
       "...                               ...                             ...   \n",
       "13337                          2042.0                          1125.0   \n",
       "13338                          2042.0                          1125.0   \n",
       "13339                          2042.0                          1125.0   \n",
       "13340                          2042.0                          1125.0   \n",
       "13341                          2042.0                          1125.0   \n",
       "\n",
       "       autoquantiles_sold_ma_30_0.835  autoquantiles_sold_ma_60_0.835  \n",
       "2                                 NaN                             NaN  \n",
       "3                                 NaN                             NaN  \n",
       "4                                 NaN                             NaN  \n",
       "5                                 NaN                             NaN  \n",
       "6                                 NaN                             NaN  \n",
       "...                               ...                             ...  \n",
       "13337                          1871.0                          1872.0  \n",
       "13338                          1871.0                          1872.0  \n",
       "13339                          1871.0                          1872.0  \n",
       "13340                          1871.0                          1842.0  \n",
       "13341                          1840.0                          1842.0  \n",
       "\n",
       "[10220 rows x 27 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixes = ['autoquantiles_']\n",
    "features[[c for c in features.columns if prefixes_in_column(c, prefixes)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[1]\tvalid_0's quantile: 130.123\n",
      "[2]\tvalid_0's quantile: 130.123\n",
      "[3]\tvalid_0's quantile: 130.123\n",
      "[4]\tvalid_0's quantile: 130.123\n",
      "[5]\tvalid_0's quantile: 130.123\n",
      "[6]\tvalid_0's quantile: 130.123\n",
      "[7]\tvalid_0's quantile: 130.123\n",
      "[8]\tvalid_0's quantile: 130.122\n",
      "[9]\tvalid_0's quantile: 130.122\n",
      "[10]\tvalid_0's quantile: 130.122\n",
      "[11]\tvalid_0's quantile: 130.122\n",
      "[12]\tvalid_0's quantile: 130.122\n",
      "[13]\tvalid_0's quantile: 130.122\n",
      "[14]\tvalid_0's quantile: 130.121\n",
      "[15]\tvalid_0's quantile: 130.121\n",
      "[16]\tvalid_0's quantile: 130.121\n",
      "[17]\tvalid_0's quantile: 130.121\n",
      "[18]\tvalid_0's quantile: 130.121\n",
      "[19]\tvalid_0's quantile: 130.121\n",
      "[20]\tvalid_0's quantile: 130.121\n",
      "[21]\tvalid_0's quantile: 130.12\n",
      "[22]\tvalid_0's quantile: 130.119\n",
      "[23]\tvalid_0's quantile: 130.119\n",
      "[24]\tvalid_0's quantile: 130.119\n",
      "[25]\tvalid_0's quantile: 130.119\n",
      "[26]\tvalid_0's quantile: 130.119\n",
      "[27]\tvalid_0's quantile: 130.118\n",
      "[28]\tvalid_0's quantile: 130.117\n",
      "[29]\tvalid_0's quantile: 130.116\n",
      "[30]\tvalid_0's quantile: 130.116\n",
      "[31]\tvalid_0's quantile: 130.115\n",
      "[32]\tvalid_0's quantile: 130.115\n",
      "[33]\tvalid_0's quantile: 130.115\n",
      "[34]\tvalid_0's quantile: 130.115\n",
      "[35]\tvalid_0's quantile: 130.114\n",
      "[36]\tvalid_0's quantile: 130.114\n",
      "[37]\tvalid_0's quantile: 130.113\n",
      "[38]\tvalid_0's quantile: 130.113\n",
      "[39]\tvalid_0's quantile: 130.113\n",
      "[40]\tvalid_0's quantile: 130.113\n",
      "[41]\tvalid_0's quantile: 130.112\n",
      "[42]\tvalid_0's quantile: 130.111\n",
      "[43]\tvalid_0's quantile: 130.109\n",
      "[44]\tvalid_0's quantile: 130.109\n",
      "[45]\tvalid_0's quantile: 130.108\n",
      "[46]\tvalid_0's quantile: 130.108\n",
      "[47]\tvalid_0's quantile: 130.108\n",
      "[48]\tvalid_0's quantile: 130.107\n",
      "[49]\tvalid_0's quantile: 130.107\n",
      "[50]\tvalid_0's quantile: 130.106\n",
      "[51]\tvalid_0's quantile: 130.104\n",
      "[52]\tvalid_0's quantile: 130.103\n",
      "[53]\tvalid_0's quantile: 130.102\n",
      "[54]\tvalid_0's quantile: 130.102\n",
      "[55]\tvalid_0's quantile: 130.102\n",
      "[56]\tvalid_0's quantile: 130.101\n",
      "[57]\tvalid_0's quantile: 130.099\n",
      "[58]\tvalid_0's quantile: 130.099\n",
      "[59]\tvalid_0's quantile: 130.098\n",
      "[60]\tvalid_0's quantile: 130.096\n",
      "[61]\tvalid_0's quantile: 130.096\n",
      "[62]\tvalid_0's quantile: 130.095\n",
      "[63]\tvalid_0's quantile: 130.093\n",
      "[64]\tvalid_0's quantile: 130.091\n",
      "[65]\tvalid_0's quantile: 130.091\n",
      "[66]\tvalid_0's quantile: 130.09\n",
      "[67]\tvalid_0's quantile: 130.088\n",
      "[68]\tvalid_0's quantile: 130.086\n",
      "[69]\tvalid_0's quantile: 130.084\n",
      "[70]\tvalid_0's quantile: 130.084\n",
      "[71]\tvalid_0's quantile: 130.083\n",
      "[72]\tvalid_0's quantile: 130.081\n",
      "[73]\tvalid_0's quantile: 130.079\n",
      "[74]\tvalid_0's quantile: 130.079\n",
      "[75]\tvalid_0's quantile: 130.079\n",
      "[76]\tvalid_0's quantile: 130.076\n",
      "[77]\tvalid_0's quantile: 130.074\n",
      "[78]\tvalid_0's quantile: 130.074\n",
      "[79]\tvalid_0's quantile: 130.072\n",
      "[80]\tvalid_0's quantile: 130.07\n",
      "[81]\tvalid_0's quantile: 130.07\n",
      "[82]\tvalid_0's quantile: 130.068\n",
      "[83]\tvalid_0's quantile: 130.068\n",
      "[84]\tvalid_0's quantile: 130.068\n",
      "[85]\tvalid_0's quantile: 130.068\n",
      "[86]\tvalid_0's quantile: 130.065\n",
      "[87]\tvalid_0's quantile: 130.063\n",
      "[88]\tvalid_0's quantile: 130.063\n",
      "[89]\tvalid_0's quantile: 130.061\n",
      "[90]\tvalid_0's quantile: 130.058\n",
      "[91]\tvalid_0's quantile: 130.058\n",
      "[92]\tvalid_0's quantile: 130.058\n",
      "[93]\tvalid_0's quantile: 130.056\n",
      "[94]\tvalid_0's quantile: 130.056\n",
      "[95]\tvalid_0's quantile: 130.054\n",
      "[96]\tvalid_0's quantile: 130.051\n",
      "[97]\tvalid_0's quantile: 130.048\n",
      "[98]\tvalid_0's quantile: 130.046\n",
      "[99]\tvalid_0's quantile: 130.046\n",
      "[100]\tvalid_0's quantile: 130.046\n",
      "[101]\tvalid_0's quantile: 130.046\n",
      "[102]\tvalid_0's quantile: 130.046\n",
      "[103]\tvalid_0's quantile: 130.043\n",
      "[104]\tvalid_0's quantile: 130.042\n",
      "[105]\tvalid_0's quantile: 130.042\n",
      "[106]\tvalid_0's quantile: 130.039\n",
      "[107]\tvalid_0's quantile: 130.039\n",
      "[108]\tvalid_0's quantile: 130.039\n",
      "[109]\tvalid_0's quantile: 130.036\n",
      "[110]\tvalid_0's quantile: 130.036\n",
      "[111]\tvalid_0's quantile: 130.036\n",
      "[112]\tvalid_0's quantile: 130.036\n",
      "[113]\tvalid_0's quantile: 130.033\n",
      "[114]\tvalid_0's quantile: 130.033\n",
      "[115]\tvalid_0's quantile: 130.033\n",
      "[116]\tvalid_0's quantile: 130.033\n",
      "[117]\tvalid_0's quantile: 130.031\n",
      "[118]\tvalid_0's quantile: 130.028\n",
      "[119]\tvalid_0's quantile: 130.028\n",
      "[120]\tvalid_0's quantile: 130.028\n",
      "[121]\tvalid_0's quantile: 130.025\n",
      "[122]\tvalid_0's quantile: 130.021\n",
      "[123]\tvalid_0's quantile: 130.021\n",
      "[124]\tvalid_0's quantile: 130.021\n",
      "[125]\tvalid_0's quantile: 130.018\n",
      "[126]\tvalid_0's quantile: 130.015\n",
      "[127]\tvalid_0's quantile: 130.012\n",
      "[128]\tvalid_0's quantile: 130.008\n",
      "[129]\tvalid_0's quantile: 130.008\n",
      "[130]\tvalid_0's quantile: 130.008\n",
      "[131]\tvalid_0's quantile: 130.005\n",
      "[132]\tvalid_0's quantile: 130.002\n",
      "[133]\tvalid_0's quantile: 130.002\n",
      "[134]\tvalid_0's quantile: 129.998\n",
      "[135]\tvalid_0's quantile: 129.995\n",
      "[136]\tvalid_0's quantile: 129.995\n",
      "[137]\tvalid_0's quantile: 129.995\n",
      "[138]\tvalid_0's quantile: 129.995\n",
      "[139]\tvalid_0's quantile: 129.992\n",
      "[140]\tvalid_0's quantile: 129.988\n",
      "[141]\tvalid_0's quantile: 129.988\n",
      "[142]\tvalid_0's quantile: 129.988\n",
      "[143]\tvalid_0's quantile: 129.988\n",
      "[144]\tvalid_0's quantile: 129.988\n",
      "[145]\tvalid_0's quantile: 129.988\n",
      "[146]\tvalid_0's quantile: 129.984\n",
      "[147]\tvalid_0's quantile: 129.984\n",
      "[148]\tvalid_0's quantile: 129.981\n",
      "[149]\tvalid_0's quantile: 129.978\n",
      "[150]\tvalid_0's quantile: 129.974\n",
      "[151]\tvalid_0's quantile: 129.971\n",
      "[152]\tvalid_0's quantile: 129.971\n",
      "[153]\tvalid_0's quantile: 129.967\n",
      "[154]\tvalid_0's quantile: 129.963\n",
      "[155]\tvalid_0's quantile: 129.959\n",
      "[156]\tvalid_0's quantile: 129.954\n",
      "[157]\tvalid_0's quantile: 129.954\n",
      "[158]\tvalid_0's quantile: 129.95\n",
      "[159]\tvalid_0's quantile: 129.95\n",
      "[160]\tvalid_0's quantile: 129.946\n",
      "[161]\tvalid_0's quantile: 129.946\n",
      "[162]\tvalid_0's quantile: 129.942\n",
      "[163]\tvalid_0's quantile: 129.941\n",
      "[164]\tvalid_0's quantile: 129.937\n",
      "[165]\tvalid_0's quantile: 129.937\n",
      "[166]\tvalid_0's quantile: 129.932\n",
      "[167]\tvalid_0's quantile: 129.929\n",
      "[168]\tvalid_0's quantile: 129.924\n",
      "[169]\tvalid_0's quantile: 129.92\n",
      "[170]\tvalid_0's quantile: 129.916\n",
      "[171]\tvalid_0's quantile: 129.912\n",
      "[172]\tvalid_0's quantile: 129.907\n",
      "[173]\tvalid_0's quantile: 129.903\n",
      "[174]\tvalid_0's quantile: 129.903\n",
      "[175]\tvalid_0's quantile: 129.898\n",
      "[176]\tvalid_0's quantile: 129.894\n",
      "[177]\tvalid_0's quantile: 129.889\n",
      "[178]\tvalid_0's quantile: 129.885\n",
      "[179]\tvalid_0's quantile: 129.885\n",
      "[180]\tvalid_0's quantile: 129.885\n",
      "[181]\tvalid_0's quantile: 129.88\n",
      "[182]\tvalid_0's quantile: 129.88\n",
      "[183]\tvalid_0's quantile: 129.88\n",
      "[184]\tvalid_0's quantile: 129.876\n",
      "[185]\tvalid_0's quantile: 129.876\n",
      "[186]\tvalid_0's quantile: 129.871\n",
      "[187]\tvalid_0's quantile: 129.871\n",
      "[188]\tvalid_0's quantile: 129.866\n",
      "[189]\tvalid_0's quantile: 129.862\n",
      "[190]\tvalid_0's quantile: 129.862\n",
      "[191]\tvalid_0's quantile: 129.856\n",
      "[192]\tvalid_0's quantile: 129.856\n",
      "[193]\tvalid_0's quantile: 129.852\n",
      "[194]\tvalid_0's quantile: 129.852\n",
      "[195]\tvalid_0's quantile: 129.847\n",
      "[196]\tvalid_0's quantile: 129.847\n",
      "[197]\tvalid_0's quantile: 129.847\n",
      "[198]\tvalid_0's quantile: 129.842\n",
      "[199]\tvalid_0's quantile: 129.842\n",
      "[200]\tvalid_0's quantile: 129.842\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# kfold\n",
    "prefixes = ['autoquantiles_']\n",
    "features_train, features_validation, targets_train, targets_validation =\\\n",
    "    train_test_split(features[[c for c in features.columns if prefixes_in_column(c, prefixes)]], targets, train_size = .8, shuffle=True, random_state=42)\n",
    "\n",
    "# undersample training features\n",
    "under_sample_pct = .01\n",
    "features_train, _, targets_train, _ = train_test_split(features_train, targets_train, train_size=under_sample_pct, shuffle=True, random_state=42)\n",
    "\n",
    "# define params\n",
    "n_est = 200\n",
    "lr = .001\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': 4,\n",
    "    'subsample': .5,#.5\n",
    "    'subsample_freq': 1,\n",
    "    \"num_leaves\": 2**8-1,#2**8-1,\n",
    "    # 'min_data_in_leaf': 15,#2**8-1,\n",
    "    'feature_fraction': 1, #.5\n",
    "    'bagging_fraction': .8,\n",
    "    \"learning_rate\": lr,\n",
    "    \"n_estimators\": n_est,#100\n",
    "    # \"max_bin\": 100,\n",
    "    'boost_from_average': False,\n",
    "    # \"tweedie_variance_power\": 1.1, # Set the Tweedie variance power (1 <= p <= 2)\n",
    "    \n",
    "    'reg_sqrt': True,\n",
    "    'alpha': q,\n",
    "}\n",
    "\n",
    "# # normalize\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# targets_train = scaler\\\n",
    "#     .fit_transform(targets_train.values.reshape(-1,1))\\\n",
    "#     .reshape(-1)\n",
    "# targets_validation = scaler\\\n",
    "#     .transform(targets_validation.values.reshape(-1,1))\\\n",
    "#     .reshape(-1)\n",
    "\n",
    "# train lgb model        \n",
    "temp_dict = {}\n",
    "mod: lgb.Booster = lgb.train(params, \n",
    "    train_set = lgb.Dataset(features_train, targets_train),\n",
    "    valid_sets = lgb.Dataset(features_validation, targets_validation),\n",
    "    evals_result = temp_dict\n",
    ")\n",
    "\n",
    "# plot distribution of residuals, should have roughly q*n values on the left, and (1-q)*n values on the right\n",
    "plt.hist(mod.predict(features_validation) - targets_validation, bins=200)\n",
    "plt.show()\n",
    "\n",
    "# plot prediction vs. true outcome (with quantile regression, this should correspond to confidence bounds)\n",
    "n = 100\n",
    "idx = targets_validation[:n].index\n",
    "plt.scatter(idx, mod.predict(features_validation)[:n], label = 'pred')\n",
    "plt.scatter(idx, targets_validation[:n], label = 'true')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# plot histogram of targets \n",
    "plt.hist(targets)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# plot log(loss) of training iterations to get insights in convergence\n",
    "plt.plot(np.log(temp_dict[\"valid_0\"][\"quantile\"]))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['auto_sold_7', 'auto_sold_14', 'auto_sold_2', 'auto_sold_1',\n",
       "       'auto_sold_21', 'auto_sold_ma_180', 'auto_sold_ma_60',\n",
       "       'auto_sold_ma_28', 'auto_sold_ma_std_7', 'auto_sold_ma_std_60',\n",
       "       'auto_sold_ma_7', 'auto_sold_ma_std_180', 'auto_sold_ma_std_28',\n",
       "       'autoquantiles_sold_ma_180_0.25', 'autoquantiles_sold_ma_180_0.995',\n",
       "       'autoquantiles_sold_ma_60_0.995', 'autoquantiles_sold_ma_180_0.005',\n",
       "       'autoquantiles_sold_ma_30_0.025', 'autoquantiles_sold_ma_30_0.75',\n",
       "       'autoquantiles_sold_ma_180_0.75', 'autoquantiles_sold_ma_30_0.995',\n",
       "       'autoquantiles_sold_ma_180_0.975', 'autoquantiles_sold_ma_60_0.005',\n",
       "       'autoquantiles_sold_ma_30_0.975', 'autoquantiles_sold_ma_60_0.75',\n",
       "       'autoquantiles_sold_ma_180_0.165', 'autoquantiles_sold_ma_30_0.165',\n",
       "       'autoquantiles_sold_ma_180_0.835', 'autoquantiles_sold_ma_180_0.025',\n",
       "       'autoquantiles_sold_ma_180_0.5', 'autoquantiles_sold_ma_60_0.5',\n",
       "       'autoquantiles_sold_ma_60_0.025', 'autoquantiles_sold_ma_60_0.165',\n",
       "       'autoquantiles_sold_ma_30_0.5', 'autoquantiles_sold_ma_60_0.25',\n",
       "       'autoquantiles_sold_ma_30_0.25', 'autoquantiles_sold_ma_60_0.975',\n",
       "       'autoquantiles_sold_ma_30_0.005', 'autoquantiles_sold_ma_30_0.835',\n",
       "       'autoquantiles_sold_ma_60_0.835', 'momentum_sell_price_m',\n",
       "       'momentum_sell_price_w', 'momentum_sell_price_y', 'seasonal_8',\n",
       "       'seasonal_10', 'seasonal_1', 'seasonal_Friday', 'seasonal_4',\n",
       "       'seasonal_Sunday', 'seasonal_11', 'seasonal_Thursday', 'seasonal_7',\n",
       "       'seasonal_6', 'seasonal_3', 'seasonal_9', 'seasonal_2', 'seasonal_5',\n",
       "       'seasonal_Monday', 'seasonal_Wednesday', 'seasonal_Tuesday',\n",
       "       'seasonal_12', 'seasonal_Saturday', 'seasonal_d_int'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Run for Testing (Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total ~280 seconds\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': 1,\n",
    "    'n_jobs': 4,\n",
    "    'eval_at': 100,\n",
    "    # 'verbose_eval': 0\n",
    "    'subsample': 0.5,\n",
    "    'subsample_freq': 1,\n",
    "    'feature_fraction': 0.5,\n",
    "    'boost_from_average': False,\n",
    "    'alpha': .975\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"num_leaves\": [255], #[int(2**i) for i in [5, 6, 8]],\n",
    "    'min_data_in_leaf': [255], #[int(2**i -1) for i in [5, 6, 8]]\n",
    "    \"learning_rate\": [0.01],#[0.04, 0.02, 0.01, 0.005],\n",
    "    \"n_estimators\": [5000], # [5000, 500, 100]\n",
    "    # \"tweedie_variance_power\": [1.1], # Set the Tweedie variance power (1 <= p <= 2)\n",
    "    # 'max_bin': [100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_train, targets_train = prep_data('Level5')\n",
    "# grid_search(params, param_grid, features_train, targets_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train + Predict submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_level_all_quantiles(agg_level: str, type_of: str, sub_d_start: int, exclude_columns: list = [], test: bool = False, do_grid_search: bool = False, store_submissions_path: str = 'temp_submissions/'):\n",
    "    \"\"\" \n",
    "    Train, for a specific aggregation level, models for all quantiles.\n",
    "    For aggregation levels 10, 11 and 12, undersampling is used to drastically reduce training time.\n",
    "    \"\"\"\n",
    "\n",
    "    # type_of = 'val'\n",
    "    # test = False\n",
    "    # agg_level = 'Level1'\n",
    "    \n",
    "    agg_columns = AGG_LEVEL_COLUMNS[agg_level]\n",
    "    if len(agg_columns) == 0:\n",
    "        agg_str: str = 'Total_X'\n",
    "    elif len(agg_columns) == 1:\n",
    "        agg_str: str = f'{agg_columns[0]}_X'\n",
    "    else:\n",
    "        agg_str: str = '_'.join(agg_columns)\n",
    "\n",
    "    try:\n",
    "        features = pd.DataFrame(features)\n",
    "    except Exception:\n",
    "        logger.info('(re)loading features')\n",
    "        features = pd.read_parquet(f'../data/uncertainty/fold_{sub_d_start}/features/' + (TEST_PATH if test else '') + f'features_{type_of}_{agg_str}.parquet')\n",
    "        features = _down_cast(features)\n",
    "        \n",
    "    features_gr = features.copy()\n",
    "\n",
    "    group_columns = agg_columns\n",
    "    res: list = []\n",
    "\n",
    "    exclude_prefix_list = exclude_columns # unconditional, auto, momentum, seasonal\n",
    "    columns = [c for c in features_gr if c.split('_')[0] not in exclude_prefix_list]\n",
    "    features_gr = features_gr[columns]\n",
    "    \n",
    "    # preparations\n",
    "    # sub_d_start = SUB_D_START_VAL if type_of == 'val' else SUB_D_START_EVAL\n",
    "    train_idx = features_gr['sold'].notna() & features_gr['d'].isin([f'd_{sub_d_start - 1 - i}' for i in range(1460)])\n",
    "    pred_idx = features_gr['d'].isin([f'd_{sub_d_start + i}' for i in range(28)])\n",
    "    df_train = features_gr[train_idx]\n",
    "    df_pred = features_gr[pred_idx]\n",
    "    features_train: pd.DataFrame = df_train.drop(DROP_FEATURE_COLUMNS, axis = 1, errors = 'ignore')\n",
    "    targets_train: pd.Series = df_train['sold']\n",
    "    features_predict: pd.DataFrame = df_pred.drop(DROP_FEATURE_COLUMNS, axis = 1, errors = 'ignore')\n",
    "    \n",
    "    undersampling_dict = {\n",
    "        'Level3': .5,\n",
    "        'Level4': .5,\n",
    "        'Level5': .5,\n",
    "        'Level6': .3,\n",
    "        'Level7': .3,\n",
    "        'Level8': .3,\n",
    "        'Level9': .2,\n",
    "        'Level10': .2,\n",
    "        'Level11': .05,\n",
    "        'Level12': .01\n",
    "    }\n",
    "    if agg_level in undersampling_dict:\n",
    "        undersampling_pct = undersampling_dict[agg_level]\n",
    "        features_train, _, targets_train, _ = train_test_split(features_train, targets_train, train_size = undersampling_pct, shuffle=True, random_state=43)\n",
    "\n",
    "    # normalise targets\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    targets_train = scaler.fit_transform(targets_train.values.reshape(-1,1))\n",
    "        \n",
    "    # train model for all quantiles\n",
    "    for quantile in QUANTILES:\n",
    "        \n",
    "        # perform grid search for best parameters\n",
    "        if do_grid_search == True:\n",
    "            # split data to training and testing\n",
    "            logger.info('divide for cross validation')\n",
    "            x_train, x_test, y_train, y_test = train_test_split(features_train, targets_train, train_size=.8, shuffle=False, random_state=42)\n",
    "            train_data = lgb.Dataset(x_train, y_train)\n",
    "            validation_data = lgb.Dataset(x_test, y_test)\n",
    "            logger.info('perform gridsearch')\n",
    "            best_combination, results = grid_search(params, param_grid, train_data = train_data, validation_data = validation_data)\n",
    "            del train_data; del validation_data\n",
    "            params_grid_train = best_combination[\"params\"]\n",
    "        else:\n",
    "            params_grid_train = {\n",
    "                'objective': 'quantile',\n",
    "                'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "                'boosting_type': 'gbdt',\n",
    "                'random_state': 43,\n",
    "                'verbose': -1,\n",
    "                'n_jobs': 4,\n",
    "                'subsample': .5,#.5\n",
    "                'subsample_freq': 1,\n",
    "                \"num_leaves\": 2**8-1,#2**8-1,\n",
    "                # 'min_data_in_leaf': 15,#2**8-1,\n",
    "                'feature_fraction': 0.5, #.5\n",
    "                'bagging_fraction': .8,\n",
    "                \"learning_rate\": 0.2,\n",
    "                \"n_estimators\": 500,#100\n",
    "                # \"max_bin\": 100,\n",
    "                'boost_from_average': False,\n",
    "                # \"tweedie_variance_power\": 1.1, # Set the Tweedie variance power (1 <= p <= 2)\n",
    "                \n",
    "                'reg_sqrt': True,\n",
    "                'alpha': quantile,\n",
    "            }\n",
    "\n",
    "        # train_best_model\n",
    "        mod = lgb.train(params_grid_train,\n",
    "            train_set = lgb.Dataset(features_train, targets_train)\n",
    "        )\n",
    "        predictions = mod.predict(features_predict)\n",
    "        predictions = scaler.inverse_transform(predictions.reshape(-1,1)).reshape(-1,)\n",
    "        \n",
    "        # store predictions\n",
    "        df_p = pd.DataFrame(\n",
    "            {\n",
    "                'pred': predictions,\n",
    "                'd': df_pred['d'],\n",
    "            }\n",
    "        )\n",
    "        df_p['quantile'] = quantile\n",
    "        df_p['Level'] = agg_level\n",
    "        df_p['type_of'] = 'validation' if type_of == 'val' else 'evaluation'\n",
    "        if len(agg_columns) == 0:\n",
    "            df_p['agg_column1'] = 'Total'\n",
    "            df_p['agg_column2'] = 'X'\n",
    "        elif len(agg_columns) == 1:\n",
    "            df_p['agg_column1'] = df_pred[agg_columns[0]].values\n",
    "            df_p['agg_column2'] = 'X'\n",
    "        else:\n",
    "            df_p['agg_column1'] = df_pred[agg_columns[0]].values\n",
    "            df_p['agg_column2'] = df_pred[agg_columns[1]].values\n",
    "            \n",
    "        df_p = df_p[['Level', 'agg_column1', 'agg_column2', 'd', 'quantile', 'pred', 'type_of']]\n",
    "        \n",
    "        res.append(_down_cast(df_p))\n",
    "        \n",
    "    # remove to reduce memory usage asap\n",
    "    del features\n",
    "        \n",
    "    # storing predictions in specified file + folder\n",
    "    df_sub_val = pd.concat(res)\n",
    "    group_names = '_'.join(group_columns)\n",
    "    if group_names == '':\n",
    "        group_names = 'Total_X'\n",
    "    exclude_names = 'None' if len(exclude_prefix_list) == 0 else '_'.join(exclude_prefix_list)\n",
    "    df_sub_val.to_csv(f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_multivariate_{type_of}_non_transposed_{group_names}_exclude_{exclude_names}.csv', index = False)\n",
    "    logger.info('saved under: ' + f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_multivariate_{type_of}_non_transposed_{group_names}_exclude_{exclude_names}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:15:02 - __main__ - INFO - starting with agg_level: Level1\n",
      "2023-11-08 18:15:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:15:10 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_Total_X_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:15:10 - __main__ - INFO - starting with agg_level: Level2\n",
      "2023-11-08 18:15:10 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:15:35 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:15:35 - __main__ - INFO - starting with agg_level: Level3\n",
      "2023-11-08 18:15:35 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:16:19 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:16:19 - __main__ - INFO - starting with agg_level: Level4\n",
      "2023-11-08 18:16:19 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:16:36 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:16:36 - __main__ - INFO - starting with agg_level: Level5\n",
      "2023-11-08 18:16:36 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:17:02 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:17:02 - __main__ - INFO - starting with agg_level: Level6\n",
      "2023-11-08 18:17:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:17:23 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:17:23 - __main__ - INFO - starting with agg_level: Level7\n",
      "2023-11-08 18:17:23 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:18:12 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:18:12 - __main__ - INFO - starting with agg_level: Level8\n",
      "2023-11-08 18:18:12 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:19:00 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:19:00 - __main__ - INFO - starting with agg_level: Level9\n",
      "2023-11-08 18:19:00 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:20:02 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:20:02 - __main__ - INFO - starting with agg_level: Level10\n",
      "2023-11-08 18:20:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:24:14 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_item_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:24:14 - __main__ - INFO - starting with agg_level: Level11\n",
      "2023-11-08 18:24:14 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:28:35 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_item_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:28:35 - __main__ - INFO - starting with agg_level: Level12\n",
      "2023-11-08 18:28:35 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:34:08 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_item_id_store_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:34:08 - __main__ - INFO - starting with agg_level: Level1\n",
      "2023-11-08 18:34:08 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:34:15 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_Total_X_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:34:15 - __main__ - INFO - starting with agg_level: Level2\n",
      "2023-11-08 18:34:15 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:34:39 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:34:39 - __main__ - INFO - starting with agg_level: Level3\n",
      "2023-11-08 18:34:39 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:35:13 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:35:13 - __main__ - INFO - starting with agg_level: Level4\n",
      "2023-11-08 18:35:13 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:35:24 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:35:24 - __main__ - INFO - starting with agg_level: Level5\n",
      "2023-11-08 18:35:24 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:35:55 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:35:55 - __main__ - INFO - starting with agg_level: Level6\n",
      "2023-11-08 18:35:55 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:36:15 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:36:15 - __main__ - INFO - starting with agg_level: Level7\n",
      "2023-11-08 18:36:15 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:37:05 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:37:05 - __main__ - INFO - starting with agg_level: Level8\n",
      "2023-11-08 18:37:05 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:37:57 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:37:57 - __main__ - INFO - starting with agg_level: Level9\n",
      "2023-11-08 18:37:57 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:39:02 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:39:02 - __main__ - INFO - starting with agg_level: Level10\n",
      "2023-11-08 18:39:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m agg_level \u001b[39min\u001b[39;00m AGG_LEVEL_COLUMNS: \u001b[39m# for each aggregation level\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstarting with agg_level: \u001b[39m\u001b[39m{\u001b[39;00magg_level\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     train_level_all_quantiles(\n\u001b[1;32m     27\u001b[0m         agg_level, \n\u001b[1;32m     28\u001b[0m         sub_d_start\u001b[39m=\u001b[39;49msub_d_start,\n\u001b[1;32m     29\u001b[0m         type_of\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     30\u001b[0m         exclude_columns\u001b[39m=\u001b[39;49mexclude_columns,\n\u001b[1;32m     31\u001b[0m         do_grid_search\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     32\u001b[0m         store_submissions_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtemp_submissions_research/\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     33\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[32], line 112\u001b[0m, in \u001b[0;36mtrain_level_all_quantiles\u001b[0;34m(agg_level, type_of, sub_d_start, exclude_columns, test, do_grid_search, store_submissions_path)\u001b[0m\n\u001b[1;32m     88\u001b[0m     params_grid_train \u001b[39m=\u001b[39m {\n\u001b[1;32m     89\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mquantile\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     90\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mquantile\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m# Use Root Mean Squared Error (RMSE) as the evaluation metric\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m: quantile,\n\u001b[1;32m    109\u001b[0m     }\n\u001b[1;32m    111\u001b[0m \u001b[39m# train_best_model\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m mod \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(params_grid_train,\n\u001b[1;32m    113\u001b[0m     train_set \u001b[39m=\u001b[39;49m lgb\u001b[39m.\u001b[39;49mDataset(features_train, targets_train)\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m predictions \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39mpredict(features_predict)\n\u001b[1;32m    116\u001b[0m predictions \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(predictions\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_tf_env/lib/python3.9/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_tf_env/lib/python3.9/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# all groups: seasonal, auto, autoquantiles, momentum\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    # [],\n",
    "    # ['seasonal'],\n",
    "    # ['auto'],\n",
    "    # ['autoquantiles'],\n",
    "    # ['momentum'],\n",
    "    ['seasonal', 'auto', 'momentum'] # only autocorrelated quantiles\n",
    ")\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    # [],\n",
    "    # ['seasonal'],\n",
    "    # ['momentum'],\n",
    "    # ['autoquantiles'],\n",
    "    # ['auto'],\n",
    "    ['seasonal', 'auto', 'momentum'],\n",
    "    # ['auto', 'momentum']\n",
    ")\n",
    "\n",
    "for exclude_columns in EXCLUDE_COLUMNS_LIST: # for each specified feature combination\n",
    "    for sub_d_start in D_CROSS_VAL_START_LIST: # for each fold\n",
    "        for agg_level in AGG_LEVEL_COLUMNS: # for each aggregation level\n",
    "            logger.info(f'starting with agg_level: {agg_level}')\n",
    "            train_level_all_quantiles(\n",
    "                agg_level, \n",
    "                sub_d_start=sub_d_start,\n",
    "                type_of='val', \n",
    "                exclude_columns=exclude_columns,\n",
    "                do_grid_search=False,\n",
    "                store_submissions_path='temp_submissions_research/'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load val + eval prediction files and merge to one submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_columns = '_'.join([])\n",
    "# if exclude_columns == '':\n",
    "#     exclude_columns = 'None'\n",
    "\n",
    "# dfs: list = []\n",
    "# for level in AGG_LEVEL_COLUMNS:\n",
    "#     agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "#     group_names = '_'.join(agg_columns)\n",
    "#     if group_names == '':\n",
    "#         group_names = 'Total_X'\n",
    "#     i = str(1802)\n",
    "#     dfs.append(\n",
    "#         f'../data/uncertainty/fold_{i}/temp_submissions/' + f'lgb_multivariate_val_non_transposed_{group_names}_exclude_{exclude_columns}.csv',\n",
    "#     )\n",
    "\n",
    "# df_sub_val = ensemble_submissions_uncertainty(dfs)\n",
    "# transpose = True\n",
    "# if transpose == True:\n",
    "#     sub_validation = df_sub_val.pivot(index='id', columns='d', values='pred').reset_index(drop=False)\n",
    "#     sub_validation.columns = [\"id\"] + [f\"F{i}\" for i in range(1,DAYS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_concat_predictions(fold_name: int, exclude_columns: list = []):\n",
    "    \"\"\" \n",
    "    For specified fold, read the predictions for all aggregation levels and stack them together in one dataframe.\n",
    "    \"\"\"\n",
    "    # D_CV_START_LIST\n",
    "    # if fold_name not in D_CV_START_LIST:\n",
    "        # raise ValueError('fold_name must be a value in D_CV_START_LIST')\n",
    "        \n",
    "    exclude_columns = '_'.join(exclude_columns)\n",
    "    if exclude_columns == '':\n",
    "        exclude_columns = 'None'\n",
    "\n",
    "    logger.info('loading files under path:' + f'../data/uncertainty/fold_{fold_name}/temp_submissions/')\n",
    "\n",
    "    dfs: list = []\n",
    "    for level in AGG_LEVEL_COLUMNS:\n",
    "        agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "        group_names = '_'.join(agg_columns)\n",
    "        if group_names == '':\n",
    "            group_names = 'Total_X'\n",
    "\n",
    "        dfs.append(\n",
    "            f'../data/uncertainty/fold_{fold_name}/temp_submissions/' + f'lgb_multivariate_val_non_transposed_{group_names}_exclude_{exclude_columns}.csv',\n",
    "        )\n",
    "\n",
    "    return ensemble_submissions_uncertainty(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_columns = '_'.join([])\n",
    "# if exclude_columns == '':\n",
    "#     exclude_columns = 'None'\n",
    "\n",
    "# dfs: list = []\n",
    "# for level in AGG_LEVEL_COLUMNS:\n",
    "#     agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "#     group_names = '_'.join(agg_columns)\n",
    "#     if group_names == '':\n",
    "#         group_names = 'Total_X'\n",
    "        \n",
    "#     dfs.append(\n",
    "#         PREDICTION_BASE_PATH + f'lgb_multivariate_eval_non_transposed_{group_names}_exclude_{exclude_columns}.csv',\n",
    "#     )\n",
    "\n",
    "# df_sub_eval = ensemble_submissions_uncertainty(dfs)\n",
    "# transpose = True\n",
    "# if transpose == True:\n",
    "#     sub_evaluation = df_sub_eval.pivot(index='id', columns='d', values='pred').reset_index(drop=False)\n",
    "#     sub_evaluation.columns = [\"id\"] + [f\"F{i}\" for i in range(1,DAYS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sub_evaluation = pd.read_csv('../submissions/submission_baseline_evaluation.csv').drop(['Unnamed: 0'], axis=1)\n",
    "# pd.concat([sub_validation, sub_evaluation]).to_csv(SUBMISSION_BASE_PATH + f'submission_lgb_ensemble{exclude_columns}.csv', index=False)\n",
    "# del sub_validation; del sub_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Validation Prediction, we can compute WRMSSE locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these variables are used later on\n",
    "d = pd.read_parquet('../data/uncertainty/cv_template/temp.parquet')\n",
    "d_int = d['d'].str.split('_').apply(lambda x: int(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv(df: pd.DataFrame, df_sub: pd.DataFrame):\n",
    "    \n",
    "    # to be able to merge\n",
    "    df_sub['id_merge'] = df_sub['id'].str.split('.')\\\n",
    "        .apply(lambda x: x[0])\n",
    "    df_sub['quantile'] = df_sub['id'].str.split('.')\\\n",
    "        .apply(lambda x: float('.'.join([x[-2], x[-1].split('_')[0]])))\n",
    "\n",
    "    # merge predictions in cv template\n",
    "    p = pd.merge(\n",
    "        df,\n",
    "        df_sub,\n",
    "        how='left',\n",
    "        on=['id_merge', 'd']\n",
    "    )\n",
    "    # del df; del df_sub_val\n",
    "    p['id_merge'] = p['id_merge'].astype(str)\n",
    "\n",
    "    for c in ['sold', 'revenue']:\n",
    "        p[c] = p[c].astype(np.float32)\n",
    "    # d = d[d_int < (D_CV_START + 28)]\n",
    "\n",
    "    return WSPL(p, [f'd_{i}' for i in range(D_CV_START, D_CV_START + 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 11:01:20 - __main__ - INFO - --------------- ['seasonal', 'auto', 'momentum'] ---------------\n",
      "2023-08-23 11:01:32 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1802/temp_submissions/\n",
      "2023-08-23 11:02:23 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:02:23 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:02:55 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:03:02 - utils.metrics - INFO - Level1 - 0.5094243163667926\n",
      "2023-08-23 11:03:13 - utils.metrics - INFO - Level10 - 0.2974691040013057\n",
      "2023-08-23 11:03:47 - utils.metrics - INFO - Level11 - 0.2925593341513246\n",
      "2023-08-23 11:05:44 - utils.metrics - INFO - Level12 - 0.28617993644852113\n",
      "2023-08-23 11:05:44 - utils.metrics - INFO - Level2 - 0.41335436599424047\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level3 - 0.39246218255236165\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level4 - 0.4088971129355237\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level5 - 0.4194056690547897\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level6 - 0.4375510311627534\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level7 - 0.3907954511737379\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level8 - 0.36553621833229316\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level9 - 0.34526050295601973\n",
      "2023-08-23 11:05:52 - __main__ - INFO - 1802 - wspl: 0.3799079354274719\n",
      "2023-08-23 11:05:57 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1830/temp_submissions/\n",
      "2023-08-23 11:06:56 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:06:56 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:07:32 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:07:39 - utils.metrics - INFO - Level1 - 0.5415997159891802\n",
      "2023-08-23 11:07:50 - utils.metrics - INFO - Level10 - 0.3118867521987879\n",
      "2023-08-23 11:08:25 - utils.metrics - INFO - Level11 - 0.2937851951226946\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level12 - 0.3050911166458399\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level2 - 0.32010568198709466\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level3 - 0.36978150314645747\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level4 - 0.41060458902628244\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level5 - 0.3687130828653947\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level6 - 0.33081491808106106\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level7 - 0.3366365987835377\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level8 - 0.3047925519792386\n",
      "2023-08-23 11:10:29 - utils.metrics - INFO - Level9 - 0.33237765317725315\n",
      "2023-08-23 11:10:36 - __main__ - INFO - 1830 - wspl: 0.35218244658356856\n",
      "2023-08-23 11:10:40 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1858/temp_submissions/\n",
      "2023-08-23 11:11:38 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:11:38 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:12:12 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:12:20 - utils.metrics - INFO - Level1 - 0.2943017381600151\n",
      "2023-08-23 11:12:31 - utils.metrics - INFO - Level10 - 0.30288826775160727\n",
      "2023-08-23 11:13:06 - utils.metrics - INFO - Level11 - 0.28620971054666\n",
      "2023-08-23 11:15:07 - utils.metrics - INFO - Level12 - 0.29991271990272766\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level2 - 0.3624579924102846\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level3 - 0.36798301448813125\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level4 - 0.433688849398041\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level5 - 0.37661763889814726\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level6 - 0.3422735822692424\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level7 - 0.33408616146152786\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level8 - 0.32576719136307347\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level9 - 0.3308348820850935\n",
      "2023-08-23 11:15:16 - __main__ - INFO - 1858 - wspl: 0.3380851457278793\n",
      "2023-08-23 11:15:19 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1886/temp_submissions/\n",
      "2023-08-23 11:16:15 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:16:15 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:16:50 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:16:57 - utils.metrics - INFO - Level1 - 0.3633308108190663\n",
      "2023-08-23 11:17:09 - utils.metrics - INFO - Level10 - 0.2933981539888825\n",
      "2023-08-23 11:17:43 - utils.metrics - INFO - Level11 - 0.2862304002976008\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level12 - 0.3001748469437216\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level2 - 0.3515288970251534\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level3 - 0.34772943533066003\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level4 - 0.40403379344921475\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level5 - 0.41064645143106027\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level6 - 0.34449343445455327\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level7 - 0.3578890637811169\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level8 - 0.34057884237815733\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level9 - 0.319121427300331\n",
      "2023-08-23 11:19:48 - __main__ - INFO - 1886 - wspl: 0.3432629630999598\n",
      "2023-08-23 11:19:52 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1914/temp_submissions/\n",
      "2023-08-23 11:20:47 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:20:47 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:21:22 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:21:30 - utils.metrics - INFO - Level1 - 0.26114931458459384\n",
      "2023-08-23 11:21:41 - utils.metrics - INFO - Level10 - 0.27791292735675954\n",
      "2023-08-23 11:22:15 - utils.metrics - INFO - Level11 - 0.26659250693078723\n",
      "2023-08-23 11:24:15 - utils.metrics - INFO - Level12 - 0.26632866263415017\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level2 - 0.3465961818505697\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level3 - 0.3042461454413001\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level4 - 0.3767883544669268\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level5 - 0.3823450135491447\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level6 - 0.3260881519253884\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level7 - 0.3190495612495478\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level8 - 0.3053848606748176\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level9 - 0.3054618531816178\n",
      "2023-08-23 11:24:25 - __main__ - INFO - 1914 - wspl: 0.31149529448713364\n",
      "2023-08-23 11:24:25 - __main__ - INFO - 1914 - mean wspl: 0.34498675706520265 +/- 0.022106779123872475\n",
      "2023-08-23 11:24:25 - __main__ - INFO - 1914 - raw results: [0.3799079354274719, 0.35218244658356856, 0.3380851457278793, 0.3432629630999598, 0.31149529448713364]\n",
      "2023-08-23 11:24:25 - __main__ - INFO - --------------- ['auto', 'momentum'] ---------------\n",
      "2023-08-23 11:24:28 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1802/temp_submissions/\n",
      "2023-08-23 11:25:25 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:25:25 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:25:59 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:26:06 - utils.metrics - INFO - Level1 - 0.2317026538574037\n",
      "2023-08-23 11:26:17 - utils.metrics - INFO - Level10 - 0.2916661536097424\n",
      "2023-08-23 11:26:52 - utils.metrics - INFO - Level11 - 0.2810585579919864\n",
      "2023-08-23 11:28:50 - utils.metrics - INFO - Level12 - 0.28678906783182223\n",
      "2023-08-23 11:28:50 - utils.metrics - INFO - Level2 - 0.24638947981969986\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level3 - 0.27387834259810706\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level4 - 0.21760546479644452\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level5 - 0.3150004599099869\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level6 - 0.3223399679356197\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level7 - 0.3052157822001202\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level8 - 0.3248847597012523\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level9 - 0.31693789527120697\n",
      "2023-08-23 11:28:57 - __main__ - INFO - 1802 - wspl: 0.2844557154602827\n",
      "2023-08-23 11:29:01 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1830/temp_submissions/\n",
      "2023-08-23 11:29:56 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:29:56 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:30:30 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:30:37 - utils.metrics - INFO - Level1 - 0.3435708185799468\n",
      "2023-08-23 11:30:50 - utils.metrics - INFO - Level10 - 0.2956243926117087\n",
      "2023-08-23 11:31:29 - utils.metrics - INFO - Level11 - 0.2818383519765543\n",
      "2023-08-23 11:33:40 - utils.metrics - INFO - Level12 - 0.3022776377212882\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level2 - 0.21084223804123034\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level3 - 0.2466268074848912\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level4 - 0.28273583945890507\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level5 - 0.30446196777497203\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level6 - 0.2328859251735203\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level7 - 0.285448351669116\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level8 - 0.2434190031700636\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level9 - 0.2743202918565348\n",
      "2023-08-23 11:33:48 - __main__ - INFO - 1830 - wspl: 0.27533763545989426\n",
      "2023-08-23 11:33:51 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1858/temp_submissions/\n",
      "2023-08-23 11:34:50 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:34:50 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:35:27 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:35:36 - utils.metrics - INFO - Level1 - 0.23428793547877136\n",
      "2023-08-23 11:35:49 - utils.metrics - INFO - Level10 - 0.29087867349207874\n",
      "2023-08-23 11:36:27 - utils.metrics - INFO - Level11 - 0.27918063739859594\n",
      "2023-08-23 11:38:40 - utils.metrics - INFO - Level12 - 0.2917579925634804\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level2 - 0.19805506533240552\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level3 - 0.24963856529600328\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level4 - 0.3703047682737021\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level5 - 0.2525415131891123\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level6 - 0.25632805882106985\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level7 - 0.22537108993797045\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level8 - 0.24489828034780925\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level9 - 0.26215668873090453\n",
      "2023-08-23 11:38:49 - __main__ - INFO - 1858 - wspl: 0.2629499390718253\n",
      "2023-08-23 11:38:52 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1886/temp_submissions/\n",
      "2023-08-23 11:39:58 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:39:58 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:40:38 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:40:47 - utils.metrics - INFO - Level1 - 0.1459219538539635\n",
      "2023-08-23 11:41:00 - utils.metrics - INFO - Level10 - 0.28023551447133943\n",
      "2023-08-23 11:41:41 - utils.metrics - INFO - Level11 - 0.27478866565103244\n",
      "2023-08-23 11:43:53 - utils.metrics - INFO - Level12 - 0.29078434392245056\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level2 - 0.16200958782912497\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level3 - 0.18771726531764124\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level4 - 0.3917470835366255\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level5 - 0.275308420388723\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level6 - 0.21760255413399807\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level7 - 0.21181521773055875\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level8 - 0.20985644502367476\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level9 - 0.23140371950460617\n",
      "2023-08-23 11:44:01 - __main__ - INFO - 1886 - wspl: 0.2399325642803115\n",
      "2023-08-23 11:44:05 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1914/temp_submissions/\n",
      "2023-08-23 11:45:05 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:45:05 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:45:47 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:45:55 - utils.metrics - INFO - Level1 - 0.2513019360922543\n",
      "2023-08-23 11:46:07 - utils.metrics - INFO - Level10 - 0.26614146227268104\n",
      "2023-08-23 11:46:45 - utils.metrics - INFO - Level11 - 0.26127442458183503\n",
      "2023-08-23 11:48:53 - utils.metrics - INFO - Level12 - 0.26483872317408663\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level2 - 0.22494925554743278\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level3 - 0.23965821903255716\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level4 - 0.30132737675378357\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level5 - 0.30201066262965093\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level6 - 0.24959331723936853\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level7 - 0.25191802585809314\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level8 - 0.256621755920822\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level9 - 0.2549035258115886\n",
      "2023-08-23 11:49:02 - __main__ - INFO - 1914 - wspl: 0.26037822374284614\n",
      "2023-08-23 11:49:02 - __main__ - INFO - 1914 - mean wspl: 0.264610815603032 +/- 0.015090222978074668\n",
      "2023-08-23 11:49:02 - __main__ - INFO - 1914 - raw results: [0.2844557154602827, 0.27533763545989426, 0.2629499390718253, 0.2399325642803115, 0.26037822374284614]\n"
     ]
    }
   ],
   "source": [
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    [],\n",
    "    ['seasonal'],\n",
    "    ['auto'],\n",
    "    ['autoquantiles'],\n",
    "    ['momentum'],\n",
    ")\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    # ['seasonal'],\n",
    "    # ['momentum'],\n",
    "    # ['autoquantiles'],\n",
    "    ['seasonal', 'auto', 'momentum'],\n",
    "    ['auto', 'momentum'],\n",
    ")\n",
    "\n",
    "for EXCLUDE_COLUMNS in EXCLUDE_COLUMNS_LIST:\n",
    "    logger.info('--------------- ' + str(EXCLUDE_COLUMNS) + ' ---------------')\n",
    "    res = []\n",
    "    for D_CV_START in D_CROSS_VAL_START_LIST:\n",
    "        mean_wspl = perform_cv(_down_cast(d)[d_int < (D_CV_START + 28)], read_concat_predictions(D_CV_START, EXCLUDE_COLUMNS))\n",
    "        res.append(mean_wspl)\n",
    "        logger.info(str(D_CV_START) + ' - wspl: ' + str(mean_wspl))\n",
    "        \n",
    "    logger.info(str(D_CV_START) + ' - mean wspl: ' + str(np.mean(res)) + ' +/- ' + str(np.std(res)))\n",
    "    logger.info(str(D_CV_START) + ' - raw results: ' + str(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Beneath can be used to create submission template\n",
    "The submission template can be used to quickly insert your predictions.\n",
    "It also contains all other (historical) sales to be able to compute the WRMSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_validation = pd.read_csv(DATA_BASE_PATH + SALES_VALIDATION)\n",
    "sales_evaluation = pd.read_csv(DATA_BASE_PATH + SALES_EVALUATION)\n",
    "calendar = pd.read_csv(DATA_BASE_PATH + CALENDAR)\n",
    "sell_prices = pd.read_csv(DATA_BASE_PATH + SELL_PRICES)\n",
    "\n",
    "df_val, submission_idx_val = data_preprocessing(sales_validation, calendar, sell_prices)\n",
    "del sales_validation\n",
    "df_eval, submission_idx_eval = data_preprocessing(sales_evaluation, calendar, sell_prices)\n",
    "del sales_evaluation\n",
    "\n",
    "df_val_after_release = df_val[(df_val.wm_yr_wk > df_val.release)]# & (df_val[\"sold\"].notna())]\n",
    "del df_val\n",
    "df_eval_after_release = df_eval[(df_eval.wm_yr_wk > df_eval.release)]# & (df_eval[\"sold\"].notna())]\n",
    "del df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 17:27:39 - __main__ - INFO - Level1\n",
      "2023-08-17 17:27:40 - __main__ - INFO - Level2\n",
      "2023-08-17 17:27:44 - __main__ - INFO - Level3\n",
      "2023-08-17 17:27:48 - __main__ - INFO - Level4\n",
      "2023-08-17 17:27:51 - __main__ - INFO - Level5\n",
      "2023-08-17 17:27:55 - __main__ - INFO - Level6\n",
      "2023-08-17 17:28:00 - __main__ - INFO - Level7\n",
      "2023-08-17 17:28:05 - __main__ - INFO - Level8\n",
      "2023-08-17 17:28:10 - __main__ - INFO - Level9\n",
      "2023-08-17 17:28:15 - __main__ - INFO - Level10\n",
      "2023-08-17 17:28:21 - __main__ - INFO - Level11\n",
      "2023-08-17 17:28:33 - __main__ - INFO - Level12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>agg_column1</th>\n",
       "      <th>agg_column2</th>\n",
       "      <th>d</th>\n",
       "      <th>sold</th>\n",
       "      <th>revenue</th>\n",
       "      <th>id_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_10</td>\n",
       "      <td>24858.0</td>\n",
       "      <td>63029.78</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_100</td>\n",
       "      <td>23653.0</td>\n",
       "      <td>65665.71</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1000</td>\n",
       "      <td>29241.0</td>\n",
       "      <td>82351.45</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1001</td>\n",
       "      <td>33804.0</td>\n",
       "      <td>93975.55</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1002</td>\n",
       "      <td>42447.0</td>\n",
       "      <td>118961.96</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1003</td>\n",
       "      <td>40647.0</td>\n",
       "      <td>116052.48</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1004</td>\n",
       "      <td>32039.0</td>\n",
       "      <td>89314.17</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1005</td>\n",
       "      <td>29501.0</td>\n",
       "      <td>81688.96</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1006</td>\n",
       "      <td>31117.0</td>\n",
       "      <td>85754.15</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1007</td>\n",
       "      <td>27018.0</td>\n",
       "      <td>74244.86</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1008</td>\n",
       "      <td>39707.0</td>\n",
       "      <td>108637.04</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1009</td>\n",
       "      <td>47082.0</td>\n",
       "      <td>128940.24</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_101</td>\n",
       "      <td>24982.0</td>\n",
       "      <td>68908.04</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1010</td>\n",
       "      <td>48360.0</td>\n",
       "      <td>133218.73</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1011</td>\n",
       "      <td>32930.0</td>\n",
       "      <td>92274.15</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1012</td>\n",
       "      <td>33990.0</td>\n",
       "      <td>92743.98</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1013</td>\n",
       "      <td>32956.0</td>\n",
       "      <td>90505.80</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1014</td>\n",
       "      <td>31862.0</td>\n",
       "      <td>87172.76</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1015</td>\n",
       "      <td>35365.0</td>\n",
       "      <td>95702.83</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1016</td>\n",
       "      <td>45705.0</td>\n",
       "      <td>125791.89</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1017</td>\n",
       "      <td>43898.0</td>\n",
       "      <td>123256.45</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1018</td>\n",
       "      <td>36385.0</td>\n",
       "      <td>100212.69</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1019</td>\n",
       "      <td>32258.0</td>\n",
       "      <td>87909.01</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_102</td>\n",
       "      <td>22196.0</td>\n",
       "      <td>60000.65</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1020</td>\n",
       "      <td>29242.0</td>\n",
       "      <td>81367.81</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1021</td>\n",
       "      <td>29452.0</td>\n",
       "      <td>79956.86</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1022</td>\n",
       "      <td>35763.0</td>\n",
       "      <td>97645.15</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1023</td>\n",
       "      <td>44579.0</td>\n",
       "      <td>123721.42</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1024</td>\n",
       "      <td>42582.0</td>\n",
       "      <td>121478.81</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1025</td>\n",
       "      <td>32102.0</td>\n",
       "      <td>89627.71</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1026</td>\n",
       "      <td>28521.0</td>\n",
       "      <td>78796.16</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1027</td>\n",
       "      <td>27904.0</td>\n",
       "      <td>78144.16</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1028</td>\n",
       "      <td>28693.0</td>\n",
       "      <td>78581.27</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1029</td>\n",
       "      <td>32847.0</td>\n",
       "      <td>91347.72</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_103</td>\n",
       "      <td>22117.0</td>\n",
       "      <td>61407.00</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1030</td>\n",
       "      <td>40046.0</td>\n",
       "      <td>114533.56</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1031</td>\n",
       "      <td>38445.0</td>\n",
       "      <td>111826.12</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1032</td>\n",
       "      <td>28603.0</td>\n",
       "      <td>81092.24</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1033</td>\n",
       "      <td>31247.0</td>\n",
       "      <td>87799.42</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1034</td>\n",
       "      <td>36053.0</td>\n",
       "      <td>97214.80</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1035</td>\n",
       "      <td>19783.0</td>\n",
       "      <td>53456.88</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1036</td>\n",
       "      <td>26041.0</td>\n",
       "      <td>75086.93</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1037</td>\n",
       "      <td>31539.0</td>\n",
       "      <td>91356.80</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1038</td>\n",
       "      <td>38182.0</td>\n",
       "      <td>108919.39</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1039</td>\n",
       "      <td>37079.0</td>\n",
       "      <td>97503.03</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_104</td>\n",
       "      <td>22347.0</td>\n",
       "      <td>60736.91</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1040</td>\n",
       "      <td>38010.0</td>\n",
       "      <td>100557.02</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1041</td>\n",
       "      <td>31513.0</td>\n",
       "      <td>83895.82</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1042</td>\n",
       "      <td>35139.0</td>\n",
       "      <td>93359.95</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1043</td>\n",
       "      <td>36894.0</td>\n",
       "      <td>99430.98</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Level agg_column1 agg_column2       d     sold    revenue id_merge\n",
       "0   Level1       Total           X    d_10  24858.0   63029.78  Total_X\n",
       "1   Level1       Total           X   d_100  23653.0   65665.71  Total_X\n",
       "2   Level1       Total           X  d_1000  29241.0   82351.45  Total_X\n",
       "3   Level1       Total           X  d_1001  33804.0   93975.55  Total_X\n",
       "4   Level1       Total           X  d_1002  42447.0  118961.96  Total_X\n",
       "5   Level1       Total           X  d_1003  40647.0  116052.48  Total_X\n",
       "6   Level1       Total           X  d_1004  32039.0   89314.17  Total_X\n",
       "7   Level1       Total           X  d_1005  29501.0   81688.96  Total_X\n",
       "8   Level1       Total           X  d_1006  31117.0   85754.15  Total_X\n",
       "9   Level1       Total           X  d_1007  27018.0   74244.86  Total_X\n",
       "10  Level1       Total           X  d_1008  39707.0  108637.04  Total_X\n",
       "11  Level1       Total           X  d_1009  47082.0  128940.24  Total_X\n",
       "12  Level1       Total           X   d_101  24982.0   68908.04  Total_X\n",
       "13  Level1       Total           X  d_1010  48360.0  133218.73  Total_X\n",
       "14  Level1       Total           X  d_1011  32930.0   92274.15  Total_X\n",
       "15  Level1       Total           X  d_1012  33990.0   92743.98  Total_X\n",
       "16  Level1       Total           X  d_1013  32956.0   90505.80  Total_X\n",
       "17  Level1       Total           X  d_1014  31862.0   87172.76  Total_X\n",
       "18  Level1       Total           X  d_1015  35365.0   95702.83  Total_X\n",
       "19  Level1       Total           X  d_1016  45705.0  125791.89  Total_X\n",
       "20  Level1       Total           X  d_1017  43898.0  123256.45  Total_X\n",
       "21  Level1       Total           X  d_1018  36385.0  100212.69  Total_X\n",
       "22  Level1       Total           X  d_1019  32258.0   87909.01  Total_X\n",
       "23  Level1       Total           X   d_102  22196.0   60000.65  Total_X\n",
       "24  Level1       Total           X  d_1020  29242.0   81367.81  Total_X\n",
       "25  Level1       Total           X  d_1021  29452.0   79956.86  Total_X\n",
       "26  Level1       Total           X  d_1022  35763.0   97645.15  Total_X\n",
       "27  Level1       Total           X  d_1023  44579.0  123721.42  Total_X\n",
       "28  Level1       Total           X  d_1024  42582.0  121478.81  Total_X\n",
       "29  Level1       Total           X  d_1025  32102.0   89627.71  Total_X\n",
       "30  Level1       Total           X  d_1026  28521.0   78796.16  Total_X\n",
       "31  Level1       Total           X  d_1027  27904.0   78144.16  Total_X\n",
       "32  Level1       Total           X  d_1028  28693.0   78581.27  Total_X\n",
       "33  Level1       Total           X  d_1029  32847.0   91347.72  Total_X\n",
       "34  Level1       Total           X   d_103  22117.0   61407.00  Total_X\n",
       "35  Level1       Total           X  d_1030  40046.0  114533.56  Total_X\n",
       "36  Level1       Total           X  d_1031  38445.0  111826.12  Total_X\n",
       "37  Level1       Total           X  d_1032  28603.0   81092.24  Total_X\n",
       "38  Level1       Total           X  d_1033  31247.0   87799.42  Total_X\n",
       "39  Level1       Total           X  d_1034  36053.0   97214.80  Total_X\n",
       "40  Level1       Total           X  d_1035  19783.0   53456.88  Total_X\n",
       "41  Level1       Total           X  d_1036  26041.0   75086.93  Total_X\n",
       "42  Level1       Total           X  d_1037  31539.0   91356.80  Total_X\n",
       "43  Level1       Total           X  d_1038  38182.0  108919.39  Total_X\n",
       "44  Level1       Total           X  d_1039  37079.0   97503.03  Total_X\n",
       "45  Level1       Total           X   d_104  22347.0   60736.91  Total_X\n",
       "46  Level1       Total           X  d_1040  38010.0  100557.02  Total_X\n",
       "47  Level1       Total           X  d_1041  31513.0   83895.82  Total_X\n",
       "48  Level1       Total           X  d_1042  35139.0   93359.95  Total_X\n",
       "49  Level1       Total           X  d_1043  36894.0   99430.98  Total_X"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "df_eval_after_release['revenue'] = df_eval_after_release['sold'] * df_eval_after_release['sell_price']\n",
    "for level in list(AGG_LEVEL_COLUMNS.keys()):\n",
    "    c = AGG_LEVEL_COLUMNS[level]\n",
    "    logger.info(level)\n",
    "    agg_dict = {\n",
    "        'sold': 'sum',\n",
    "        'revenue': 'sum'\n",
    "    }\n",
    "    d1 = df_eval_after_release.groupby(c + ['d']).agg(agg_dict).reset_index(drop=False)\n",
    "    d = pd.DataFrame({\n",
    "        'd': d1['d'],\n",
    "        'sold': d1['sold'],\n",
    "        'revenue': d1['revenue']\n",
    "    })\n",
    "    if len(c) == 0:\n",
    "        d['agg_column1'] = 'Total'\n",
    "        d['agg_column2'] = 'X'\n",
    "    elif len(c) == 1:\n",
    "        d['agg_column1'] = d1[c[0]]\n",
    "        d['agg_column2'] = 'X'\n",
    "    else:\n",
    "        d['agg_column1'] = d1[c[0]]\n",
    "        d['agg_column2'] = d1[c[1]]\n",
    "    d['id_merge'] = d['agg_column1'] + '_' + d['agg_column2']\n",
    "    d['Level'] = level\n",
    "    dfs.append(d[['Level', 'agg_column1', 'agg_column2', 'd', 'sold', 'revenue', 'id_merge']])\n",
    "d = pd.concat(dfs)\n",
    "d.head(50)\n",
    "d.to_parquet('temp.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open('test.txt')\n",
    "# file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
