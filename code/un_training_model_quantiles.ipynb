{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, math, gc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import pickle as pkl\n",
    "from utils.utils import merge_eval_sold_on_df, sort_df_on_d, WRMSSE, RMSSE, _down_cast, data_preprocessing, diff_lists, log_status\n",
    "from utils.utils import customIter, cross_validation_on_validation_set, ensemble_submissions, ensemble_submissions_uncertainty\n",
    "from utils.metrics import WSPL\n",
    "from utils.configure_logger import configure_logger\n",
    "from utils import constants\n",
    "\n",
    "configure_logger()\n",
    "from logging import getLogger\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_PATH = constants.DATA_BASE_PATH #'../data/m5-forecasting-accuracy/'\n",
    "DATA_BASE_PATH_UNCERTAINTY = constants.DATA_BASE_PATH_UNCERTAINTY #'../data/m5-forecasting-uncertainty/'\n",
    "SALES_EVALUATION = constants.SALES_EVALUATION #'sales_train_evaluation.csv'\n",
    "SALES_VALIDATION = constants.SALES_VALIDATION #'sales_train_validation.csv'\n",
    "CALENDAR = constants.CALENDAR #'calendar.csv'\n",
    "SAMPLE_SUBMISSION = constants.SAMPLE_SUBMISSION #'sample_submission.csv'\n",
    "SELL_PRICES = constants.SELL_PRICES #'sell_prices.csv'\n",
    "\n",
    "PRECOMPUTED_BASE_PATH = constants.PRECOMPUTED_BASE_PATH #'../data/uncertainty/features/'\n",
    "\n",
    "DAYS: int = constants.DAYS #28\n",
    "QUANTILES: int = constants.QUANTILES #[0.005, 0.025, 0.165, 0.25, 0.50, 0.75, 0.835, 0.975, 0.995]\n",
    "\n",
    "AGG_LEVEL_COLUMNS = constants.AGG_LEVEL_COLUMNS\n",
    "D_CROSS_VAL_START_LIST = constants.D_CROSS_VAL_START_LIST #[1802, 1830, 1858, 1886, 1914]\n",
    "\n",
    "# to simple get the precomputed name\n",
    "precomputed_name = lambda store, eval_val: f'processed_{store}_{eval_val}.pkl'\n",
    "\n",
    "TEST_PATH = constants.TEST_PATH#'test/'\n",
    "PREDICTION_BASE_PATH = constants.PREDICTION_BASE_PATH #'../data/uncertainty/temp_submissions/'\n",
    "SUBMISSION_BASE_PATH = constants.SUBMISSION_BASE_PATH #'../data/uncertainty/final_submissions/'\n",
    "\n",
    "SUB_D_START_VAL: int = constants.SUB_D_START_VAL #1914\n",
    "SUB_D_START_EVAL: int = constants.SUB_D_START_EVAL #1914 + 28\n",
    "\n",
    "# the columns are always included after feature processing\n",
    "# because they are required in the training and submission format\n",
    "DROP_FEATURE_COLUMNS: list = constants.DROP_FEATURE_COLUMNS #['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'd', 'sold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GridSearch functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_status\n",
    "def grid_search(params: dict, param_grid: dict, features, targets, n_folds: int = 1):\n",
    "    \"\"\" \n",
    "    Given a grid with parameters, train lgb model for all possible combinations.\n",
    "    Returns the parameter set with the best score and the dictionary with all results.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    # to be sure\n",
    "    features = features.reset_index(drop=True)\n",
    "    targets = targets.reset_index(drop=True)\n",
    "\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "    results = {}\n",
    "    for i, param_combination in enumerate(param_combinations,1):\n",
    "        \n",
    "        # create dictionary with all parameters\n",
    "        param_combination = {k:v for k,v in zip(param_grid.keys(), param_combination)}\n",
    "        param_combination.update(params)\n",
    "        \n",
    "        # init dict\n",
    "        results[f\"combination_{i}\"] = {\n",
    "            'params': param_combination,\n",
    "            'res': []\n",
    "        }\n",
    "        \n",
    "        # perform n_folds\n",
    "        # from sklearn.model_selection import KFold\n",
    "        # kfold = KFold(n_splits=n_folds)\n",
    "        # for j, (train_idx, validation_idx) in enumerate(kfold.split(features)):\n",
    "        \n",
    "        for j in range(n_folds):\n",
    "            \n",
    "            # kfold\n",
    "            features_train, features_validation, targets_train, targets_validation =\\\n",
    "                train_test_split(features, targets, train_size = .8, shuffle=True, random_state=42)\n",
    "        \n",
    "            # # split data for fold\n",
    "            # features_train, features_validation = features.loc[train_idx], features.loc[validation_idx]\n",
    "            # targets_train, targets_validation = targets.loc[train_idx], targets.loc[validation_idx]\n",
    "\n",
    "            # normalize\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            \n",
    "            targets_train = scaler\\\n",
    "                .fit_transform(targets_train.values.reshape(-1,1))\\\n",
    "                .reshape(-1)\n",
    "            targets_validation = scaler\\\n",
    "                .transform(targets_validation.values.reshape(-1,1))\\\n",
    "                .reshape(-1)\n",
    "\n",
    "            # train lgb model        \n",
    "            temp_dict = {} # this dict object will be used to add all (intermediate) evaluation scores during the training process\n",
    "            mod: lgb.Booster = lgb.train(param_combination, \n",
    "                train_set = lgb.Dataset(features_train, targets_train),\n",
    "                valid_sets = lgb.Dataset(features_validation, targets_validation),\n",
    "                evals_result = temp_dict\n",
    "            )\n",
    "            \n",
    "            # store results\n",
    "            results[f\"combination_{i}\"]['res']\\\n",
    "                .append(temp_dict[\"valid_0\"][\"quantile\"][-1],\n",
    "            )\n",
    "\n",
    "        # compute average results\n",
    "        results[f\"combination_{i}\"]['validation_score'] = \\\n",
    "            np.mean(results[f\"combination_{i}\"]['res'])\n",
    "        \n",
    "    # sort the results based on evaluation score\n",
    "    sorted_results = dict(sorted(results.items(), key=lambda item: item[1][\"validation_score\"]))\n",
    "    return list(sorted_results.values())[-1], results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(level):\n",
    "    \"\"\" read the precomputed features and targets for specified aggregation level,  \"\"\"\n",
    "    # define params\n",
    "    agg_level = level\n",
    "    sub_d_start: int = int(1886)\n",
    "    exclude_columns = []\n",
    "    test = False\n",
    "    type_of = 'val'\n",
    "\n",
    "    # read file\n",
    "    agg_columns = AGG_LEVEL_COLUMNS[agg_level]\n",
    "    if len(agg_columns) == 0:\n",
    "        agg_str: str = 'Total_X'\n",
    "    elif len(agg_columns) == 1:\n",
    "        agg_str: str = f'{agg_columns[0]}_X'\n",
    "    else:\n",
    "        agg_str: str = '_'.join(agg_columns)\n",
    "\n",
    "    try:\n",
    "        features = pd.DataFrame(features)\n",
    "    except Exception:\n",
    "        logger.info('(re)loading features')\n",
    "        features = pd.read_parquet(f'../data/uncertainty/fold_{sub_d_start}/features/' + (TEST_PATH if test else '') + f'features_{type_of}_{agg_str}.parquet')\n",
    "        features = _down_cast(features)\n",
    "\n",
    "    group_columns = agg_columns\n",
    "    exclude_prefix_list = exclude_columns # unconditional, auto, momentum, seasonal\n",
    "\n",
    "    features_gr = features.copy()\n",
    "    features_gr = features_gr[[c for c in features_gr if c.split('_')[0] not in exclude_prefix_list]]\n",
    "\n",
    "    # preparations\n",
    "    train_idx = features_gr['sold'].notna() & features_gr['d'].isin([f'd_{sub_d_start - 1 - i}' for i in range(1460)])\n",
    "    df_train = features_gr[train_idx]\n",
    "    features_train: pd.DataFrame = df_train.drop(DROP_FEATURE_COLUMNS, axis = 1, errors = 'ignore')\n",
    "    targets_train: pd.Series = df_train['sold']\n",
    "    return features_train, targets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:39:22 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's quantile: 0.350412\n",
      "[2]\tvalid_0's quantile: 0.336668\n",
      "[3]\tvalid_0's quantile: 0.317183\n",
      "[4]\tvalid_0's quantile: 0.293789\n",
      "[5]\tvalid_0's quantile: 0.268958\n",
      "[6]\tvalid_0's quantile: 0.244266\n",
      "[7]\tvalid_0's quantile: 0.218835\n",
      "[8]\tvalid_0's quantile: 0.194743\n",
      "[9]\tvalid_0's quantile: 0.173297\n",
      "[10]\tvalid_0's quantile: 0.152578\n",
      "[11]\tvalid_0's quantile: 0.134181\n",
      "[12]\tvalid_0's quantile: 0.11748\n",
      "[13]\tvalid_0's quantile: 0.102786\n",
      "[14]\tvalid_0's quantile: 0.0898452\n",
      "[15]\tvalid_0's quantile: 0.0784465\n",
      "[16]\tvalid_0's quantile: 0.0693253\n",
      "[17]\tvalid_0's quantile: 0.0617017\n",
      "[18]\tvalid_0's quantile: 0.0553916\n",
      "[19]\tvalid_0's quantile: 0.0496491\n",
      "[20]\tvalid_0's quantile: 0.0446872\n",
      "[21]\tvalid_0's quantile: 0.040437\n",
      "[22]\tvalid_0's quantile: 0.0365833\n",
      "[23]\tvalid_0's quantile: 0.0332796\n",
      "[24]\tvalid_0's quantile: 0.0303461\n",
      "[25]\tvalid_0's quantile: 0.0277636\n",
      "[26]\tvalid_0's quantile: 0.0256045\n",
      "[27]\tvalid_0's quantile: 0.0237478\n",
      "[28]\tvalid_0's quantile: 0.0221211\n",
      "[29]\tvalid_0's quantile: 0.0206836\n",
      "[30]\tvalid_0's quantile: 0.0194237\n",
      "[31]\tvalid_0's quantile: 0.0183009\n",
      "[32]\tvalid_0's quantile: 0.0173179\n",
      "[33]\tvalid_0's quantile: 0.0164752\n",
      "[34]\tvalid_0's quantile: 0.0157278\n",
      "[35]\tvalid_0's quantile: 0.0150714\n",
      "[36]\tvalid_0's quantile: 0.014509\n",
      "[37]\tvalid_0's quantile: 0.0140249\n",
      "[38]\tvalid_0's quantile: 0.0135964\n",
      "[39]\tvalid_0's quantile: 0.0132329\n",
      "[40]\tvalid_0's quantile: 0.0129518\n",
      "[41]\tvalid_0's quantile: 0.0127222\n",
      "[42]\tvalid_0's quantile: 0.0125364\n",
      "[43]\tvalid_0's quantile: 0.0123652\n",
      "[44]\tvalid_0's quantile: 0.0122508\n",
      "[45]\tvalid_0's quantile: 0.0121076\n",
      "[46]\tvalid_0's quantile: 0.0119977\n",
      "[47]\tvalid_0's quantile: 0.0119101\n",
      "[48]\tvalid_0's quantile: 0.0118593\n",
      "[49]\tvalid_0's quantile: 0.0118083\n",
      "[50]\tvalid_0's quantile: 0.0117708\n"
     ]
    }
   ],
   "source": [
    "level = 'Level5'\n",
    "q = .025\n",
    "n_est = 50 # 200\n",
    "lr = .1 #.2\n",
    "\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': 4,\n",
    "    'subsample': .5,#.5\n",
    "    'subsample_freq': 1,\n",
    "    \"num_leaves\": 2**8-1,#2**8-1,\n",
    "    # 'min_data_in_leaf': 15,#2**8-1,\n",
    "    'feature_fraction': 0.5, #.5\n",
    "    'bagging_fraction': .8,\n",
    "    \"learning_rate\": lr,\n",
    "    \"n_estimators\": n_est,#100\n",
    "    # \"max_bin\": 100,\n",
    "    'boost_from_average': False,\n",
    "    # \"tweedie_variance_power\": 1.1, # Set the Tweedie variance power (1 <= p <= 2)\n",
    "    \n",
    "    'reg_sqrt': True,\n",
    "    'alpha': q,\n",
    "}\n",
    "\n",
    "features, targets = prep_data(level)\n",
    "\n",
    "# kfold\n",
    "features_train, features_validation, targets_train, targets_validation =\\\n",
    "    train_test_split(features, targets, train_size = .8, shuffle=True, random_state=42)\n",
    "\n",
    "# normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "targets_train = scaler\\\n",
    "    .fit_transform(targets_train.values.reshape(-1,1))\\\n",
    "    .reshape(-1)\n",
    "targets_validation = scaler\\\n",
    "    .transform(targets_validation.values.reshape(-1,1))\\\n",
    "    .reshape(-1)\n",
    "\n",
    "# train lgb model        \n",
    "temp_dict = {}\n",
    "mod: lgb.Booster = lgb.train(params, \n",
    "    train_set = lgb.Dataset(features_train, targets_train),\n",
    "    valid_sets = lgb.Dataset(features_validation, targets_validation),\n",
    "    evals_result = temp_dict\n",
    ")\n",
    "\n",
    "# plt.hist(mod.predict(features_validation) - targets_validation, bins=200)\n",
    "# plt.show()\n",
    "# n = 100\n",
    "# # plt.plot(mod.predict(features_validation)[:n])\n",
    "# plt.plot(targets_validation[:n])\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(targets)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.log(temp_dict[\"valid_0\"][\"quantile\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['auto_sold_7', 'auto_sold_14', 'auto_sold_2', 'auto_sold_1',\n",
       "       'auto_sold_21', 'auto_sold_ma_180', 'auto_sold_ma_60',\n",
       "       'auto_sold_ma_28', 'auto_sold_ma_std_7', 'auto_sold_ma_std_60',\n",
       "       'auto_sold_ma_7', 'auto_sold_ma_std_180', 'auto_sold_ma_std_28',\n",
       "       'autoquantiles_sold_ma_180_0.25', 'autoquantiles_sold_ma_180_0.995',\n",
       "       'autoquantiles_sold_ma_60_0.995', 'autoquantiles_sold_ma_180_0.005',\n",
       "       'autoquantiles_sold_ma_30_0.025', 'autoquantiles_sold_ma_30_0.75',\n",
       "       'autoquantiles_sold_ma_180_0.75', 'autoquantiles_sold_ma_30_0.995',\n",
       "       'autoquantiles_sold_ma_180_0.975', 'autoquantiles_sold_ma_60_0.005',\n",
       "       'autoquantiles_sold_ma_30_0.975', 'autoquantiles_sold_ma_60_0.75',\n",
       "       'autoquantiles_sold_ma_180_0.165', 'autoquantiles_sold_ma_30_0.165',\n",
       "       'autoquantiles_sold_ma_180_0.835', 'autoquantiles_sold_ma_180_0.025',\n",
       "       'autoquantiles_sold_ma_180_0.5', 'autoquantiles_sold_ma_60_0.5',\n",
       "       'autoquantiles_sold_ma_60_0.025', 'autoquantiles_sold_ma_60_0.165',\n",
       "       'autoquantiles_sold_ma_30_0.5', 'autoquantiles_sold_ma_60_0.25',\n",
       "       'autoquantiles_sold_ma_30_0.25', 'autoquantiles_sold_ma_60_0.975',\n",
       "       'autoquantiles_sold_ma_30_0.005', 'autoquantiles_sold_ma_30_0.835',\n",
       "       'autoquantiles_sold_ma_60_0.835', 'momentum_sell_price_m',\n",
       "       'momentum_sell_price_w', 'momentum_sell_price_y', 'seasonal_8',\n",
       "       'seasonal_10', 'seasonal_1', 'seasonal_Friday', 'seasonal_4',\n",
       "       'seasonal_Sunday', 'seasonal_11', 'seasonal_Thursday', 'seasonal_7',\n",
       "       'seasonal_6', 'seasonal_3', 'seasonal_9', 'seasonal_2', 'seasonal_5',\n",
       "       'seasonal_Monday', 'seasonal_Wednesday', 'seasonal_Tuesday',\n",
       "       'seasonal_12', 'seasonal_Saturday', 'seasonal_d_int'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Run for Testing (Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_grid_train = {\n",
    "#     \"num_leaves\": 2**8-1,#2**8-1,\n",
    "#     # 'min_data_in_leaf': 15,#2**8-1,\n",
    "#     'feature_fraction': 0.5, #.5\n",
    "#     'bagging_fraction': .8,\n",
    "#     \"learning_rate\": 0.2,\n",
    "#     \"n_estimators\": 500,#100\n",
    "#     # \"max_bin\": 100,\n",
    "#     # \"tweedie_variance_power\": 1.1, # Set the Tweedie variance power (1 <= p <= 2)\n",
    "    \n",
    "#     'reg_sqrt': True,\n",
    "#     'alpha': quantile,\n",
    "# }\n",
    "\n",
    "# total ~280 seconds\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': 1,\n",
    "    'n_jobs': 4,\n",
    "    'eval_at': 100,\n",
    "    # 'verbose_eval': 0\n",
    "    'subsample': 0.5,\n",
    "    'subsample_freq': 1,\n",
    "    'feature_fraction': 0.5,\n",
    "    'boost_from_average': False,\n",
    "    'alpha': .975\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"num_leaves\": [255], #[int(2**i) for i in [5, 6, 8]],\n",
    "    'min_data_in_leaf': [255], #[int(2**i -1) for i in [5, 6, 8]]\n",
    "    \"learning_rate\": [0.01],#[0.04, 0.02, 0.01, 0.005],\n",
    "    \"n_estimators\": [5000], # [5000, 500, 100]\n",
    "    # \"tweedie_variance_power\": [1.1], # Set the Tweedie variance power (1 <= p <= 2)\n",
    "    # 'max_bin': [100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_train, targets_train = prep_data('Level5')\n",
    "# grid_search(params, param_grid, features_train, targets_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train + Predict submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_level_all_quantiles(agg_level: str, type_of: str, sub_d_start: int, exclude_columns: list = [], test: bool = False, do_grid_search: bool = False, store_submissions_path: str = 'temp_submissions/'):\n",
    "    \"\"\" \n",
    "    Train, for a specific aggregation level, models for all quantiles.\n",
    "    For aggregation levels 10, 11 and 12, undersampling is used to drastically reduce training time.\n",
    "    \"\"\"\n",
    "\n",
    "    # type_of = 'val'\n",
    "    # test = False\n",
    "    # agg_level = 'Level1'\n",
    "    \n",
    "    agg_columns = AGG_LEVEL_COLUMNS[agg_level]\n",
    "    if len(agg_columns) == 0:\n",
    "        agg_str: str = 'Total_X'\n",
    "    elif len(agg_columns) == 1:\n",
    "        agg_str: str = f'{agg_columns[0]}_X'\n",
    "    else:\n",
    "        agg_str: str = '_'.join(agg_columns)\n",
    "\n",
    "    try:\n",
    "        features = pd.DataFrame(features)\n",
    "    except Exception:\n",
    "        logger.info('(re)loading features')\n",
    "        features = pd.read_parquet(f'../data/uncertainty/fold_{sub_d_start}/features/' + (TEST_PATH if test else '') + f'features_{type_of}_{agg_str}.parquet')\n",
    "        features = _down_cast(features)\n",
    "\n",
    "    # group_columns = ['store_id', 'cat_id'] # 'store_id', 'cat_id', 'dept_id'\n",
    "    # group_columns = ['store_id', 'dept_id']\n",
    "    group_columns = agg_columns\n",
    "    res: list = []\n",
    "\n",
    "    exclude_prefix_list = exclude_columns # unconditional, auto, momentum, seasonal\n",
    "\n",
    "    # for id, features_gr in customIter(features.groupby(group_columns)):\n",
    "    #     # load grouped df\n",
    "    #     features_gr: pd.DataFrame = features_gr.reset_index(drop=True)\n",
    "\n",
    "    for i in range(1):\n",
    "        features_gr = features.copy()\n",
    "        \n",
    "        features_gr = features_gr[[c for c in features_gr if c.split('_')[0] not in exclude_prefix_list]]\n",
    "        \n",
    "        # preparations\n",
    "        # sub_d_start = SUB_D_START_VAL if type_of == 'val' else SUB_D_START_EVAL\n",
    "        train_idx = features_gr['sold'].notna() & features_gr['d'].isin([f'd_{sub_d_start - 1 - i}' for i in range(1460)])\n",
    "        pred_idx = features_gr['d'].isin([f'd_{sub_d_start + i}' for i in range(28)])\n",
    "        df_train = features_gr[train_idx]\n",
    "        df_pred = features_gr[pred_idx]\n",
    "        features_train: pd.DataFrame = df_train.drop(DROP_FEATURE_COLUMNS, axis = 1, errors = 'ignore')\n",
    "        targets_train: pd.Series = df_train['sold']\n",
    "        features_predict: pd.DataFrame = df_pred.drop(DROP_FEATURE_COLUMNS, axis = 1, errors = 'ignore')\n",
    "        \n",
    "        undersampling_dict = {\n",
    "            'Level3': .5,\n",
    "            'Level4': .5,\n",
    "            'Level5': .5,\n",
    "            'Level6': .3,\n",
    "            'Level7': .3,\n",
    "            'Level8': .3,\n",
    "            'Level9': .2,\n",
    "            'Level10': .2,\n",
    "            'Level11': .05,\n",
    "            'Level12': .01\n",
    "        }\n",
    "        if agg_level in undersampling_dict:\n",
    "            undersampling_pct = undersampling_dict[agg_level]\n",
    "            features_train, _, targets_train, _ = train_test_split(features_train, targets_train, train_size = undersampling_pct, shuffle=True, random_state=43)\n",
    "\n",
    "        # normalise targets\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        targets_train = scaler.fit_transform(targets_train.values.reshape(-1,1))\n",
    "            \n",
    "        # train model for all quantiles\n",
    "        for quantile in QUANTILES:\n",
    "            \n",
    "            # perform grid search for best parameters\n",
    "            if do_grid_search == True:\n",
    "                # split data to training and testing\n",
    "                logger.info('divide for cross validation')\n",
    "                x_train, x_test, y_train, y_test = train_test_split(features_train, targets_train, train_size=.8, shuffle=False, random_state=42)\n",
    "                train_data = lgb.Dataset(x_train, y_train)\n",
    "                validation_data = lgb.Dataset(x_test, y_test)\n",
    "                logger.info('perform gridsearch')\n",
    "                best_combination, results = grid_search(params, param_grid, train_data = train_data, validation_data = validation_data)\n",
    "                del train_data; del validation_data\n",
    "                params_grid_train = best_combination[\"params\"]\n",
    "            else:\n",
    "                params_grid_train = {\n",
    "                    'objective': 'quantile',\n",
    "                    'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'random_state': 43,\n",
    "                    'verbose': -1,\n",
    "                    'n_jobs': 4,\n",
    "                    'subsample': .5,#.5\n",
    "                    'subsample_freq': 1,\n",
    "                    \"num_leaves\": 2**8-1,#2**8-1,\n",
    "                    # 'min_data_in_leaf': 15,#2**8-1,\n",
    "                    'feature_fraction': 0.5, #.5\n",
    "                    'bagging_fraction': .8,\n",
    "                    \"learning_rate\": 0.2,\n",
    "                    \"n_estimators\": 500,#100\n",
    "                    # \"max_bin\": 100,\n",
    "                    'boost_from_average': False,\n",
    "                    # \"tweedie_variance_power\": 1.1, # Set the Tweedie variance power (1 <= p <= 2)\n",
    "                    \n",
    "                    'reg_sqrt': True,\n",
    "                    'alpha': quantile,\n",
    "                }\n",
    "\n",
    "            # train_best_model\n",
    "            mod = lgb.train(params_grid_train,\n",
    "                train_set = lgb.Dataset(features_train, targets_train)\n",
    "            )\n",
    "            predictions = mod.predict(features_predict)\n",
    "            predictions = scaler.inverse_transform(predictions.reshape(-1,1)).reshape(-1,)\n",
    "            \n",
    "            # store predictions\n",
    "            df_p = pd.DataFrame(\n",
    "                {\n",
    "                    'pred': predictions,\n",
    "                    'd': df_pred['d'],\n",
    "                }\n",
    "            )\n",
    "            df_p['quantile'] = quantile\n",
    "            df_p['Level'] = agg_level\n",
    "            df_p['type_of'] = 'validation' if type_of == 'val' else 'evaluation'\n",
    "            if len(agg_columns) == 0:\n",
    "                df_p['agg_column1'] = 'Total'\n",
    "                df_p['agg_column2'] = 'X'\n",
    "            elif len(agg_columns) == 1:\n",
    "                df_p['agg_column1'] = df_pred[agg_columns[0]].values\n",
    "                df_p['agg_column2'] = 'X'\n",
    "            else:\n",
    "                df_p['agg_column1'] = df_pred[agg_columns[0]].values\n",
    "                df_p['agg_column2'] = df_pred[agg_columns[1]].values\n",
    "                \n",
    "            df_p = df_p[['Level', 'agg_column1', 'agg_column2', 'd', 'quantile', 'pred', 'type_of']]\n",
    "            \n",
    "            res.append(_down_cast(df_p))\n",
    "        \n",
    "    # remove to reduce memory usage asap\n",
    "    del features\n",
    "        \n",
    "    # storing predictions in specified file + folder\n",
    "    df_sub_val = pd.concat(res)\n",
    "    group_names = '_'.join(group_columns)\n",
    "    if group_names == '':\n",
    "        group_names = 'Total_X'\n",
    "    exclude_names = 'None' if len(exclude_prefix_list) == 0 else '_'.join(exclude_prefix_list)\n",
    "    df_sub_val.to_csv(f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_multivariate_{type_of}_non_transposed_{group_names}_exclude_{exclude_names}.csv', index = False)\n",
    "    logger.info('saved under: ' + f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_multivariate_{type_of}_non_transposed_{group_names}_exclude_{exclude_names}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:15:02 - __main__ - INFO - starting with agg_level: Level1\n",
      "2023-11-08 18:15:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:15:10 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_Total_X_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:15:10 - __main__ - INFO - starting with agg_level: Level2\n",
      "2023-11-08 18:15:10 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:15:35 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:15:35 - __main__ - INFO - starting with agg_level: Level3\n",
      "2023-11-08 18:15:35 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:16:19 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:16:19 - __main__ - INFO - starting with agg_level: Level4\n",
      "2023-11-08 18:16:19 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:16:36 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:16:36 - __main__ - INFO - starting with agg_level: Level5\n",
      "2023-11-08 18:16:36 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:17:02 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:17:02 - __main__ - INFO - starting with agg_level: Level6\n",
      "2023-11-08 18:17:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:17:23 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:17:23 - __main__ - INFO - starting with agg_level: Level7\n",
      "2023-11-08 18:17:23 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:18:12 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:18:12 - __main__ - INFO - starting with agg_level: Level8\n",
      "2023-11-08 18:18:12 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:19:00 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:19:00 - __main__ - INFO - starting with agg_level: Level9\n",
      "2023-11-08 18:19:00 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:20:02 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:20:02 - __main__ - INFO - starting with agg_level: Level10\n",
      "2023-11-08 18:20:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:24:14 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_item_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:24:14 - __main__ - INFO - starting with agg_level: Level11\n",
      "2023-11-08 18:24:14 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:28:35 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_item_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:28:35 - __main__ - INFO - starting with agg_level: Level12\n",
      "2023-11-08 18:28:35 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:34:08 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_item_id_store_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:34:08 - __main__ - INFO - starting with agg_level: Level1\n",
      "2023-11-08 18:34:08 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:34:15 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_Total_X_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:34:15 - __main__ - INFO - starting with agg_level: Level2\n",
      "2023-11-08 18:34:15 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:34:39 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:34:39 - __main__ - INFO - starting with agg_level: Level3\n",
      "2023-11-08 18:34:39 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:35:13 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:35:13 - __main__ - INFO - starting with agg_level: Level4\n",
      "2023-11-08 18:35:13 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:35:24 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:35:24 - __main__ - INFO - starting with agg_level: Level5\n",
      "2023-11-08 18:35:24 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:35:55 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:35:55 - __main__ - INFO - starting with agg_level: Level6\n",
      "2023-11-08 18:35:55 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:36:15 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:36:15 - __main__ - INFO - starting with agg_level: Level7\n",
      "2023-11-08 18:36:15 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:37:05 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:37:05 - __main__ - INFO - starting with agg_level: Level8\n",
      "2023-11-08 18:37:05 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:37:57 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:37:57 - __main__ - INFO - starting with agg_level: Level9\n",
      "2023-11-08 18:37:57 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:39:02 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:39:02 - __main__ - INFO - starting with agg_level: Level10\n",
      "2023-11-08 18:39:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m agg_level \u001b[39min\u001b[39;00m AGG_LEVEL_COLUMNS: \u001b[39m# for each aggregation level\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstarting with agg_level: \u001b[39m\u001b[39m{\u001b[39;00magg_level\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     train_level_all_quantiles(\n\u001b[1;32m     27\u001b[0m         agg_level, \n\u001b[1;32m     28\u001b[0m         sub_d_start\u001b[39m=\u001b[39;49msub_d_start,\n\u001b[1;32m     29\u001b[0m         type_of\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     30\u001b[0m         exclude_columns\u001b[39m=\u001b[39;49mexclude_columns,\n\u001b[1;32m     31\u001b[0m         do_grid_search\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     32\u001b[0m         store_submissions_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtemp_submissions_research/\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     33\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[32], line 112\u001b[0m, in \u001b[0;36mtrain_level_all_quantiles\u001b[0;34m(agg_level, type_of, sub_d_start, exclude_columns, test, do_grid_search, store_submissions_path)\u001b[0m\n\u001b[1;32m     88\u001b[0m     params_grid_train \u001b[39m=\u001b[39m {\n\u001b[1;32m     89\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mquantile\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     90\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mquantile\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m# Use Root Mean Squared Error (RMSE) as the evaluation metric\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m: quantile,\n\u001b[1;32m    109\u001b[0m     }\n\u001b[1;32m    111\u001b[0m \u001b[39m# train_best_model\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m mod \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(params_grid_train,\n\u001b[1;32m    113\u001b[0m     train_set \u001b[39m=\u001b[39;49m lgb\u001b[39m.\u001b[39;49mDataset(features_train, targets_train)\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m predictions \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39mpredict(features_predict)\n\u001b[1;32m    116\u001b[0m predictions \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(predictions\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_tf_env/lib/python3.9/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_tf_env/lib/python3.9/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# all groups: seasonal, auto, autoquantiles, momentum\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    # [],\n",
    "    # ['seasonal'],\n",
    "    # ['auto'],\n",
    "    # ['autoquantiles'],\n",
    "    # ['momentum'],\n",
    "    ['seasonal', 'auto', 'momentum'] # only autocorrelated quantiles\n",
    ")\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    # [],\n",
    "    # ['seasonal'],\n",
    "    # ['momentum'],\n",
    "    # ['autoquantiles'],\n",
    "    # ['auto'],\n",
    "    ['seasonal', 'auto', 'momentum'],\n",
    "    # ['auto', 'momentum']\n",
    ")\n",
    "\n",
    "for exclude_columns in EXCLUDE_COLUMNS_LIST: # for each specified feature combination\n",
    "    for sub_d_start in D_CROSS_VAL_START_LIST: # for each fold\n",
    "        for agg_level in AGG_LEVEL_COLUMNS: # for each aggregation level\n",
    "            logger.info(f'starting with agg_level: {agg_level}')\n",
    "            train_level_all_quantiles(\n",
    "                agg_level, \n",
    "                sub_d_start=sub_d_start,\n",
    "                type_of='val', \n",
    "                exclude_columns=exclude_columns,\n",
    "                do_grid_search=False,\n",
    "                store_submissions_path='temp_submissions_research/'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load val + eval prediction files and merge to one submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_columns = '_'.join([])\n",
    "# if exclude_columns == '':\n",
    "#     exclude_columns = 'None'\n",
    "\n",
    "# dfs: list = []\n",
    "# for level in AGG_LEVEL_COLUMNS:\n",
    "#     agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "#     group_names = '_'.join(agg_columns)\n",
    "#     if group_names == '':\n",
    "#         group_names = 'Total_X'\n",
    "#     i = str(1802)\n",
    "#     dfs.append(\n",
    "#         f'../data/uncertainty/fold_{i}/temp_submissions/' + f'lgb_multivariate_val_non_transposed_{group_names}_exclude_{exclude_columns}.csv',\n",
    "#     )\n",
    "\n",
    "# df_sub_val = ensemble_submissions_uncertainty(dfs)\n",
    "# transpose = True\n",
    "# if transpose == True:\n",
    "#     sub_validation = df_sub_val.pivot(index='id', columns='d', values='pred').reset_index(drop=False)\n",
    "#     sub_validation.columns = [\"id\"] + [f\"F{i}\" for i in range(1,DAYS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_concat_predictions(fold_name: int, exclude_columns: list = []):\n",
    "    \"\"\" \n",
    "    For specified fold, read the predictions for all aggregation levels and stack them together in one dataframe.\n",
    "    \"\"\"\n",
    "    # D_CV_START_LIST\n",
    "    # if fold_name not in D_CV_START_LIST:\n",
    "        # raise ValueError('fold_name must be a value in D_CV_START_LIST')\n",
    "        \n",
    "    exclude_columns = '_'.join(exclude_columns)\n",
    "    if exclude_columns == '':\n",
    "        exclude_columns = 'None'\n",
    "\n",
    "    logger.info('loading files under path:' + f'../data/uncertainty/fold_{fold_name}/temp_submissions/')\n",
    "\n",
    "    dfs: list = []\n",
    "    for level in AGG_LEVEL_COLUMNS:\n",
    "        agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "        group_names = '_'.join(agg_columns)\n",
    "        if group_names == '':\n",
    "            group_names = 'Total_X'\n",
    "\n",
    "        dfs.append(\n",
    "            f'../data/uncertainty/fold_{fold_name}/temp_submissions/' + f'lgb_multivariate_val_non_transposed_{group_names}_exclude_{exclude_columns}.csv',\n",
    "        )\n",
    "\n",
    "    return ensemble_submissions_uncertainty(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_columns = '_'.join([])\n",
    "# if exclude_columns == '':\n",
    "#     exclude_columns = 'None'\n",
    "\n",
    "# dfs: list = []\n",
    "# for level in AGG_LEVEL_COLUMNS:\n",
    "#     agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "#     group_names = '_'.join(agg_columns)\n",
    "#     if group_names == '':\n",
    "#         group_names = 'Total_X'\n",
    "        \n",
    "#     dfs.append(\n",
    "#         PREDICTION_BASE_PATH + f'lgb_multivariate_eval_non_transposed_{group_names}_exclude_{exclude_columns}.csv',\n",
    "#     )\n",
    "\n",
    "# df_sub_eval = ensemble_submissions_uncertainty(dfs)\n",
    "# transpose = True\n",
    "# if transpose == True:\n",
    "#     sub_evaluation = df_sub_eval.pivot(index='id', columns='d', values='pred').reset_index(drop=False)\n",
    "#     sub_evaluation.columns = [\"id\"] + [f\"F{i}\" for i in range(1,DAYS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sub_evaluation = pd.read_csv('../submissions/submission_baseline_evaluation.csv').drop(['Unnamed: 0'], axis=1)\n",
    "# pd.concat([sub_validation, sub_evaluation]).to_csv(SUBMISSION_BASE_PATH + f'submission_lgb_ensemble{exclude_columns}.csv', index=False)\n",
    "# del sub_validation; del sub_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Validation Prediction, we can compute WRMSSE locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these variables are used later on\n",
    "d = pd.read_parquet('../data/uncertainty/cv_template/temp.parquet')\n",
    "d_int = d['d'].str.split('_').apply(lambda x: int(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv(df: pd.DataFrame, df_sub: pd.DataFrame):\n",
    "    \n",
    "    # to be able to merge\n",
    "    df_sub['id_merge'] = df_sub['id'].str.split('.')\\\n",
    "        .apply(lambda x: x[0])\n",
    "    df_sub['quantile'] = df_sub['id'].str.split('.')\\\n",
    "        .apply(lambda x: float('.'.join([x[-2], x[-1].split('_')[0]])))\n",
    "\n",
    "    # merge predictions in cv template\n",
    "    p = pd.merge(\n",
    "        df,\n",
    "        df_sub,\n",
    "        how='left',\n",
    "        on=['id_merge', 'd']\n",
    "    )\n",
    "    # del df; del df_sub_val\n",
    "    p['id_merge'] = p['id_merge'].astype(str)\n",
    "\n",
    "    for c in ['sold', 'revenue']:\n",
    "        p[c] = p[c].astype(np.float32)\n",
    "    # d = d[d_int < (D_CV_START + 28)]\n",
    "\n",
    "    return WSPL(p, [f'd_{i}' for i in range(D_CV_START, D_CV_START + 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 11:01:20 - __main__ - INFO - --------------- ['seasonal', 'auto', 'momentum'] ---------------\n",
      "2023-08-23 11:01:32 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1802/temp_submissions/\n",
      "2023-08-23 11:02:23 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:02:23 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:02:55 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:03:02 - utils.metrics - INFO - Level1 - 0.5094243163667926\n",
      "2023-08-23 11:03:13 - utils.metrics - INFO - Level10 - 0.2974691040013057\n",
      "2023-08-23 11:03:47 - utils.metrics - INFO - Level11 - 0.2925593341513246\n",
      "2023-08-23 11:05:44 - utils.metrics - INFO - Level12 - 0.28617993644852113\n",
      "2023-08-23 11:05:44 - utils.metrics - INFO - Level2 - 0.41335436599424047\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level3 - 0.39246218255236165\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level4 - 0.4088971129355237\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level5 - 0.4194056690547897\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level6 - 0.4375510311627534\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level7 - 0.3907954511737379\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level8 - 0.36553621833229316\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level9 - 0.34526050295601973\n",
      "2023-08-23 11:05:52 - __main__ - INFO - 1802 - wspl: 0.3799079354274719\n",
      "2023-08-23 11:05:57 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1830/temp_submissions/\n",
      "2023-08-23 11:06:56 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:06:56 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:07:32 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:07:39 - utils.metrics - INFO - Level1 - 0.5415997159891802\n",
      "2023-08-23 11:07:50 - utils.metrics - INFO - Level10 - 0.3118867521987879\n",
      "2023-08-23 11:08:25 - utils.metrics - INFO - Level11 - 0.2937851951226946\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level12 - 0.3050911166458399\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level2 - 0.32010568198709466\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level3 - 0.36978150314645747\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level4 - 0.41060458902628244\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level5 - 0.3687130828653947\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level6 - 0.33081491808106106\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level7 - 0.3366365987835377\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level8 - 0.3047925519792386\n",
      "2023-08-23 11:10:29 - utils.metrics - INFO - Level9 - 0.33237765317725315\n",
      "2023-08-23 11:10:36 - __main__ - INFO - 1830 - wspl: 0.35218244658356856\n",
      "2023-08-23 11:10:40 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1858/temp_submissions/\n",
      "2023-08-23 11:11:38 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:11:38 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:12:12 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:12:20 - utils.metrics - INFO - Level1 - 0.2943017381600151\n",
      "2023-08-23 11:12:31 - utils.metrics - INFO - Level10 - 0.30288826775160727\n",
      "2023-08-23 11:13:06 - utils.metrics - INFO - Level11 - 0.28620971054666\n",
      "2023-08-23 11:15:07 - utils.metrics - INFO - Level12 - 0.29991271990272766\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level2 - 0.3624579924102846\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level3 - 0.36798301448813125\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level4 - 0.433688849398041\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level5 - 0.37661763889814726\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level6 - 0.3422735822692424\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level7 - 0.33408616146152786\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level8 - 0.32576719136307347\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level9 - 0.3308348820850935\n",
      "2023-08-23 11:15:16 - __main__ - INFO - 1858 - wspl: 0.3380851457278793\n",
      "2023-08-23 11:15:19 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1886/temp_submissions/\n",
      "2023-08-23 11:16:15 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:16:15 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:16:50 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:16:57 - utils.metrics - INFO - Level1 - 0.3633308108190663\n",
      "2023-08-23 11:17:09 - utils.metrics - INFO - Level10 - 0.2933981539888825\n",
      "2023-08-23 11:17:43 - utils.metrics - INFO - Level11 - 0.2862304002976008\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level12 - 0.3001748469437216\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level2 - 0.3515288970251534\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level3 - 0.34772943533066003\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level4 - 0.40403379344921475\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level5 - 0.41064645143106027\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level6 - 0.34449343445455327\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level7 - 0.3578890637811169\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level8 - 0.34057884237815733\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level9 - 0.319121427300331\n",
      "2023-08-23 11:19:48 - __main__ - INFO - 1886 - wspl: 0.3432629630999598\n",
      "2023-08-23 11:19:52 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1914/temp_submissions/\n",
      "2023-08-23 11:20:47 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:20:47 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:21:22 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:21:30 - utils.metrics - INFO - Level1 - 0.26114931458459384\n",
      "2023-08-23 11:21:41 - utils.metrics - INFO - Level10 - 0.27791292735675954\n",
      "2023-08-23 11:22:15 - utils.metrics - INFO - Level11 - 0.26659250693078723\n",
      "2023-08-23 11:24:15 - utils.metrics - INFO - Level12 - 0.26632866263415017\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level2 - 0.3465961818505697\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level3 - 0.3042461454413001\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level4 - 0.3767883544669268\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level5 - 0.3823450135491447\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level6 - 0.3260881519253884\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level7 - 0.3190495612495478\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level8 - 0.3053848606748176\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level9 - 0.3054618531816178\n",
      "2023-08-23 11:24:25 - __main__ - INFO - 1914 - wspl: 0.31149529448713364\n",
      "2023-08-23 11:24:25 - __main__ - INFO - 1914 - mean wspl: 0.34498675706520265 +/- 0.022106779123872475\n",
      "2023-08-23 11:24:25 - __main__ - INFO - 1914 - raw results: [0.3799079354274719, 0.35218244658356856, 0.3380851457278793, 0.3432629630999598, 0.31149529448713364]\n",
      "2023-08-23 11:24:25 - __main__ - INFO - --------------- ['auto', 'momentum'] ---------------\n",
      "2023-08-23 11:24:28 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1802/temp_submissions/\n",
      "2023-08-23 11:25:25 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:25:25 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:25:59 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:26:06 - utils.metrics - INFO - Level1 - 0.2317026538574037\n",
      "2023-08-23 11:26:17 - utils.metrics - INFO - Level10 - 0.2916661536097424\n",
      "2023-08-23 11:26:52 - utils.metrics - INFO - Level11 - 0.2810585579919864\n",
      "2023-08-23 11:28:50 - utils.metrics - INFO - Level12 - 0.28678906783182223\n",
      "2023-08-23 11:28:50 - utils.metrics - INFO - Level2 - 0.24638947981969986\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level3 - 0.27387834259810706\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level4 - 0.21760546479644452\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level5 - 0.3150004599099869\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level6 - 0.3223399679356197\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level7 - 0.3052157822001202\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level8 - 0.3248847597012523\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level9 - 0.31693789527120697\n",
      "2023-08-23 11:28:57 - __main__ - INFO - 1802 - wspl: 0.2844557154602827\n",
      "2023-08-23 11:29:01 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1830/temp_submissions/\n",
      "2023-08-23 11:29:56 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:29:56 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:30:30 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:30:37 - utils.metrics - INFO - Level1 - 0.3435708185799468\n",
      "2023-08-23 11:30:50 - utils.metrics - INFO - Level10 - 0.2956243926117087\n",
      "2023-08-23 11:31:29 - utils.metrics - INFO - Level11 - 0.2818383519765543\n",
      "2023-08-23 11:33:40 - utils.metrics - INFO - Level12 - 0.3022776377212882\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level2 - 0.21084223804123034\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level3 - 0.2466268074848912\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level4 - 0.28273583945890507\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level5 - 0.30446196777497203\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level6 - 0.2328859251735203\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level7 - 0.285448351669116\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level8 - 0.2434190031700636\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level9 - 0.2743202918565348\n",
      "2023-08-23 11:33:48 - __main__ - INFO - 1830 - wspl: 0.27533763545989426\n",
      "2023-08-23 11:33:51 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1858/temp_submissions/\n",
      "2023-08-23 11:34:50 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:34:50 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:35:27 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:35:36 - utils.metrics - INFO - Level1 - 0.23428793547877136\n",
      "2023-08-23 11:35:49 - utils.metrics - INFO - Level10 - 0.29087867349207874\n",
      "2023-08-23 11:36:27 - utils.metrics - INFO - Level11 - 0.27918063739859594\n",
      "2023-08-23 11:38:40 - utils.metrics - INFO - Level12 - 0.2917579925634804\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level2 - 0.19805506533240552\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level3 - 0.24963856529600328\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level4 - 0.3703047682737021\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level5 - 0.2525415131891123\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level6 - 0.25632805882106985\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level7 - 0.22537108993797045\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level8 - 0.24489828034780925\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level9 - 0.26215668873090453\n",
      "2023-08-23 11:38:49 - __main__ - INFO - 1858 - wspl: 0.2629499390718253\n",
      "2023-08-23 11:38:52 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1886/temp_submissions/\n",
      "2023-08-23 11:39:58 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:39:58 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:40:38 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:40:47 - utils.metrics - INFO - Level1 - 0.1459219538539635\n",
      "2023-08-23 11:41:00 - utils.metrics - INFO - Level10 - 0.28023551447133943\n",
      "2023-08-23 11:41:41 - utils.metrics - INFO - Level11 - 0.27478866565103244\n",
      "2023-08-23 11:43:53 - utils.metrics - INFO - Level12 - 0.29078434392245056\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level2 - 0.16200958782912497\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level3 - 0.18771726531764124\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level4 - 0.3917470835366255\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level5 - 0.275308420388723\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level6 - 0.21760255413399807\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level7 - 0.21181521773055875\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level8 - 0.20985644502367476\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level9 - 0.23140371950460617\n",
      "2023-08-23 11:44:01 - __main__ - INFO - 1886 - wspl: 0.2399325642803115\n",
      "2023-08-23 11:44:05 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1914/temp_submissions/\n",
      "2023-08-23 11:45:05 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:45:05 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:45:47 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:45:55 - utils.metrics - INFO - Level1 - 0.2513019360922543\n",
      "2023-08-23 11:46:07 - utils.metrics - INFO - Level10 - 0.26614146227268104\n",
      "2023-08-23 11:46:45 - utils.metrics - INFO - Level11 - 0.26127442458183503\n",
      "2023-08-23 11:48:53 - utils.metrics - INFO - Level12 - 0.26483872317408663\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level2 - 0.22494925554743278\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level3 - 0.23965821903255716\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level4 - 0.30132737675378357\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level5 - 0.30201066262965093\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level6 - 0.24959331723936853\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level7 - 0.25191802585809314\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level8 - 0.256621755920822\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level9 - 0.2549035258115886\n",
      "2023-08-23 11:49:02 - __main__ - INFO - 1914 - wspl: 0.26037822374284614\n",
      "2023-08-23 11:49:02 - __main__ - INFO - 1914 - mean wspl: 0.264610815603032 +/- 0.015090222978074668\n",
      "2023-08-23 11:49:02 - __main__ - INFO - 1914 - raw results: [0.2844557154602827, 0.27533763545989426, 0.2629499390718253, 0.2399325642803115, 0.26037822374284614]\n"
     ]
    }
   ],
   "source": [
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    [],\n",
    "    ['seasonal'],\n",
    "    ['auto'],\n",
    "    ['autoquantiles'],\n",
    "    ['momentum'],\n",
    ")\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    # ['seasonal'],\n",
    "    # ['momentum'],\n",
    "    # ['autoquantiles'],\n",
    "    ['seasonal', 'auto', 'momentum'],\n",
    "    ['auto', 'momentum'],\n",
    ")\n",
    "\n",
    "for EXCLUDE_COLUMNS in EXCLUDE_COLUMNS_LIST:\n",
    "    logger.info('--------------- ' + str(EXCLUDE_COLUMNS) + ' ---------------')\n",
    "    res = []\n",
    "    for D_CV_START in D_CROSS_VAL_START_LIST:\n",
    "        mean_wspl = perform_cv(_down_cast(d)[d_int < (D_CV_START + 28)], read_concat_predictions(D_CV_START, EXCLUDE_COLUMNS))\n",
    "        res.append(mean_wspl)\n",
    "        logger.info(str(D_CV_START) + ' - wspl: ' + str(mean_wspl))\n",
    "        \n",
    "    logger.info(str(D_CV_START) + ' - mean wspl: ' + str(np.mean(res)) + ' +/- ' + str(np.std(res)))\n",
    "    logger.info(str(D_CV_START) + ' - raw results: ' + str(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Beneath can be used to create submission template\n",
    "The submission template can be used to quickly insert your predictions.\n",
    "It also contains all other (historical) sales to be able to compute the WRMSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_validation = pd.read_csv(DATA_BASE_PATH + SALES_VALIDATION)\n",
    "sales_evaluation = pd.read_csv(DATA_BASE_PATH + SALES_EVALUATION)\n",
    "calendar = pd.read_csv(DATA_BASE_PATH + CALENDAR)\n",
    "sell_prices = pd.read_csv(DATA_BASE_PATH + SELL_PRICES)\n",
    "\n",
    "df_val, submission_idx_val = data_preprocessing(sales_validation, calendar, sell_prices)\n",
    "del sales_validation\n",
    "df_eval, submission_idx_eval = data_preprocessing(sales_evaluation, calendar, sell_prices)\n",
    "del sales_evaluation\n",
    "\n",
    "df_val_after_release = df_val[(df_val.wm_yr_wk > df_val.release)]# & (df_val[\"sold\"].notna())]\n",
    "del df_val\n",
    "df_eval_after_release = df_eval[(df_eval.wm_yr_wk > df_eval.release)]# & (df_eval[\"sold\"].notna())]\n",
    "del df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 17:27:39 - __main__ - INFO - Level1\n",
      "2023-08-17 17:27:40 - __main__ - INFO - Level2\n",
      "2023-08-17 17:27:44 - __main__ - INFO - Level3\n",
      "2023-08-17 17:27:48 - __main__ - INFO - Level4\n",
      "2023-08-17 17:27:51 - __main__ - INFO - Level5\n",
      "2023-08-17 17:27:55 - __main__ - INFO - Level6\n",
      "2023-08-17 17:28:00 - __main__ - INFO - Level7\n",
      "2023-08-17 17:28:05 - __main__ - INFO - Level8\n",
      "2023-08-17 17:28:10 - __main__ - INFO - Level9\n",
      "2023-08-17 17:28:15 - __main__ - INFO - Level10\n",
      "2023-08-17 17:28:21 - __main__ - INFO - Level11\n",
      "2023-08-17 17:28:33 - __main__ - INFO - Level12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>agg_column1</th>\n",
       "      <th>agg_column2</th>\n",
       "      <th>d</th>\n",
       "      <th>sold</th>\n",
       "      <th>revenue</th>\n",
       "      <th>id_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_10</td>\n",
       "      <td>24858.0</td>\n",
       "      <td>63029.78</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_100</td>\n",
       "      <td>23653.0</td>\n",
       "      <td>65665.71</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1000</td>\n",
       "      <td>29241.0</td>\n",
       "      <td>82351.45</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1001</td>\n",
       "      <td>33804.0</td>\n",
       "      <td>93975.55</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1002</td>\n",
       "      <td>42447.0</td>\n",
       "      <td>118961.96</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1003</td>\n",
       "      <td>40647.0</td>\n",
       "      <td>116052.48</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1004</td>\n",
       "      <td>32039.0</td>\n",
       "      <td>89314.17</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1005</td>\n",
       "      <td>29501.0</td>\n",
       "      <td>81688.96</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1006</td>\n",
       "      <td>31117.0</td>\n",
       "      <td>85754.15</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1007</td>\n",
       "      <td>27018.0</td>\n",
       "      <td>74244.86</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1008</td>\n",
       "      <td>39707.0</td>\n",
       "      <td>108637.04</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1009</td>\n",
       "      <td>47082.0</td>\n",
       "      <td>128940.24</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_101</td>\n",
       "      <td>24982.0</td>\n",
       "      <td>68908.04</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1010</td>\n",
       "      <td>48360.0</td>\n",
       "      <td>133218.73</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1011</td>\n",
       "      <td>32930.0</td>\n",
       "      <td>92274.15</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1012</td>\n",
       "      <td>33990.0</td>\n",
       "      <td>92743.98</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1013</td>\n",
       "      <td>32956.0</td>\n",
       "      <td>90505.80</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1014</td>\n",
       "      <td>31862.0</td>\n",
       "      <td>87172.76</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1015</td>\n",
       "      <td>35365.0</td>\n",
       "      <td>95702.83</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1016</td>\n",
       "      <td>45705.0</td>\n",
       "      <td>125791.89</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1017</td>\n",
       "      <td>43898.0</td>\n",
       "      <td>123256.45</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1018</td>\n",
       "      <td>36385.0</td>\n",
       "      <td>100212.69</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1019</td>\n",
       "      <td>32258.0</td>\n",
       "      <td>87909.01</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_102</td>\n",
       "      <td>22196.0</td>\n",
       "      <td>60000.65</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1020</td>\n",
       "      <td>29242.0</td>\n",
       "      <td>81367.81</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1021</td>\n",
       "      <td>29452.0</td>\n",
       "      <td>79956.86</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1022</td>\n",
       "      <td>35763.0</td>\n",
       "      <td>97645.15</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1023</td>\n",
       "      <td>44579.0</td>\n",
       "      <td>123721.42</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1024</td>\n",
       "      <td>42582.0</td>\n",
       "      <td>121478.81</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1025</td>\n",
       "      <td>32102.0</td>\n",
       "      <td>89627.71</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1026</td>\n",
       "      <td>28521.0</td>\n",
       "      <td>78796.16</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1027</td>\n",
       "      <td>27904.0</td>\n",
       "      <td>78144.16</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1028</td>\n",
       "      <td>28693.0</td>\n",
       "      <td>78581.27</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1029</td>\n",
       "      <td>32847.0</td>\n",
       "      <td>91347.72</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_103</td>\n",
       "      <td>22117.0</td>\n",
       "      <td>61407.00</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1030</td>\n",
       "      <td>40046.0</td>\n",
       "      <td>114533.56</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1031</td>\n",
       "      <td>38445.0</td>\n",
       "      <td>111826.12</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1032</td>\n",
       "      <td>28603.0</td>\n",
       "      <td>81092.24</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1033</td>\n",
       "      <td>31247.0</td>\n",
       "      <td>87799.42</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1034</td>\n",
       "      <td>36053.0</td>\n",
       "      <td>97214.80</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1035</td>\n",
       "      <td>19783.0</td>\n",
       "      <td>53456.88</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1036</td>\n",
       "      <td>26041.0</td>\n",
       "      <td>75086.93</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1037</td>\n",
       "      <td>31539.0</td>\n",
       "      <td>91356.80</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1038</td>\n",
       "      <td>38182.0</td>\n",
       "      <td>108919.39</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1039</td>\n",
       "      <td>37079.0</td>\n",
       "      <td>97503.03</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_104</td>\n",
       "      <td>22347.0</td>\n",
       "      <td>60736.91</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1040</td>\n",
       "      <td>38010.0</td>\n",
       "      <td>100557.02</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1041</td>\n",
       "      <td>31513.0</td>\n",
       "      <td>83895.82</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1042</td>\n",
       "      <td>35139.0</td>\n",
       "      <td>93359.95</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1043</td>\n",
       "      <td>36894.0</td>\n",
       "      <td>99430.98</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Level agg_column1 agg_column2       d     sold    revenue id_merge\n",
       "0   Level1       Total           X    d_10  24858.0   63029.78  Total_X\n",
       "1   Level1       Total           X   d_100  23653.0   65665.71  Total_X\n",
       "2   Level1       Total           X  d_1000  29241.0   82351.45  Total_X\n",
       "3   Level1       Total           X  d_1001  33804.0   93975.55  Total_X\n",
       "4   Level1       Total           X  d_1002  42447.0  118961.96  Total_X\n",
       "5   Level1       Total           X  d_1003  40647.0  116052.48  Total_X\n",
       "6   Level1       Total           X  d_1004  32039.0   89314.17  Total_X\n",
       "7   Level1       Total           X  d_1005  29501.0   81688.96  Total_X\n",
       "8   Level1       Total           X  d_1006  31117.0   85754.15  Total_X\n",
       "9   Level1       Total           X  d_1007  27018.0   74244.86  Total_X\n",
       "10  Level1       Total           X  d_1008  39707.0  108637.04  Total_X\n",
       "11  Level1       Total           X  d_1009  47082.0  128940.24  Total_X\n",
       "12  Level1       Total           X   d_101  24982.0   68908.04  Total_X\n",
       "13  Level1       Total           X  d_1010  48360.0  133218.73  Total_X\n",
       "14  Level1       Total           X  d_1011  32930.0   92274.15  Total_X\n",
       "15  Level1       Total           X  d_1012  33990.0   92743.98  Total_X\n",
       "16  Level1       Total           X  d_1013  32956.0   90505.80  Total_X\n",
       "17  Level1       Total           X  d_1014  31862.0   87172.76  Total_X\n",
       "18  Level1       Total           X  d_1015  35365.0   95702.83  Total_X\n",
       "19  Level1       Total           X  d_1016  45705.0  125791.89  Total_X\n",
       "20  Level1       Total           X  d_1017  43898.0  123256.45  Total_X\n",
       "21  Level1       Total           X  d_1018  36385.0  100212.69  Total_X\n",
       "22  Level1       Total           X  d_1019  32258.0   87909.01  Total_X\n",
       "23  Level1       Total           X   d_102  22196.0   60000.65  Total_X\n",
       "24  Level1       Total           X  d_1020  29242.0   81367.81  Total_X\n",
       "25  Level1       Total           X  d_1021  29452.0   79956.86  Total_X\n",
       "26  Level1       Total           X  d_1022  35763.0   97645.15  Total_X\n",
       "27  Level1       Total           X  d_1023  44579.0  123721.42  Total_X\n",
       "28  Level1       Total           X  d_1024  42582.0  121478.81  Total_X\n",
       "29  Level1       Total           X  d_1025  32102.0   89627.71  Total_X\n",
       "30  Level1       Total           X  d_1026  28521.0   78796.16  Total_X\n",
       "31  Level1       Total           X  d_1027  27904.0   78144.16  Total_X\n",
       "32  Level1       Total           X  d_1028  28693.0   78581.27  Total_X\n",
       "33  Level1       Total           X  d_1029  32847.0   91347.72  Total_X\n",
       "34  Level1       Total           X   d_103  22117.0   61407.00  Total_X\n",
       "35  Level1       Total           X  d_1030  40046.0  114533.56  Total_X\n",
       "36  Level1       Total           X  d_1031  38445.0  111826.12  Total_X\n",
       "37  Level1       Total           X  d_1032  28603.0   81092.24  Total_X\n",
       "38  Level1       Total           X  d_1033  31247.0   87799.42  Total_X\n",
       "39  Level1       Total           X  d_1034  36053.0   97214.80  Total_X\n",
       "40  Level1       Total           X  d_1035  19783.0   53456.88  Total_X\n",
       "41  Level1       Total           X  d_1036  26041.0   75086.93  Total_X\n",
       "42  Level1       Total           X  d_1037  31539.0   91356.80  Total_X\n",
       "43  Level1       Total           X  d_1038  38182.0  108919.39  Total_X\n",
       "44  Level1       Total           X  d_1039  37079.0   97503.03  Total_X\n",
       "45  Level1       Total           X   d_104  22347.0   60736.91  Total_X\n",
       "46  Level1       Total           X  d_1040  38010.0  100557.02  Total_X\n",
       "47  Level1       Total           X  d_1041  31513.0   83895.82  Total_X\n",
       "48  Level1       Total           X  d_1042  35139.0   93359.95  Total_X\n",
       "49  Level1       Total           X  d_1043  36894.0   99430.98  Total_X"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "df_eval_after_release['revenue'] = df_eval_after_release['sold'] * df_eval_after_release['sell_price']\n",
    "for level in list(AGG_LEVEL_COLUMNS.keys()):\n",
    "    c = AGG_LEVEL_COLUMNS[level]\n",
    "    logger.info(level)\n",
    "    agg_dict = {\n",
    "        'sold': 'sum',\n",
    "        'revenue': 'sum'\n",
    "    }\n",
    "    d1 = df_eval_after_release.groupby(c + ['d']).agg(agg_dict).reset_index(drop=False)\n",
    "    d = pd.DataFrame({\n",
    "        'd': d1['d'],\n",
    "        'sold': d1['sold'],\n",
    "        'revenue': d1['revenue']\n",
    "    })\n",
    "    if len(c) == 0:\n",
    "        d['agg_column1'] = 'Total'\n",
    "        d['agg_column2'] = 'X'\n",
    "    elif len(c) == 1:\n",
    "        d['agg_column1'] = d1[c[0]]\n",
    "        d['agg_column2'] = 'X'\n",
    "    else:\n",
    "        d['agg_column1'] = d1[c[0]]\n",
    "        d['agg_column2'] = d1[c[1]]\n",
    "    d['id_merge'] = d['agg_column1'] + '_' + d['agg_column2']\n",
    "    d['Level'] = level\n",
    "    dfs.append(d[['Level', 'agg_column1', 'agg_column2', 'd', 'sold', 'revenue', 'id_merge']])\n",
    "d = pd.concat(dfs)\n",
    "d.head(50)\n",
    "d.to_parquet('temp.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open('test.txt')\n",
    "# file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
