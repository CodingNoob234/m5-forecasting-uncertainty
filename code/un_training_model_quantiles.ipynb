{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import lightgbm as lgb\n",
    "from utils.utils import _down_cast, data_preprocessing, diff_lists, log_status\n",
    "from utils.utils import ensemble_submissions, ensemble_submissions_uncertainty\n",
    "from utils.metrics import WSPL\n",
    "from utils.configure_logger import configure_logger\n",
    "from utils.utils import prefixes_in_column\n",
    "from utils import constants\n",
    "\n",
    "configure_logger()\n",
    "from logging import getLogger\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_PATH = constants.DATA_BASE_PATH #'../data/m5-forecasting-accuracy/'\n",
    "DATA_BASE_PATH_UNCERTAINTY = constants.DATA_BASE_PATH_UNCERTAINTY #'../data/m5-forecasting-uncertainty/'\n",
    "SALES_EVALUATION = constants.SALES_EVALUATION \n",
    "SALES_VALIDATION = constants.SALES_VALIDATION\n",
    "CALENDAR = constants.CALENDAR \n",
    "SAMPLE_SUBMISSION = constants.SAMPLE_SUBMISSION \n",
    "SELL_PRICES = constants.SELL_PRICES\n",
    "\n",
    "PRECOMPUTED_BASE_PATH = constants.PRECOMPUTED_BASE_PATH #'../data/uncertainty/features/'\n",
    "\n",
    "DAYS: int = constants.DAYS #28\n",
    "QUANTILES: int = constants.QUANTILES \n",
    "\n",
    "AGG_LEVEL_COLUMNS = constants.AGG_LEVEL_COLUMNS\n",
    "D_CROSS_VAL_START_LIST = constants.D_CROSS_VAL_START_LIST\n",
    "\n",
    "# to simple get the precomputed name\n",
    "precomputed_name = lambda store, eval_val: f'processed_{store}_{eval_val}.pkl'\n",
    "\n",
    "TEST_PATH = constants.TEST_PATH#'test/'\n",
    "PREDICTION_BASE_PATH = constants.PREDICTION_BASE_PATH #'../data/uncertainty/temp_submissions/'\n",
    "SUBMISSION_BASE_PATH = constants.SUBMISSION_BASE_PATH #'../data/uncertainty/final_submissions/'\n",
    "\n",
    "SUB_D_START_VAL: int = constants.SUB_D_START_VAL\n",
    "SUB_D_START_EVAL: int = constants.SUB_D_START_EVAL\n",
    "\n",
    "# the columns are always included after feature processing\n",
    "# because they are required in the training and submission format\n",
    "DROP_FEATURE_COLUMNS: list = constants.DROP_FEATURE_COLUMNS #['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'd', 'sold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GridSearch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_status\n",
    "def grid_search(params: dict, param_grid: dict, features, targets, n_folds: int = 1):\n",
    "    \"\"\" \n",
    "    Given a grid with parameters, train lgb model for all possible combinations.\n",
    "    Returns the parameter set with the best score and the dictionary with all results.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    # to be sure\n",
    "    features = features.reset_index(drop=True)\n",
    "    targets = targets.reset_index(drop=True)\n",
    "\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "    results = {}\n",
    "    for i, param_combination in enumerate(param_combinations,1):\n",
    "        \n",
    "        # create dictionary with all parameters\n",
    "        param_combination = {k:v for k,v in zip(param_grid.keys(), param_combination)}\n",
    "        param_combination.update(params)\n",
    "                \n",
    "        # init dict\n",
    "        results[f\"combination_{i}\"] = {\n",
    "            'params': param_combination,\n",
    "            'res': []\n",
    "        }\n",
    "        \n",
    "        # perform n_folds\n",
    "        for j in range(n_folds):\n",
    "            \n",
    "            # kfold\n",
    "            features_train, features_validation, targets_train, targets_validation =\\\n",
    "                train_test_split(features, targets, train_size = .8, shuffle=True)#, random_state=42)\n",
    "\n",
    "            # train lgb model        \n",
    "            temp_dict = {} # this dict object will be used to add all (intermediate) evaluation scores during the training process\n",
    "            mod: lgb.Booster = lgb.train(param_combination, \n",
    "                train_set = lgb.Dataset(features_train, targets_train),\n",
    "                valid_sets = lgb.Dataset(features_validation, targets_validation),\n",
    "                evals_result = temp_dict,\n",
    "                verbose_eval=False\n",
    "            )\n",
    "            \n",
    "            # store results\n",
    "            results[f\"combination_{i}\"]['res']\\\n",
    "                .append(temp_dict[\"valid_0\"][\"quantile\"][-1],\n",
    "                )\n",
    "\n",
    "        # compute average results\n",
    "        results[f\"combination_{i}\"]['validation_score'] = \\\n",
    "            np.mean(results[f\"combination_{i}\"]['res'])\n",
    "            \n",
    "        # REMOVE\n",
    "        p = results[f\"combination_{i}\"]['params']\n",
    "        logger.info(f\"{p['learning_rate']} - {p['num_leaves']} - {p['n_estimators']}\" + ' - score: ' + str(np.mean(results[f\"combination_{i}\"]['res'])) + ' ' + str(np.std(results[f\"combination_{i}\"]['res'])))\n",
    "        # REMOVE\n",
    "        \n",
    "    # sort the results based on evaluation score\n",
    "    sorted_results = dict(sorted(results.items(), key=lambda item: item[1][\"validation_score\"]))\n",
    "    return list(sorted_results.values())[0], results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData:\n",
    "    \"\"\" Class to load data \"\"\"\n",
    "    def __init__(self):\n",
    "        self.level = None\n",
    "        \n",
    "    def prep_data(self,level, sub_d_start):\n",
    "        \"\"\" read the precomputed features and targets for specified aggregation level,  \"\"\"\n",
    "        # define params\n",
    "        agg_level = level\n",
    "        # sub_d_start: int = int(1886)\n",
    "        exclude_columns = []\n",
    "        test = False\n",
    "        type_of = 'val'\n",
    "\n",
    "        # read file\n",
    "        agg_columns = AGG_LEVEL_COLUMNS[agg_level]\n",
    "        if len(agg_columns) == 0:\n",
    "            agg_str: str = 'Total_X'\n",
    "        elif len(agg_columns) == 1:\n",
    "            agg_str: str = f'{agg_columns[0]}_X'\n",
    "        else:\n",
    "            agg_str: str = '_'.join(agg_columns)\n",
    "\n",
    "        if self.level == level:\n",
    "            pass\n",
    "        else:\n",
    "            logger.info('(re)loading features')\n",
    "            features = pd.read_parquet(f'../data/uncertainty/fold_{sub_d_start}/features/' + (TEST_PATH if test else '') + f'features_{type_of}_{agg_str}.parquet')\n",
    "            features = _down_cast(features)\n",
    "\n",
    "        group_columns = agg_columns\n",
    "        exclude_prefix_list = exclude_columns # unconditional, auto, momentum, seasonal\n",
    "        \n",
    "        features_gr = features.copy()\n",
    "        features_gr = features_gr[[c for c in features_gr if c.split('_')[0] not in exclude_prefix_list]]\n",
    "\n",
    "        # preparations\n",
    "        train_idx = features_gr['sold'].notna() & features_gr['d'].isin([f'd_{sub_d_start - 1 - i}' for i in range(1460)])\n",
    "        df_train = features_gr[train_idx]\n",
    "        features_train: pd.DataFrame = df_train.drop(DROP_FEATURE_COLUMNS, axis = 1, errors = 'ignore')\n",
    "        targets_train: pd.Series = df_train['sold']\n",
    "        return features_train, targets_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Training a Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 19:45:16 - __main__ - INFO - (re)loading features\n"
     ]
    }
   ],
   "source": [
    "# load data example, to investigate which features are computed, among other things\n",
    "level = 'Level2'\n",
    "dataLoader = LoadData()\n",
    "features, targets = dataLoader.prep_data(level, 1914)\n",
    "# list(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold\n",
    "prefixes = ['seasonal', 'auto_sold_ewm']\n",
    "features_train, features_validation, targets_train, targets_validation =\\\n",
    "    train_test_split(features, targets, test_size = 28, shuffle=False, random_state=42)\n",
    "    # train_test_split(features[[c for c in features.columns if prefixes_in_column(c, prefixes)]], targets, train_size = .8, shuffle=False, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    # 'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -100,\n",
    "    'n_jobs': 4,\n",
    "    # 'subsample': .9,\n",
    "    # 'subsample_freq': 1,\n",
    "    \"num_leaves\": 30,\n",
    "    \"min_child_weight\": .1,\n",
    "    \"min_child_samples\": 4,\n",
    "    \"hist_pool_size\": 1000,\n",
    "    'feature_fraction': 0.9, #.5\n",
    "    # 'bagging_fraction': .8,\n",
    "    \"learning_rate\": 0.005, #0.07,\n",
    "    \"n_estimators\": 2000,#100\n",
    "    \"max_depth\": 10,\n",
    "    # 'reg_sqrt': True,\n",
    "    # 'req_lambda': .00001,\n",
    "    # 'reg_alpha': .00001,\n",
    "    'alpha': .25,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# # train lgb model       \n",
    "# for q in [0.005, 0.025, 0.135, 0.25, 0.5, 0.75, 0.865, 0.975, 0.995]:\n",
    "#     params['alpha'] = q \n",
    "#     temp_dict = {}\n",
    "#     mod: lgb.Booster = lgb.train(params, \n",
    "#         train_set = lgb.Dataset(features_train, targets_train),\n",
    "#         valid_sets = lgb.Dataset(features_validation, targets_validation),\n",
    "#         evals_result = temp_dict,\n",
    "#         verbose_eval = False\n",
    "#     )\n",
    "#     plt.plot(mod.predict(features_validation), label = f'{q}')\n",
    "\n",
    "# plt.scatter(range(len(targets_validation.index)), targets_validation, label = 'true', s = 10)\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total ~280 seconds\n",
    "lgb_quantile_params = {     # fairly well tuned, with high runtimes \n",
    "    'max_depth': [10, 20],\n",
    "    'n_estimators': [ 150, 200, 200],  # 300, 350, 400, ],   \n",
    "    'min_split_gain': [0, 0, 0, 0, 1e-4, 1e-3, 1e-2, 0.1],\n",
    "    'min_child_samples': [ 2, 4, 7, 10, 14, 20, 30, 40, 60, 80, 100, 100, 100, \n",
    "                                        130, 170, 200, 300, 500, 700, 1000 ],\n",
    "    'min_child_weight': [0, 0, 0, 0, 1e-4, 1e-3, 1e-3, 1e-3, 5e-3, 2e-2, 0.1 ],\n",
    "    'num_leaves': [ 20, 30, 50, 50 ], # 50, 70, 90, ],\n",
    "    'learning_rate': [  0.04, 0.05, 0.07, 0.07, 0.07, 0.1, 0.1, 0.1 ],   # 0.02, 0.03,        \n",
    "    'colsample_bytree': [0.3, 0.5, 0.7, 0.8, 0.9, 0.9, 0.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \n",
    "    'colsample_bynode':[0.1, 0.15, 0.2, 0.2, 0.2, 0.25, 0.3, 0.5, 0.65, 0.8, 0.9, 1],\n",
    "    'reg_lambda': [0, 0, 0, 0, 1e-5, 1e-5, 1e-5, 1e-5, 3e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 10, 100   ],\n",
    "    'reg_alpha': [0, 1e-5, 3e-5, 1e-4, 1e-4, 1e-3, 3e-3, 1e-2, 0.1, 1, 1, 10, 10, 100, 1000,],\n",
    "    'subsample': [  0.9, 1],\n",
    "    'subsample_freq': [1],\n",
    "    'cat_smooth': [0.1, 0.2, 0.5, 1, 2, 5, 7, 10],\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    # 'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': 4,\n",
    "    # 'eval_at': 10,\n",
    "    'hist_pool_size': 1000,\n",
    "    # 'verbose_eval': 0\n",
    "    # 'subsample': 0.5,\n",
    "    # 'subsample_freq': 1,\n",
    "    # 'feature_fraction': 0.5,\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [10],\n",
    "    'n_estimators': [200, 800],\n",
    "    # 'min_split_gain': [0, 0, 0, 0, 1e-4, 1e-3, 1e-2, 0.1],\n",
    "    'min_child_samples': [4],\n",
    "    'min_child_weight': [0.1 ],\n",
    "    'num_leaves': [30], # 50, 70, 90, ],\n",
    "    'learning_rate': [0.001, 0.005, 0.01 ],   # 0.02, 0.03,        \n",
    "    # 'colsample_bytree': [0.3, 0.5, 0.7, 0.8, 0.9, 0.9, 0.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \n",
    "    # 'colsample_bynode':[0.1, 0.15, 0.2, 0.2, 0.2, 0.25, 0.3, 0.5, 0.65, 0.8, 0.9, 1],\n",
    "    # 'reg_lambda': [0, 1e-5, 1e-5, 1e-4, 1e-2, 1, 10, ],\n",
    "    # 'reg_alpha': [0, 1e-5, 3e-5, 1e-4, 1e-3, 1e-2, 1, 10, 100, 1000,],\n",
    "    'subsample': [  0.9, 1],\n",
    "    'subsample_freq': [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test grid search for all quantiles\n",
    "# for q in QUANTILES[:5]:\n",
    "    \n",
    "#     # of course, update quantile in params\n",
    "#     params['alpha'] = q\n",
    "#     best_res, res = grid_search(params, param_grid, features_train, targets_train, 1)\n",
    "#     logger.info(best_res['params'])\n",
    "    \n",
    "#     mod = lgb.train(best_res['params'],\n",
    "#         train_set = lgb.Dataset(features_train, targets_train)\n",
    "#     )\n",
    "#     predictions = mod.predict(features_validation)\n",
    "#     plt.plot(predictions, label = str(q))\n",
    "\n",
    "# plt.scatter(range(len(targets_validation)), targets_validation)\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train + Predict submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_level_all_quantiles(\n",
    "    agg_level: str, \n",
    "    type_of: str, \n",
    "    sub_d_start: int, \n",
    "    exclude_columns: list = [], \n",
    "    include_columns: list = None,\n",
    "    test: bool = False, \n",
    "    do_grid_search: bool = False, \n",
    "    store_submissions_path: str = None, \n",
    "    normalize: bool = False,\n",
    "):\n",
    "    \"\"\" \n",
    "    Train, for a specific aggregation level, models for all quantiles.\n",
    "    For aggregation levels 10, 11 and 12, undersampling is used to drastically reduce training time.\n",
    "    \"\"\"\n",
    "    ALWAYS_KEEP_COLUMNS = ['days_fwd', 'sold', 'd']\n",
    "    \n",
    "    agg_columns = AGG_LEVEL_COLUMNS[agg_level]\n",
    "    if len(agg_columns) == 0:\n",
    "        agg_str: str = 'Total_X'\n",
    "    elif len(agg_columns) == 1:\n",
    "        agg_str: str = f'{agg_columns[0]}_X'\n",
    "    else:\n",
    "        agg_str: str = '_'.join(agg_columns)\n",
    "\n",
    "    # try:\n",
    "    #     features = pd.DataFrame(features)\n",
    "    # except Exception:\n",
    "    # loading features\n",
    "    logger.info('(re)loading features')\n",
    "    features = pd.read_parquet(f'../data/uncertainty/fold_{sub_d_start}/features/' + (TEST_PATH if test else '') + f'features_{type_of}_{agg_str}.parquet')\n",
    "    features = _down_cast(features)\n",
    "    features_gr = features.copy()\n",
    "    \n",
    "    # preparations\n",
    "    # sub_d_start = SUB_D_START_VAL if type_of == 'val' else SUB_D_START_EVAL\n",
    "    train_idx = features_gr['sold'].notna() & features_gr['d'].isin([f'd_{sub_d_start - 1 - i}' for i in range(1300)])\n",
    "    pred_idx = features_gr['d'].isin([f'd_{sub_d_start + i}' for i in range(DAYS)])\n",
    "\n",
    "    group_columns = agg_columns\n",
    "    res: list = []\n",
    "    \n",
    "    def check_any_prefix_matches(column, prefixes):\n",
    "        \"\"\" Return true if any prefix is in column \"\"\"\n",
    "        # print(column, prefixes, prefixes[0] in column)\n",
    "        for prefix in prefixes:\n",
    "            if prefix in column:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # select features\n",
    "    if USE_ALL or 'kbest' in include_columns:\n",
    "        columns = features_gr.columns\n",
    "    elif SPARSE_FEATURES:\n",
    "        columns = [c for c in features_gr.columns if c in SPARSE_FEATURES]\n",
    "    elif include_columns == None:\n",
    "        # exclude features from exclusion prefix list\n",
    "        exclude_prefix_list = exclude_columns \n",
    "        # columns = [c for c in features_gr.columns if c.split('_')[0] not in exclude_prefix_list]\n",
    "        columns = [c for c in features_gr.columns if not check_any_prefix_matches(c, exclude_prefix_list)]\n",
    "    elif isinstance(include_columns, list):\n",
    "        include_prefix_list = include_columns\n",
    "        # columns = [c for c in features_gr.columns if c.split('_')[0] in include_prefix_list]\n",
    "        columns = [c for c in features_gr.columns if check_any_prefix_matches(c, include_prefix_list)]\n",
    "\n",
    "    for column in ALWAYS_KEEP_COLUMNS + group_columns:\n",
    "        if column not in columns:\n",
    "            columns.append(column) \n",
    "\n",
    "    features_gr = features_gr[columns]\n",
    "    df_pred = features_gr[pred_idx]\n",
    "    df_train = features_gr[train_idx]\n",
    "    if agg_level not in ['Level9', 'Level10', 'Level11', 'Level12']:\n",
    "        df_train = df_train[df_train['sold'] >= 50]\n",
    "\n",
    "    from copy import deepcopy\n",
    "    temp_drop_feature_columns = deepcopy(DROP_FEATURE_COLUMNS)\n",
    "    if not USE_ALL and 'kbest' not in include_columns:\n",
    "        if 'state_id' in include_prefix_list:\n",
    "            temp_drop_feature_columns.remove('state_id')\n",
    "        if 'store_id' in include_prefix_list:\n",
    "            temp_drop_feature_columns.remove('store_id')\n",
    "    if USE_ALL or 'kbest' in include_columns:\n",
    "        temp_drop_feature_columns.remove('state_id')\n",
    "        temp_drop_feature_columns.remove('store_id')\n",
    "        \n",
    "    features_train: pd.DataFrame = df_train.drop(temp_drop_feature_columns, axis = 1, errors = 'ignore')\n",
    "    # logger.info(f'feature: {str(features_train.columns)}')\n",
    "    targets_train: pd.Series = df_train['sold']\n",
    "    features_predict: pd.DataFrame = df_pred.drop(temp_drop_feature_columns, axis = 1, errors = 'ignore')\n",
    "    targets_test: pd.Series = df_pred['sold']\n",
    "    \n",
    "    #### SELECT FEATURES ####\n",
    "    if 'kbest' in include_columns:\n",
    "        # cannot do selectkbest for category variables\n",
    "        exclude_from_kbest = ['state_id', 'store_id', 'seasonal_weekday', 'seasonal_monthday', 'seasonal_month', 'days_fwd']\n",
    "        # temp_drop_idx = features_train.notna().all(axis=1)\n",
    "        temp_drop_idx = features_train.drop(exclude_from_kbest, axis=1, errors='ignore').fillna(0).notna().all(axis=1)\n",
    "        from sklearn import metrics\n",
    "        from sklearn import feature_selection\n",
    "        fit = SelectKBest(\n",
    "                k=5,\n",
    "                # score_func=metrics.mean_pinball_loss\n",
    "                score_func=feature_selection.f_regression\n",
    "            ).fit(\n",
    "                features_train.drop(exclude_from_kbest, axis=1, errors='ignore').fillna(0)[temp_drop_idx], \n",
    "                targets_train[temp_drop_idx]\n",
    "            )\n",
    "        # print(fit.get_feature_names_out())\n",
    "        features_keep = list(fit.get_feature_names_out())\n",
    "        for c in exclude_from_kbest:\n",
    "            if c in features_train.columns:\n",
    "                features_keep.append(c)\n",
    "        print(features_keep)\n",
    "        features_train = features_train[features_keep]\n",
    "        features_predict = features_predict[features_keep]\n",
    "    #### SELECT FEATURES ####\n",
    "    \n",
    "    # undersample data\n",
    "    if agg_level in undersampling_dict.keys() and HIGH_UNDERSAMPLING:\n",
    "        undersampling_pct = undersampling_dict[agg_level]\n",
    "        features_train, _, targets_train, _ = train_test_split(features_train, targets_train, train_size = undersampling_pct, shuffle=True, random_state=43)\n",
    "\n",
    "    # normalise targets\n",
    "    if normalize:\n",
    "        logger.info('scaling targets')\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        targets_train = scaler.fit_transform(targets_train.values.reshape(-1,1))\n",
    "        \n",
    "    # REMOVE THIS\n",
    "    import matplotlib.pyplot as plt\n",
    "    if PLOT_PREDICTIONS:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (10,5))\n",
    "        aaa = [i for i in range(targets_test.shape[0])]\n",
    "    # REMOVE THIS\n",
    "        \n",
    "    # train model for all quantiles\n",
    "    for quantile in QUANTILES:\n",
    "        \n",
    "        # perform grid search for best parameters\n",
    "        if do_grid_search == True:\n",
    "            # split data to training and testing\n",
    "            logger.info('perform gridsearch')\n",
    "            params['alpha'] = quantile\n",
    "            best_combination, results = grid_search(params, param_grid, features_train, targets_train, n_folds = 5)\n",
    "            # del train_data; del validation_data\n",
    "            params_grid_train = best_combination[\"params\"]\n",
    "            logger.info(f'q: {quantile} - cv best params: {params_grid_train}')\n",
    "        else:\n",
    "            params_grid_train = PARAM_GRID_TRAIN\n",
    "            params_grid_train['alpha'] = quantile\n",
    "\n",
    "        # train_best_model\n",
    "        # logger.info(f'features: {str(features_train.columns)}')\n",
    "        mod = lgb.train(params_grid_train,\n",
    "            train_set = lgb.Dataset(features_train, targets_train)\n",
    "        )\n",
    "        # save model\n",
    "        group_names = '_'.join(group_columns)\n",
    "        if group_names == '':\n",
    "            group_names = 'Total_X'\n",
    "        if USE_ALL:\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + 'models/' + f'lgb_{type_of}_nt_{group_names}_use_all_q={quantile}.joblib'\n",
    "        elif 'kbest' in include_columns:\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + 'models/' + f'lgb_{type_of}_nt_{group_names}_include_k_best_q={quantile}.joblib'\n",
    "        elif SPARSE_FEATURES:\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + 'models/' + f'lgb_{type_of}_nt_{group_names}_sparse_q={quantile}.joblib' \n",
    "        elif include_columns == None:\n",
    "            exclude_names = 'None' if len(exclude_prefix_list) == 0 else '_'.join(exclude_prefix_list)\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + 'models/' + f'lgb_{type_of}_nt_{group_names}_exclude_{exclude_names}_q={quantile}.joblib'\n",
    "        elif isinstance(include_columns, list):\n",
    "            exclude_names = 'None' if len(include_prefix_list) == 0 else '_'.join(include_prefix_list)\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + 'models/' + f'lgb_{type_of}_nt_{group_names}_include_{exclude_names}_q={quantile}.joblib'\n",
    "\n",
    "        import joblib\n",
    "        joblib.dump(mod, file_path)\n",
    "        \n",
    "        predictions = mod.predict(features_predict)\n",
    "        if normalize:\n",
    "            predictions = scaler.inverse_transform(predictions.reshape(-1,1)).reshape(-1,)\n",
    "        \n",
    "        # REMOVE THIS\n",
    "        if PLOT_PREDICTIONS:\n",
    "            ax.plot(aaa, predictions, label = f'{quantile}')\n",
    "        # REMOVE THIS\n",
    "        \n",
    "        # store predictions\n",
    "        df_p = pd.DataFrame(\n",
    "            {\n",
    "                'pred': predictions,\n",
    "                'd': df_pred['d'],\n",
    "            }\n",
    "        )\n",
    "        df_p['quantile'] = quantile\n",
    "        df_p['Level'] = agg_level\n",
    "        df_p['type_of'] = 'validation' if type_of == 'val' else 'evaluation'\n",
    "        if len(agg_columns) == 0:\n",
    "            df_p['agg_column1'] = 'Total'\n",
    "            df_p['agg_column2'] = 'X'\n",
    "        elif len(agg_columns) == 1:\n",
    "            df_p['agg_column1'] = df_pred[agg_columns[0]].values\n",
    "            df_p['agg_column2'] = 'X'\n",
    "        else:\n",
    "            df_p['agg_column1'] = df_pred[agg_columns[0]].values\n",
    "            df_p['agg_column2'] = df_pred[agg_columns[1]].values\n",
    "            \n",
    "        df_p = df_p[['Level', 'agg_column1', 'agg_column2', 'd', 'quantile', 'pred', 'type_of']]\n",
    "        \n",
    "        res.append(_down_cast(df_p))\n",
    "        \n",
    "    # REMOVE THIS\n",
    "    if PLOT_PREDICTIONS:\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        plt.show()\n",
    "    # REMOVE THIS\n",
    "        \n",
    "    # remove to reduce memory usage asap\n",
    "    del features\n",
    "        \n",
    "    # storing predictions in specified file + folder\n",
    "    df_sub_val = pd.concat(res)\n",
    "    group_names = '_'.join(group_columns)\n",
    "    if group_names == '':\n",
    "        group_names = 'Total_X'\n",
    "        \n",
    "    if USE_ALL:\n",
    "        file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_{type_of}_nt_{group_names}_use_all.csv'\n",
    "    elif 'kbest' in include_columns:\n",
    "        file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_{type_of}_nt_{group_names}_include_k_best.csv'\n",
    "    elif SPARSE_FEATURES:\n",
    "        file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_{type_of}_nt_{group_names}_sparse.csv'  \n",
    "    elif include_columns == None:\n",
    "        exclude_names = 'None' if len(exclude_prefix_list) == 0 else '_'.join(exclude_prefix_list)\n",
    "        file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_{type_of}_nt_{group_names}_exclude_{exclude_names}.csv'\n",
    "    elif isinstance(include_columns, list):\n",
    "        exclude_names = 'None' if len(include_prefix_list) == 0 else '_'.join(include_prefix_list)\n",
    "        file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_{type_of}_nt_{group_names}_include_{exclude_names}.csv'\n",
    "\n",
    "    if store_submissions_path:\n",
    "        df_sub_val.to_csv(file_path, index = False)\n",
    "        logger.info('saved under: ' + file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seasonal',\n",
       " 'state vs. store',\n",
       " 'ewm vs. ma',\n",
       " 'quantiles vs. std',\n",
       " 'price auto/momentum',\n",
       " 'best models',\n",
       " 'full vs. sparse ma',\n",
       " 'sparse vs. kbest',\n",
       " 'full vs. sparse']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENTS_DICT = {\n",
    "    \"seasonal\": {\n",
    "        \"BASE\": [],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold_ewm'],\n",
    "            ['seasonal_weekday','auto_sold_ewm'],\n",
    "            ['seasonal_monthday','auto_sold_ewm'],\n",
    "            ['seasonal_weekday','seasonal_monthday','auto_sold_ewm'],\n",
    "            ['seasonal','auto_sold_ewm'],\n",
    "        ]\n",
    "    },\n",
    "    \"state vs. store\": {\n",
    "        \"BASE\": ['seasonal', 'auto_sold_ma'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            [],\n",
    "            ['state_id',],\n",
    "            ['store_id',],\n",
    "            ['state_id', 'store_id']\n",
    "        ]\n",
    "    },\n",
    "    \"ewm vs. ma\": {\n",
    "        \"BASE\": ['seasonal'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold_ewm'],\n",
    "            ['auto_sold_ma'],\n",
    "            ['auto_sold_ewm', 'auto_sold_ma'],\n",
    "        ]\n",
    "    },\n",
    "    \"quantiles vs. std\": {\n",
    "        \"BASE\": ['seasonal', 'auto_sold_ma'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            [],\n",
    "            ['auto_sold_qtile'],\n",
    "            ['auto_sold_std'],\n",
    "            ['auto_sold_qtile','auto_sold_std'],   \n",
    "        ]\n",
    "    },\n",
    "    \"price auto/momentum\": {\n",
    "        \"BASE\": ['seasonal', 'auto_sold_ma'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            [],\n",
    "            ['price_auto_std'],\n",
    "            ['price_momentum'],\n",
    "            ['price_uncond'],\n",
    "            ['price_auto_std', 'price_momentum'],\n",
    "            ['price_auto_std', 'price_momentum', 'price_uncond']\n",
    "        ]\n",
    "    },\n",
    "    \"best models\": {\n",
    "        \"BASE\": ['seasonal'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold_ma', 'state_id', 'store_id'],\n",
    "            ['auto_sold_ma', 'auto_sold_std', 'state_id', 'store_id'],\n",
    "        ]\n",
    "    },\n",
    "    \"full vs. sparse ma\" : {\n",
    "        \"BASE\": ['seasonal'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold_ma', 'auto_sold_std', 'auto_sold_qtile', 'auto_sold_ewm', 'state_id', 'store_id'],\n",
    "            ['auto_sold_ma_28', 'auto_sold_ma_56', 'auto_sold_ma_168', 'state_id', 'store_id']\n",
    "        ]\n",
    "    },\n",
    "    \"sparse vs. kbest\": {\n",
    "        \"BASE\": ['seasonal', 'state_id', 'store_id'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold', 'price', 'kbest'],\n",
    "            ['auto_sold_ewm_112', 'auto_sold_ewm_28',\n",
    "             'auto_sold_qtile_28_0.5', 'auto_sold_ma_28', \n",
    "             'auto_sold_qtile_28_0.9',],\n",
    "        ]\n",
    "    },\n",
    "    'full vs. sparse': {\n",
    "        \"BASE\": ['seasonal'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold_ma', 'auto_sold_std', 'auto_sold_qtile', 'auto_sold_ewm', 'state_id', 'store_id'],\n",
    "            ['auto_sold_ma_28', 'auto_sold_ma_56', 'auto_sold_ma_168', 'state_id', 'store_id'],\n",
    "            ['auto_sold_std_3', 'auto_sold_std_56', 'auto_sold_std_168', \n",
    "            'auto_sold_ma_7',  'auto_sold_ma_28', 'auto_sold_ma_56', \n",
    "            'auto_sold_qtile_28_0.25', 'auto_sold_qtile_168_0.25', 'auto_sold_qtile_56_0.1', \n",
    "            'state_id', 'store_id'],\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "list(EXPERIMENTS_DICT.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 21:32:34 - __main__ - INFO - starting with all EXCLUDE_COLUMNS\n",
      "2023-12-20 21:32:34 - __main__ - INFO - finished all EXCLUDE_COLUMNS\n",
      "2023-12-20 21:32:34 - __main__ - INFO - ---------------------------------\n",
      "2023-12-20 21:32:34 - __main__ - INFO - starting with all INCLUDE_COLUMNS\n",
      "2023-12-20 21:32:34 - __main__ - INFO - Include columns: ['seasonal', 'auto_sold_ewm']\n",
      "2023-12-20 21:32:34 - __main__ - INFO - starting with agg_level: Level1\n",
      "2023-12-20 21:32:34 - __main__ - INFO - (re)loading features\n",
      "2023-12-20 21:32:34 - __main__ - INFO - perform gridsearch\n",
      "2023-12-20 21:32:34 - grid_search - INFO - calling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: verbose_eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 21:32:34 - __main__ - INFO - 0.001 - 10 - 200 - score: 69.98473773420362 5.338744915933145\n",
      "2023-12-20 21:32:34 - __main__ - INFO - 0.005 - 10 - 200 - score: 69.70822717198675 6.708542702227735\n",
      "2023-12-20 21:32:35 - __main__ - INFO - 0.01 - 10 - 200 - score: 83.22545795708727 21.001754320945814\n",
      "2023-12-20 21:32:35 - __main__ - INFO - 0.02 - 10 - 200 - score: 71.1603218117206 6.9333237113242\n",
      "2023-12-20 21:32:36 - __main__ - INFO - 0.001 - 30 - 200 - score: 73.2078736051174 12.869318908082045\n",
      "2023-12-20 21:32:36 - __main__ - INFO - 0.005 - 30 - 200 - score: 64.08475929793329 4.638862998673051\n",
      "2023-12-20 21:32:36 - __main__ - INFO - 0.01 - 30 - 200 - score: 72.04248584898349 10.382114151671715\n",
      "2023-12-20 21:32:37 - __main__ - INFO - 0.02 - 30 - 200 - score: 71.95370793166626 20.914882216778874\n",
      "2023-12-20 21:32:37 - __main__ - INFO - 0.001 - 90 - 200 - score: 62.565479652227545 1.4780250467702791\n",
      "2023-12-20 21:32:38 - __main__ - INFO - 0.005 - 90 - 200 - score: 77.83150512820285 15.400465285848371\n",
      "2023-12-20 21:32:38 - __main__ - INFO - 0.01 - 90 - 200 - score: 69.6548174827608 6.500372573877336\n",
      "2023-12-20 21:32:38 - __main__ - INFO - 0.02 - 90 - 200 - score: 77.16469830678656 13.258772959037321\n",
      "2023-12-20 21:32:39 - __main__ - INFO - 0.001 - 10 - 500 - score: 69.6880038084351 7.549178416782678\n",
      "2023-12-20 21:32:40 - __main__ - INFO - 0.005 - 10 - 500 - score: 69.69371306709623 2.8427449866793335\n",
      "2023-12-20 21:32:41 - __main__ - INFO - 0.01 - 10 - 500 - score: 90.01594477339637 20.01739524631727\n",
      "2023-12-20 21:32:42 - __main__ - INFO - 0.02 - 10 - 500 - score: 77.28300764946152 14.924086896680715\n",
      "2023-12-20 21:32:43 - __main__ - INFO - 0.001 - 30 - 500 - score: 70.92524825874702 8.230284188140539\n",
      "2023-12-20 21:32:44 - __main__ - INFO - 0.005 - 30 - 500 - score: 71.18459488290422 14.384461455355927\n",
      "2023-12-20 21:32:45 - __main__ - INFO - 0.01 - 30 - 500 - score: 72.07531081492382 12.056021478692935\n",
      "2023-12-20 21:32:46 - __main__ - INFO - 0.02 - 30 - 500 - score: 104.60173299965518 32.60293629292148\n",
      "2023-12-20 21:32:47 - __main__ - INFO - 0.001 - 90 - 500 - score: 66.6455741180791 1.8750762412171391\n",
      "2023-12-20 21:32:48 - __main__ - INFO - 0.005 - 90 - 500 - score: 71.23934788002023 10.822905444152992\n",
      "2023-12-20 21:32:49 - __main__ - INFO - 0.01 - 90 - 500 - score: 79.81799451728733 18.49012393961458\n",
      "2023-12-20 21:32:50 - __main__ - INFO - 0.02 - 90 - 500 - score: 74.48295934282518 16.599814699288242\n",
      "2023-12-20 21:32:52 - __main__ - INFO - 0.001 - 10 - 1000 - score: 63.74854212131421 5.574289216276531\n",
      "2023-12-20 21:32:54 - __main__ - INFO - 0.005 - 10 - 1000 - score: 83.98311393699329 24.604602388393968\n",
      "2023-12-20 21:32:56 - __main__ - INFO - 0.01 - 10 - 1000 - score: 103.65960958882302 18.85185214248069\n",
      "2023-12-20 21:32:58 - __main__ - INFO - 0.02 - 10 - 1000 - score: 88.48143105141112 21.9453980658451\n",
      "2023-12-20 21:33:00 - __main__ - INFO - 0.001 - 30 - 1000 - score: 73.36630668603303 12.600929566035292\n",
      "2023-12-20 21:33:02 - __main__ - INFO - 0.005 - 30 - 1000 - score: 78.35226370015792 14.633116338629018\n",
      "2023-12-20 21:33:04 - __main__ - INFO - 0.01 - 30 - 1000 - score: 99.24909408901415 24.7111095913603\n",
      "2023-12-20 21:33:07 - __main__ - INFO - 0.02 - 30 - 1000 - score: 80.86618835010506 21.511913642854054\n",
      "2023-12-20 21:33:09 - __main__ - INFO - 0.001 - 90 - 1000 - score: 78.4837424631913 16.388442893578016\n",
      "2023-12-20 21:33:11 - __main__ - INFO - 0.005 - 90 - 1000 - score: 67.10878970559357 12.04470560679888\n",
      "2023-12-20 21:33:13 - __main__ - INFO - 0.01 - 90 - 1000 - score: 86.80943839782194 34.97393718759611\n",
      "2023-12-20 21:33:16 - __main__ - INFO - 0.02 - 90 - 1000 - score: 98.54641166839778 37.38578036998068\n",
      "2023-12-20 21:33:19 - __main__ - INFO - 0.001 - 10 - 2000 - score: 71.86901378269852 12.311184761051988\n",
      "2023-12-20 21:33:24 - __main__ - INFO - 0.005 - 10 - 2000 - score: 89.13312922917176 26.72379667914501\n",
      "2023-12-20 21:33:28 - __main__ - INFO - 0.01 - 10 - 2000 - score: 75.45231582878417 10.229429060995601\n",
      "2023-12-20 21:33:32 - __main__ - INFO - 0.02 - 10 - 2000 - score: 83.23686994147381 16.84639313749957\n",
      "2023-12-20 21:33:36 - __main__ - INFO - 0.001 - 30 - 2000 - score: 72.57796946838191 7.857397056416175\n",
      "2023-12-20 21:33:41 - __main__ - INFO - 0.005 - 30 - 2000 - score: 76.02668693614665 24.28771681248109\n",
      "2023-12-20 21:33:46 - __main__ - INFO - 0.01 - 30 - 2000 - score: 89.88561703675887 30.326807225505505\n",
      "2023-12-20 21:33:51 - __main__ - INFO - 0.02 - 30 - 2000 - score: 111.04367515885755 30.40984383123483\n",
      "2023-12-20 21:33:55 - __main__ - INFO - 0.001 - 90 - 2000 - score: 65.37430732722507 5.515981036014692\n",
      "2023-12-20 21:33:59 - __main__ - INFO - 0.005 - 90 - 2000 - score: 94.22731264329747 17.077121392543557\n",
      "2023-12-20 21:34:04 - __main__ - INFO - 0.01 - 90 - 2000 - score: 98.5451087779105 22.665157117189114\n",
      "2023-12-20 21:34:08 - __main__ - INFO - 0.02 - 90 - 2000 - score: 101.35276782632022 30.971132086549627\n",
      "2023-12-20 21:34:08 - __main__ - INFO - q: 0.005 - cv best params: {'max_depth': 10, 'n_estimators': 200, 'num_leaves': 90, 'learning_rate': 0.001, 'objective': 'quantile', 'boosting_type': 'gbdt', 'random_state': 43, 'verbose': -100, 'n_jobs': 4, 'hist_pool_size': 300, 'verbose_eval': -100, 'alpha': 0.005}\n",
      "2023-12-20 21:34:09 - __main__ - INFO - perform gridsearch\n",
      "2023-12-20 21:34:09 - grid_search - INFO - calling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: verbose_eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 21:34:09 - __main__ - INFO - 0.001 - 10 - 200 - score: 275.0279164539011 12.593759119711327\n",
      "2023-12-20 21:34:10 - __main__ - INFO - 0.005 - 10 - 200 - score: 244.39325712895737 11.713424891651316\n",
      "2023-12-20 21:34:10 - __main__ - INFO - 0.01 - 10 - 200 - score: 240.5160138173281 36.74560656128261\n",
      "2023-12-20 21:34:11 - __main__ - INFO - 0.02 - 10 - 200 - score: 217.48208019236682 52.87809052768971\n",
      "2023-12-20 21:34:11 - __main__ - INFO - 0.001 - 30 - 200 - score: 281.55287896144 30.611867829823968\n",
      "2023-12-20 21:34:12 - __main__ - INFO - 0.005 - 30 - 200 - score: 241.65136815564702 8.204621087621229\n",
      "2023-12-20 21:34:13 - __main__ - INFO - 0.01 - 30 - 200 - score: 216.1442705705018 19.00768312106307\n",
      "2023-12-20 21:34:13 - __main__ - INFO - 0.02 - 30 - 200 - score: 179.85455097729337 15.158224221436852\n",
      "2023-12-20 21:34:14 - __main__ - INFO - 0.001 - 90 - 200 - score: 273.9398452486785 15.151855227453764\n",
      "2023-12-20 21:34:15 - __main__ - INFO - 0.005 - 90 - 200 - score: 242.2746430798416 21.491890787868787\n",
      "2023-12-20 21:34:16 - __main__ - INFO - 0.01 - 90 - 200 - score: 215.2232532823893 15.030497160627782\n",
      "2023-12-20 21:34:16 - __main__ - INFO - 0.02 - 90 - 200 - score: 196.1542981509542 20.32603460195399\n",
      "2023-12-20 21:34:18 - __main__ - INFO - 0.001 - 10 - 500 - score: 252.77523153621547 16.066151969118195\n",
      "2023-12-20 21:34:19 - __main__ - INFO - 0.005 - 10 - 500 - score: 225.1582489933027 17.26478126102575\n",
      "2023-12-20 21:34:20 - __main__ - INFO - 0.01 - 10 - 500 - score: 191.0237503677617 34.53679138223571\n",
      "2023-12-20 21:34:21 - __main__ - INFO - 0.02 - 10 - 500 - score: 189.71856245003738 43.725492589450305\n",
      "2023-12-20 21:34:23 - __main__ - INFO - 0.001 - 30 - 500 - score: 250.25445407322587 12.443558065419515\n",
      "2023-12-20 21:34:25 - __main__ - INFO - 0.005 - 30 - 500 - score: 199.01483578040984 9.329874134882987\n",
      "2023-12-20 21:34:27 - __main__ - INFO - 0.01 - 30 - 500 - score: 185.8503963317788 28.47915643925616\n",
      "2023-12-20 21:34:29 - __main__ - INFO - 0.02 - 30 - 500 - score: 218.19027224937008 38.58247189462096\n",
      "2023-12-20 21:34:31 - __main__ - INFO - 0.001 - 90 - 500 - score: 271.61947626575557 18.306457337596655\n",
      "2023-12-20 21:34:33 - __main__ - INFO - 0.005 - 90 - 500 - score: 216.67678469282026 27.37367900536096\n",
      "2023-12-20 21:34:35 - __main__ - INFO - 0.01 - 90 - 500 - score: 201.38987128626064 33.49948936325677\n",
      "2023-12-20 21:34:37 - __main__ - INFO - 0.02 - 90 - 500 - score: 194.7422352590075 47.77698368191666\n",
      "2023-12-20 21:34:39 - __main__ - INFO - 0.001 - 10 - 1000 - score: 245.2646219826996 18.84639123924466\n",
      "2023-12-20 21:34:42 - __main__ - INFO - 0.005 - 10 - 1000 - score: 198.33850166612115 23.383530664108417\n",
      "2023-12-20 21:34:44 - __main__ - INFO - 0.01 - 10 - 1000 - score: 196.55889469453206 21.849703876894985\n",
      "2023-12-20 21:34:47 - __main__ - INFO - 0.02 - 10 - 1000 - score: 200.784315045338 21.86429042663193\n",
      "2023-12-20 21:34:50 - __main__ - INFO - 0.001 - 30 - 1000 - score: 245.776440341982 28.810296502081563\n",
      "2023-12-20 21:34:55 - __main__ - INFO - 0.005 - 30 - 1000 - score: 204.08837111214552 20.738369831540663\n",
      "2023-12-20 21:34:59 - __main__ - INFO - 0.01 - 30 - 1000 - score: 216.18830436571093 32.04201755343391\n",
      "2023-12-20 21:35:04 - __main__ - INFO - 0.02 - 30 - 1000 - score: 262.56362948527675 52.35339438276845\n",
      "2023-12-20 21:35:08 - __main__ - INFO - 0.001 - 90 - 1000 - score: 240.4146209790071 19.227219694632566\n",
      "2023-12-20 21:35:12 - __main__ - INFO - 0.005 - 90 - 1000 - score: 181.01011335669745 24.218623729824735\n",
      "2023-12-20 21:35:17 - __main__ - INFO - 0.01 - 90 - 1000 - score: 205.22150379983023 15.064535112628699\n",
      "2023-12-20 21:35:22 - __main__ - INFO - 0.02 - 90 - 1000 - score: 227.16922501932558 28.034418371960992\n",
      "2023-12-20 21:35:27 - __main__ - INFO - 0.001 - 10 - 2000 - score: 233.1597969920715 20.427049530007768\n",
      "2023-12-20 21:35:32 - __main__ - INFO - 0.005 - 10 - 2000 - score: 175.22869563797866 18.48935151790449\n",
      "2023-12-20 21:35:37 - __main__ - INFO - 0.01 - 10 - 2000 - score: 181.20098818538582 6.831350552585693\n",
      "2023-12-20 21:35:42 - __main__ - INFO - 0.02 - 10 - 2000 - score: 224.61166754978439 26.442428484793993\n",
      "2023-12-20 21:35:49 - __main__ - INFO - 0.001 - 30 - 2000 - score: 223.35563540817938 20.452173456265083\n",
      "2023-12-20 21:35:59 - __main__ - INFO - 0.005 - 30 - 2000 - score: 189.42037533153092 23.313218814489908\n",
      "2023-12-20 21:36:09 - __main__ - INFO - 0.01 - 30 - 2000 - score: 201.51331821587124 24.777940187354176\n",
      "2023-12-20 21:36:19 - __main__ - INFO - 0.02 - 30 - 2000 - score: 281.095583271847 29.825941183716047\n",
      "2023-12-20 21:36:26 - __main__ - INFO - 0.001 - 90 - 2000 - score: 224.32369933740023 15.132279119328592\n",
      "2023-12-20 21:36:36 - __main__ - INFO - 0.005 - 90 - 2000 - score: 187.33227322812883 29.66720188535513\n",
      "2023-12-20 21:36:46 - __main__ - INFO - 0.01 - 90 - 2000 - score: 214.43631658429194 16.750183115587706\n",
      "2023-12-20 21:36:55 - __main__ - INFO - 0.02 - 90 - 2000 - score: 238.0031698383862 39.1317365702058\n",
      "2023-12-20 21:36:55 - __main__ - INFO - q: 0.025 - cv best params: {'max_depth': 10, 'n_estimators': 2000, 'num_leaves': 10, 'learning_rate': 0.005, 'objective': 'quantile', 'boosting_type': 'gbdt', 'random_state': 43, 'verbose': -100, 'n_jobs': 4, 'hist_pool_size': 300, 'verbose_eval': -100, 'alpha': 0.025}\n",
      "2023-12-20 21:36:56 - __main__ - INFO - perform gridsearch\n",
      "2023-12-20 21:36:56 - grid_search - INFO - calling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: verbose_eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 21:36:57 - __main__ - INFO - 0.001 - 10 - 200 - score: 1173.767343099289 54.20042016877397\n",
      "2023-12-20 21:36:57 - __main__ - INFO - 0.005 - 10 - 200 - score: 931.5454592135063 43.84626397002443\n",
      "2023-12-20 21:36:58 - __main__ - INFO - 0.01 - 10 - 200 - score: 747.6595398271268 58.75217488693823\n",
      "2023-12-20 21:36:59 - __main__ - INFO - 0.02 - 10 - 200 - score: 608.5098266701661 18.95672574994793\n",
      "2023-12-20 21:37:00 - __main__ - INFO - 0.001 - 30 - 200 - score: 1181.2851036584084 66.07194052804681\n",
      "2023-12-20 21:37:01 - __main__ - INFO - 0.005 - 30 - 200 - score: 871.0909384048452 31.89568235484538\n",
      "2023-12-20 21:37:02 - __main__ - INFO - 0.01 - 30 - 200 - score: 640.4229421007311 27.449076634712483\n",
      "2023-12-20 21:37:03 - __main__ - INFO - 0.02 - 30 - 200 - score: 566.226383007109 59.83472031088985\n",
      "2023-12-20 21:37:04 - __main__ - INFO - 0.001 - 90 - 200 - score: 1212.8225701988795 59.4969435454505\n",
      "2023-12-20 21:37:05 - __main__ - INFO - 0.005 - 90 - 200 - score: 836.8196497936093 47.72538152921587\n",
      "2023-12-20 21:37:06 - __main__ - INFO - 0.01 - 90 - 200 - score: 692.1624503898796 36.004174020478914\n",
      "2023-12-20 21:37:08 - __main__ - INFO - 0.02 - 90 - 200 - score: 593.02995260302 33.03755365548409\n",
      "2023-12-20 21:37:09 - __main__ - INFO - 0.001 - 10 - 500 - score: 1085.0550991581508 69.08995764080194\n",
      "2023-12-20 21:37:10 - __main__ - INFO - 0.005 - 10 - 500 - score: 696.9656729759054 46.67160246220159\n",
      "2023-12-20 21:37:12 - __main__ - INFO - 0.01 - 10 - 500 - score: 616.9649244553119 48.25006506935785\n",
      "2023-12-20 21:37:13 - __main__ - INFO - 0.02 - 10 - 500 - score: 578.6074949104777 52.49363891429877\n",
      "2023-12-20 21:37:15 - __main__ - INFO - 0.001 - 30 - 500 - score: 1051.4991578994982 35.46324627314989\n",
      "2023-12-20 21:37:18 - __main__ - INFO - 0.005 - 30 - 500 - score: 608.9079433628514 38.96169859859076\n",
      "2023-12-20 21:37:21 - __main__ - INFO - 0.01 - 30 - 500 - score: 550.7443726442677 16.017173603006206\n",
      "2023-12-20 21:37:24 - __main__ - INFO - 0.02 - 30 - 500 - score: 571.267109049041 64.93507770914309\n",
      "2023-12-20 21:37:27 - __main__ - INFO - 0.001 - 90 - 500 - score: 1048.6133796298832 41.52717154864428\n",
      "2023-12-20 21:37:30 - __main__ - INFO - 0.005 - 90 - 500 - score: 607.5100066956122 30.954298243048378\n",
      "2023-12-20 21:37:33 - __main__ - INFO - 0.01 - 90 - 500 - score: 531.4086336755817 26.785106970479486\n",
      "2023-12-20 21:37:37 - __main__ - INFO - 0.02 - 90 - 500 - score: 569.6514384912911 44.65730044712005\n",
      "2023-12-20 21:37:39 - __main__ - INFO - 0.001 - 10 - 1000 - score: 937.7984583104455 38.50063327089881\n",
      "2023-12-20 21:37:42 - __main__ - INFO - 0.005 - 10 - 1000 - score: 596.6534818492212 27.60526802185653\n",
      "2023-12-20 21:37:45 - __main__ - INFO - 0.01 - 10 - 1000 - score: 565.1587329616705 21.30446784804156\n",
      "2023-12-20 21:37:47 - __main__ - INFO - 0.02 - 10 - 1000 - score: 553.9073356440736 21.661594146578835\n",
      "2023-12-20 21:37:52 - __main__ - INFO - 0.001 - 30 - 1000 - score: 886.7244740697437 33.85598363515892\n",
      "2023-12-20 21:37:58 - __main__ - INFO - 0.005 - 30 - 1000 - score: 588.3675527124276 46.1734844218655\n",
      "2023-12-20 21:38:04 - __main__ - INFO - 0.01 - 30 - 1000 - score: 541.7094303226926 41.77018453255799\n",
      "2023-12-20 21:38:11 - __main__ - INFO - 0.02 - 30 - 1000 - score: 571.3189153305209 27.834507124911003\n",
      "2023-12-20 21:38:16 - __main__ - INFO - 0.001 - 90 - 1000 - score: 876.2719743514233 34.407032950148434\n",
      "2023-12-20 21:38:23 - __main__ - INFO - 0.005 - 90 - 1000 - score: 611.7574032688557 40.37388631739392\n",
      "2023-12-20 21:38:30 - __main__ - INFO - 0.01 - 90 - 1000 - score: 534.2200507918142 36.89334664769649\n",
      "2023-12-20 21:38:36 - __main__ - INFO - 0.02 - 90 - 1000 - score: 560.4065750969606 33.93644224500306\n",
      "2023-12-20 21:38:41 - __main__ - INFO - 0.001 - 10 - 2000 - score: 718.2881397033473 42.78452235056548\n",
      "2023-12-20 21:38:47 - __main__ - INFO - 0.005 - 10 - 2000 - score: 554.0696268121226 22.85634553957586\n",
      "2023-12-20 21:38:52 - __main__ - INFO - 0.01 - 10 - 2000 - score: 573.3839095350352 39.69179705167928\n",
      "2023-12-20 21:38:57 - __main__ - INFO - 0.02 - 10 - 2000 - score: 575.1505229674765 44.30107302982275\n",
      "2023-12-20 21:39:08 - __main__ - INFO - 0.001 - 30 - 2000 - score: 698.3079197398054 21.371766211479756\n",
      "2023-12-20 21:39:20 - __main__ - INFO - 0.005 - 30 - 2000 - score: 563.8834292731658 34.66122135581958\n",
      "2023-12-20 21:39:32 - __main__ - INFO - 0.01 - 30 - 2000 - score: 570.4573432230633 26.340969786120294\n",
      "2023-12-20 21:39:44 - __main__ - INFO - 0.02 - 30 - 2000 - score: 594.3669902708358 38.599134667326446\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m         \u001b[39mfor\u001b[39;00m agg_level \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(AGG_LEVEL_COLUMNS\u001b[39m.\u001b[39mkeys())[TEST_NUMB:TEST_NUMBER]: \u001b[39m# for each aggregation level\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m             logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstarting with agg_level: \u001b[39m\u001b[39m{\u001b[39;00magg_level\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m             train_level_all_quantiles(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m                 agg_level,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m                 sub_d_start\u001b[39m=\u001b[39;49msub_d_start,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m                 type_of\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m                 exclude_columns\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m                 include_columns\u001b[39m=\u001b[39;49minclude_columns,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m                 do_grid_search\u001b[39m=\u001b[39;49mDO_GRID_SEARCH,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m                 store_submissions_path\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\u001b[39m#'temp_submissions/',\u001b[39;49;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m             )\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mfinished all INCLUDE_COLUMNS\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mperform gridsearch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=144'>145</a>\u001b[0m params[\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m quantile\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m best_combination, results \u001b[39m=\u001b[39m grid_search(params, param_grid, features_train, targets_train, n_folds \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m \u001b[39m# del train_data; del validation_data\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m params_grid_train \u001b[39m=\u001b[39m best_combination[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/projects/m5-forecasting-uncertainty/code/utils/utils.py:139\u001b[0m, in \u001b[0;36mlog_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(function\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    138\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mcalling\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# train lgb model        \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m temp_dict \u001b[39m=\u001b[39m {} \u001b[39m# this dict object will be used to add all (intermediate) evaluation scores during the training process\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m mod: lgb\u001b[39m.\u001b[39mBooster \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(param_combination, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     train_set \u001b[39m=\u001b[39;49m lgb\u001b[39m.\u001b[39;49mDataset(features_train, targets_train),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     valid_sets \u001b[39m=\u001b[39;49m lgb\u001b[39m.\u001b[39;49mDataset(features_validation, targets_validation),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     evals_result \u001b[39m=\u001b[39;49m temp_dict,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# store results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m results[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcombination_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mres\u001b[39m\u001b[39m'\u001b[39m]\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39m.\u001b[39mappend(temp_dict[\u001b[39m\"\u001b[39m\u001b[39mvalid_0\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mquantile\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joeybesseling/projects/m5-forecasting-uncertainty/code/un_training_model_quantiles.ipynb#X20sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_tf_env/lib/python3.9/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_tf_env/lib/python3.9/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SPARSE_FEATURES = [ 'seasonal_weekday', 'seasonal_monthday', 'auto_sold_ewm_112', 'auto_sold_ewm_28',\n",
    "#   'autoquantiles_sold_qtile_28_0.5', 'auto_sold_ma_28',\n",
    "#   'auto_sold_qtile_28_0.9',\n",
    "#    'auto_sold_qtile_28_0.1'\n",
    "# ],\n",
    "\n",
    "USE_ALL = False\n",
    "SPARSE_FEATURES = None\n",
    "PLOT_PREDICTIONS = True\n",
    "\n",
    "undersampling_dict = {\n",
    "    'Level10': .1, #.001\n",
    "    'Level11': .1, #.0001\n",
    "    'Level12': .1 #.00001\n",
    "}\n",
    "\n",
    "HIGH_UNDERSAMPLING = True\n",
    "TEST_NUMBER = 9 # 9\n",
    "TEST_NUMB = 0 # 0\n",
    "PARAM_GRID_TRAIN = {\n",
    "    'objective': 'quantile',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': 4,\n",
    "    \"num_leaves\": 10, # 30\n",
    "    \"hist_pool_size\": 300,\n",
    "    \"learning_rate\": .01, # .01\n",
    "    \"n_estimators\": 1000, #1000\n",
    "    \"max_depth\": 10, #10\n",
    "}\n",
    "PARAM_GRID_TRAIN_HIGH_LEVEL = {\n",
    "    'objective': 'quantile',\n",
    "    # 'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': 4,\n",
    "    \"num_leaves\": 30,\n",
    "    \"hist_pool_size\": 300,\n",
    "    # 'feature_fraction': 0.9, #.5\n",
    "    # 'bagging_fraction': .8,\n",
    "    \"learning_rate\": .01, # .01 always\n",
    "    \"n_estimators\": 3000, # 3000 always\n",
    "    \"max_depth\": 10,\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    # 'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -100,\n",
    "    'n_jobs': 4,\n",
    "    # 'eval_at': 10,\n",
    "    'hist_pool_size': 300,\n",
    "    'verbose_eval': -100,\n",
    "}\n",
    "param_grid = {\n",
    "    'max_depth': [10,],\n",
    "    'n_estimators': [200, 500, 1000, 2000],\n",
    "    # 'min_child_samples': [4],\n",
    "    # 'min_child_weight': [0,0.1],\n",
    "    'num_leaves': [10, 30, 90], # 50, 70, 90, ],\n",
    "    'learning_rate': [.001, .005, .01, .02],#[0.04, 0.07, 0.1],   # 0.02, 0.03,        \n",
    "    # 'subsample': [ 0.9, 1 ],\n",
    "    # 'subsample_freq': [1],\n",
    "}\n",
    "\n",
    "# ALL_PREFIXES = ['auto_sold', 'auto_sold_ma', 'auto_sold_std', 'auto_sold_ewm', 'auto_sold_qtile',\n",
    "#     'price_momentum', 'price_uncond', 'price_auto_std','seasonal_', 'state_', 'store_',\n",
    "# ]\n",
    "\n",
    "experiment_name = 'seasonal'\n",
    "experiment_specs = EXPERIMENTS_DICT[experiment_name]\n",
    "BASE = experiment_specs['BASE']\n",
    "INCLUDE_COLUMNS_LIST = experiment_specs['INCLUDE_COLUMNS_LIST']\n",
    "\n",
    "INCLUDE_COLUMNS_LIST = [BASE + i for i in INCLUDE_COLUMNS_LIST]\n",
    "DO_GRID_SEARCH = True\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = ()\n",
    "logger.info('starting with all EXCLUDE_COLUMNS')\n",
    "for exclude_columns in EXCLUDE_COLUMNS_LIST: # for each specified feature combination\n",
    "    logger.info(f'Exclude columns: {str(exclude_columns)}')\n",
    "    for sub_d_start in D_CROSS_VAL_START_LIST:\n",
    "        for agg_level in list(AGG_LEVEL_COLUMNS.keys())[TEST_NUMB:TEST_NUMBER]: # for each aggregation level\n",
    "            logger.info(f'starting with agg_level: {agg_level}')\n",
    "            train_level_all_quantiles(\n",
    "                agg_level,\n",
    "                sub_d_start=sub_d_start,\n",
    "                type_of='val', \n",
    "                exclude_columns=exclude_columns,\n",
    "                do_grid_search=DO_GRID_SEARCH,\n",
    "                store_submissions_path=None#'temp_submissions/',\n",
    "            )\n",
    "logger.info('finished all EXCLUDE_COLUMNS')\n",
    "\n",
    "logger.info('---------------------------------')            \n",
    "logger.info('starting with all INCLUDE_COLUMNS')            \n",
    "for include_columns in INCLUDE_COLUMNS_LIST[-1:]: # for each specified feature combination\n",
    "    logger.info(f'Include columns: {str(include_columns)}')\n",
    "    for sub_d_start in D_CROSS_VAL_START_LIST:\n",
    "        for agg_level in list(AGG_LEVEL_COLUMNS.keys())[TEST_NUMB:TEST_NUMBER]: # for each aggregation level\n",
    "            logger.info(f'starting with agg_level: {agg_level}')\n",
    "            train_level_all_quantiles(\n",
    "                agg_level,\n",
    "                sub_d_start=sub_d_start,\n",
    "                type_of='val', \n",
    "                exclude_columns=None,\n",
    "                include_columns=include_columns,\n",
    "                do_grid_search=DO_GRID_SEARCH,\n",
    "                store_submissions_path=None#'temp_submissions/',\n",
    "            )\n",
    "logger.info('finished all INCLUDE_COLUMNS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load val + eval prediction files and merge to one submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_columns = '_'.join([])\n",
    "# if exclude_columns == '':\n",
    "#     exclude_columns = 'None'\n",
    "\n",
    "# dfs: list = []\n",
    "# for level in AGG_LEVEL_COLUMNS:\n",
    "#     agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "#     group_names = '_'.join(agg_columns)\n",
    "#     if group_names == '':\n",
    "#         group_names = 'Total_X'\n",
    "#     i = str(1914)\n",
    "#     dfs.append(\n",
    "#         f'../data/uncertainty/fold_{i}/temp_submissions/' + f'lgb_multivariate_val_non_transposed_{group_names}_exclude_{exclude_columns}.csv',\n",
    "#     )\n",
    "\n",
    "# df_sub_val = ensemble_submissions_uncertainty(dfs)\n",
    "# transpose = True\n",
    "# if transpose == True:\n",
    "#     sub_validation = df_sub_val.pivot(index='id', columns='d', values='pred').reset_index(drop=False)\n",
    "#     sub_validation.columns = [\"id\"] + [f\"F{i}\" for i in range(1,DAYS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_concat_predictions(fold_name: int, exclude_columns: list = [], include_columns: list = [], sparse = False, use_all = False, load_submissions_path: str = 'temp_submissions/'):\n",
    "    \"\"\" \n",
    "    For specified fold, read the predictions for all aggregation levels and stack them together in one dataframe.\n",
    "    \"\"\"\n",
    "    # D_CV_START_LIST\n",
    "    # if fold_name not in D_CV_START_LIST:\n",
    "        # raise ValueError('fold_name must be a value in D_CV_START_LIST')\n",
    "        \n",
    "    exclude_columns = '_'.join(exclude_columns)\n",
    "    if exclude_columns == '':\n",
    "        exclude_columns = 'None'\n",
    "\n",
    "    logger.info('loading files under path:' + f'../data/uncertainty/fold_{fold_name}/' + load_submissions_path)\n",
    "\n",
    "    dfs: list = []\n",
    "    for level in list(AGG_LEVEL_COLUMNS.keys())[TEST_NUMB:TEST_NUMBER]:\n",
    "        agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "        group_names = '_'.join(agg_columns)\n",
    "        if group_names == '':\n",
    "            group_names = 'Total_X'\n",
    "        \n",
    "        file_path = f'../data/uncertainty/fold_{str(fold_name)}/' + load_submissions_path \n",
    "        file_path += f'lgb_val_nt_{group_names}_'\n",
    "        if use_all:\n",
    "            file_path += f'use_all.csv'  \n",
    "        elif include_columns == None:\n",
    "            file_path += f'exclude_{\"_\".join(exclude_columns)}.csv'            \n",
    "        elif isinstance(include_columns, list):\n",
    "            file_path += f'include_{\"_\".join(include_columns)}.csv'\n",
    "        \n",
    "        dfs.append(file_path)\n",
    "    return ensemble_submissions_uncertainty(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE = ['seasonal',]\n",
    "# INCLUDE_COLUMNS_LIST = [\n",
    "#     # ['auto_sold_ma', 'auto_sold_std', 'auto_sold_qtile', 'auto_sold_ewm', 'state_id', 'store_id'],\n",
    "#     ['auto_sold_std_3', 'auto_sold_std_56', 'auto_sold_std_168', \n",
    "#      'auto_sold_ma_7',  'auto_sold_ma_28', 'auto_sold_ma_56', \n",
    "#      'auto_sold_qtile_28_0.25', 'auto_sold_qtile_168_0.25', 'auto_sold_qtile_56_0.1', \n",
    "#      'state_id', 'store_id'],\n",
    "#     # ['kbest']\n",
    "# ]\n",
    "# \n",
    "# BASE = ['seasonal']\n",
    "# INCLUDE_COLUMNS_LIST = [\n",
    "#     ['auto_sold_ma', 'auto_sold_std', 'auto_sold_qtile', 'auto_sold_ewm', 'state_id', 'store_id'],\n",
    "#     ['auto_sold_ma_28', 'auto_sold_ma_56', 'auto_sold_ma_168', 'state_id', 'store_id']\n",
    "# ]\n",
    "\n",
    "# include_columns = BASE + INCLUDE_COLUMNS_LIST[1]\n",
    "# include_columns_str = '_'.join(include_columns)\n",
    "\n",
    "# dfs: list = []\n",
    "# for level in AGG_LEVEL_COLUMNS:\n",
    "#     agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "#     group_names = '_'.join(agg_columns)\n",
    "#     if group_names == '':\n",
    "#         group_names = 'Total_X'\n",
    "        \n",
    "#     dfs.append(\n",
    "#         f'../data/uncertainty/fold_{1914}/temp_submissions/lgb_val_nt_{group_names}_include_{include_columns_str}.csv'\n",
    "#     )\n",
    "\n",
    "# df_sub_eval = ensemble_submissions_uncertainty(dfs)\n",
    "# transpose = True\n",
    "# if transpose == True:\n",
    "#     sub_evaluation = df_sub_eval.pivot(index='id', columns='d', values='pred').reset_index(drop=False)\n",
    "#     sub_evaluation.columns = [\"id\"] + [f\"F{i}\" for i in range(1,DAYS+1)]\n",
    "\n",
    "# sub_evaluation2 = sub_evaluation.copy()\n",
    "# sub_evaluation2['id'] = sub_evaluation2['id'].str.removesuffix('_validation') + '_evaluation'\n",
    "# \n",
    "# pd.concat([sub_evaluation, sub_evaluation2]).to_csv('../data/uncertainty/fold_1914/final_submissions/' + f'submission_lgb_ensemble{exclude_columns}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_evaluation = pd.read_csv('../submissions/submission_baseline_evaluation.csv').drop(['Unnamed: 0'], axis=1)\n",
    "# pd.concat([sub_validation, sub_evaluation]).to_csv(SUBMISSION_BASE_PATH + f'submission_lgb_ensemble{exclude_columns}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Validation Prediction, we can compute WRMSSE locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these variables are used later on\n",
    "FORCE_RELOAD = False\n",
    "try:\n",
    "    # simple code to check if variable exists\n",
    "    d_int + 1\n",
    "    if FORCE_RELOAD:\n",
    "        raise Exception()\n",
    "except:\n",
    "    # if not, load again\n",
    "    # takes about 2-3 minutes to reload and parse\n",
    "    # not the most beautiful method but it works\n",
    "    d = pd.read_parquet('../data/uncertainty/cv_template/temp.parquet')\n",
    "    try:\n",
    "        d_int = pd.read_parquet('../data/uncertainty/cv_template/temp_d_int.parquet')['d_int']\n",
    "    except:\n",
    "        d_int = d['d'].apply(lambda x: int(x.split('_')[1]))\n",
    "        d_int.to_frame('d_int').to_parquet('../data/uncertainty/cv_template/temp_d_int.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv(df: pd.DataFrame, df_sub: pd.DataFrame):\n",
    "    \n",
    "    # to be able to merge\n",
    "    # df_sub['id_merge'] = df_sub['id'].str.split('.')\\\n",
    "    #     .apply(lambda x: x[0])\n",
    "    df_sub['id_merge'] = df_sub['id']\\\n",
    "        .apply(lambda x: x.split('.')[0])\n",
    "    # df_sub['quantile'] = df_sub['id'].str.split('.')\\\n",
    "    #     .apply(lambda x: float('.'.join([x[-2], x[-1].split('_')[0]])))\n",
    "    df_sub['quantile'] = df_sub['id']\\\n",
    "        .apply(\n",
    "            lambda x: float(\n",
    "                '.'.join([\n",
    "                x.split('.')[-2], \n",
    "                x.split('.')[-1].split('_')[0]\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # merge predictions in cv template\n",
    "    p = pd.merge(\n",
    "        df,\n",
    "        df_sub,\n",
    "        how='left',\n",
    "        on=['id_merge', 'd']\n",
    "    )\n",
    "    # del df; del df_sub_val\n",
    "    p['id_merge'] = p['id_merge'].astype(str)\n",
    "\n",
    "    for c in ['sold', 'revenue']:\n",
    "        p[c] = p[c].astype(np.float32)\n",
    "    # d = d[d_int < (D_CV_START + 28)]\n",
    "\n",
    "    return WSPL(p, [f'd_{i}' for i in range(D_CV_START, D_CV_START + 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 21:02:22 - __main__ - INFO - start evaluating exclude columns\n",
      "2023-12-16 21:02:22 - __main__ - INFO - start evaluating include columns\n",
      "2023-12-16 21:02:22 - __main__ - INFO - --------------- ['k_best'] ---------------\n",
      "2023-12-16 21:02:25 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1802/temp_submissions/\n",
      "2023-12-16 21:02:45 - utils.metrics - INFO - reading weights file\n",
      "2023-12-16 21:02:45 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-12-16 21:03:13 - utils.metrics - INFO - entering loop ...\n",
      "2023-12-16 21:03:19 - utils.metrics - INFO - Level1 - 0.1712239568255422\n",
      "2023-12-16 21:03:20 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:03:24 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:03:41 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:03:42 - utils.metrics - INFO - Level2 - 0.24072055648767068\n",
      "2023-12-16 21:03:42 - utils.metrics - INFO - Level3 - 0.2595724408822137\n",
      "2023-12-16 21:03:42 - utils.metrics - INFO - Level4 - 0.20524983388934617\n",
      "2023-12-16 21:03:42 - utils.metrics - INFO - Level5 - 1.5203727265560685\n",
      "2023-12-16 21:03:42 - utils.metrics - INFO - Level6 - 0.31842699399117164\n",
      "2023-12-16 21:03:42 - utils.metrics - INFO - Level7 - 1.0114061693889846\n",
      "2023-12-16 21:03:42 - utils.metrics - INFO - Level8 - 0.34330380348524797\n",
      "2023-12-16 21:03:42 - utils.metrics - INFO - Level9 - 0.8303925476838893\n",
      "2023-12-16 21:03:44 - __main__ - INFO - 1802 - wspl: 0.544518781021126\n",
      "2023-12-16 21:03:48 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1830/temp_submissions/\n",
      "2023-12-16 21:04:06 - utils.metrics - INFO - reading weights file\n",
      "2023-12-16 21:04:06 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-12-16 21:04:32 - utils.metrics - INFO - entering loop ...\n",
      "2023-12-16 21:04:37 - utils.metrics - INFO - Level1 - 0.2406354598854072\n",
      "2023-12-16 21:04:38 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:04:42 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:04:59 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:05:00 - utils.metrics - INFO - Level2 - 0.2594864475874541\n",
      "2023-12-16 21:05:00 - utils.metrics - INFO - Level3 - 0.3097064121992717\n",
      "2023-12-16 21:05:00 - utils.metrics - INFO - Level4 - 0.2901325668000964\n",
      "2023-12-16 21:05:00 - utils.metrics - INFO - Level5 - 1.2776383949842514\n",
      "2023-12-16 21:05:00 - utils.metrics - INFO - Level6 - 0.4110040879123669\n",
      "2023-12-16 21:05:00 - utils.metrics - INFO - Level7 - 0.9758249832167586\n",
      "2023-12-16 21:05:00 - utils.metrics - INFO - Level8 - 0.3743582224026753\n",
      "2023-12-16 21:05:00 - utils.metrics - INFO - Level9 - 0.8714275867136175\n",
      "2023-12-16 21:05:02 - __main__ - INFO - 1830 - wspl: 0.5566904624113221\n",
      "2023-12-16 21:05:06 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1858/temp_submissions/\n",
      "2023-12-16 21:05:24 - utils.metrics - INFO - reading weights file\n",
      "2023-12-16 21:05:24 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-12-16 21:05:51 - utils.metrics - INFO - entering loop ...\n",
      "2023-12-16 21:05:56 - utils.metrics - INFO - Level1 - 0.1609495328897632\n",
      "2023-12-16 21:05:57 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:06:02 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:06:19 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:06:19 - utils.metrics - INFO - Level2 - 0.2346027788776534\n",
      "2023-12-16 21:06:19 - utils.metrics - INFO - Level3 - 0.2927883606230057\n",
      "2023-12-16 21:06:19 - utils.metrics - INFO - Level4 - 0.24685518211238483\n",
      "2023-12-16 21:06:19 - utils.metrics - INFO - Level5 - 1.0755029553868412\n",
      "2023-12-16 21:06:19 - utils.metrics - INFO - Level6 - 0.3780224894775054\n",
      "2023-12-16 21:06:20 - utils.metrics - INFO - Level7 - 0.89990108353679\n",
      "2023-12-16 21:06:20 - utils.metrics - INFO - Level8 - 0.40379485464078346\n",
      "2023-12-16 21:06:20 - utils.metrics - INFO - Level9 - 0.8666375621617401\n",
      "2023-12-16 21:06:22 - __main__ - INFO - 1858 - wspl: 0.5065616444118297\n",
      "2023-12-16 21:06:25 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1886/temp_submissions/\n",
      "2023-12-16 21:06:44 - utils.metrics - INFO - reading weights file\n",
      "2023-12-16 21:06:44 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-12-16 21:07:11 - utils.metrics - INFO - entering loop ...\n",
      "2023-12-16 21:07:16 - utils.metrics - INFO - Level1 - 0.2674794393301125\n",
      "2023-12-16 21:07:17 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:07:21 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:07:39 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:07:39 - utils.metrics - INFO - Level2 - 0.23178935237842535\n",
      "2023-12-16 21:07:39 - utils.metrics - INFO - Level3 - 0.29956275638660856\n",
      "2023-12-16 21:07:39 - utils.metrics - INFO - Level4 - 0.19862676079185082\n",
      "2023-12-16 21:07:39 - utils.metrics - INFO - Level5 - 0.8091927903697541\n",
      "2023-12-16 21:07:39 - utils.metrics - INFO - Level6 - 0.307667976757551\n",
      "2023-12-16 21:07:40 - utils.metrics - INFO - Level7 - 0.7561376353898\n",
      "2023-12-16 21:07:40 - utils.metrics - INFO - Level8 - 0.3985095784849927\n",
      "2023-12-16 21:07:40 - utils.metrics - INFO - Level9 - 0.8619480434140016\n",
      "2023-12-16 21:07:42 - __main__ - INFO - 1886 - wspl: 0.4589904814781219\n",
      "2023-12-16 21:07:45 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1914/temp_submissions/\n",
      "2023-12-16 21:08:04 - utils.metrics - INFO - reading weights file\n",
      "2023-12-16 21:08:04 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-12-16 21:08:31 - utils.metrics - INFO - entering loop ...\n",
      "2023-12-16 21:08:36 - utils.metrics - INFO - Level1 - 0.5336452963914808\n",
      "2023-12-16 21:08:38 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:08:42 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:09:00 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:09:01 - utils.metrics - INFO - Level2 - 0.4403762812444869\n",
      "2023-12-16 21:09:01 - utils.metrics - INFO - Level3 - 0.4061895961334509\n",
      "2023-12-16 21:09:01 - utils.metrics - INFO - Level4 - 0.41178965625364244\n",
      "2023-12-16 21:09:01 - utils.metrics - INFO - Level5 - 1.2248975323844988\n",
      "2023-12-16 21:09:01 - utils.metrics - INFO - Level6 - 0.5025127820340651\n",
      "2023-12-16 21:09:01 - utils.metrics - INFO - Level7 - 0.8285329816237732\n",
      "2023-12-16 21:09:01 - utils.metrics - INFO - Level8 - 0.4735412350599226\n",
      "2023-12-16 21:09:01 - utils.metrics - INFO - Level9 - 0.8916170701573993\n",
      "2023-12-16 21:09:03 - __main__ - INFO - 1914 - wspl: 0.6347891590314133\n",
      "2023-12-16 21:09:03 - __main__ - INFO - 1914 - mean wspl: 0.5403101056707627 +/- 0.05824802224154129\n",
      "2023-12-16 21:09:03 - __main__ - INFO - 1914 - raw results: [0.544518781021126, 0.5566904624113221, 0.5065616444118297, 0.4589904814781219, 0.6347891590314133]\n",
      "2023-12-16 21:09:03 - __main__ - INFO - --------------- ['seasonal', 'state_id', 'store_id', 'auto_sold_ewm_112', 'auto_sold_ewm_28', 'auto_sold_qtile_28_0.5', 'auto_sold_ma_28', 'auto_sold_qtile_28_0.9'] ---------------\n",
      "2023-12-16 21:09:06 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1802/temp_submissions/\n",
      "2023-12-16 21:09:27 - utils.metrics - INFO - reading weights file\n",
      "2023-12-16 21:09:27 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-12-16 21:09:53 - utils.metrics - INFO - entering loop ...\n",
      "2023-12-16 21:09:58 - utils.metrics - INFO - Level1 - 0.2025243794116563\n",
      "2023-12-16 21:10:00 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:10:04 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:10:21 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:10:21 - utils.metrics - INFO - Level2 - 0.20895036614198118\n",
      "2023-12-16 21:10:21 - utils.metrics - INFO - Level3 - 0.17597719285507493\n",
      "2023-12-16 21:10:21 - utils.metrics - INFO - Level4 - 0.2231478621532336\n",
      "2023-12-16 21:10:21 - utils.metrics - INFO - Level5 - 0.22450474447184304\n",
      "2023-12-16 21:10:21 - utils.metrics - INFO - Level6 - 0.21327949319160858\n",
      "2023-12-16 21:10:21 - utils.metrics - INFO - Level7 - 0.20679517368308192\n",
      "2023-12-16 21:10:22 - utils.metrics - INFO - Level8 - 0.1937225083149421\n",
      "2023-12-16 21:10:22 - utils.metrics - INFO - Level9 - 0.21779645128461414\n",
      "2023-12-16 21:10:24 - __main__ - INFO - 1802 - wspl: 0.20741090794533734\n",
      "2023-12-16 21:10:27 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1830/temp_submissions/\n",
      "2023-12-16 21:10:45 - utils.metrics - INFO - reading weights file\n",
      "2023-12-16 21:10:45 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-12-16 21:11:11 - utils.metrics - INFO - entering loop ...\n",
      "2023-12-16 21:11:16 - utils.metrics - INFO - Level1 - 0.2430874375004398\n",
      "2023-12-16 21:11:17 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:11:22 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:11:39 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:11:40 - utils.metrics - INFO - Level2 - 0.2034974446141869\n",
      "2023-12-16 21:11:40 - utils.metrics - INFO - Level3 - 0.19497557475759592\n",
      "2023-12-16 21:11:40 - utils.metrics - INFO - Level4 - 0.24349888261758543\n",
      "2023-12-16 21:11:40 - utils.metrics - INFO - Level5 - 0.21846076791060634\n",
      "2023-12-16 21:11:40 - utils.metrics - INFO - Level6 - 0.2069509537705163\n",
      "2023-12-16 21:11:40 - utils.metrics - INFO - Level7 - 0.20956462649850535\n",
      "2023-12-16 21:11:40 - utils.metrics - INFO - Level8 - 0.19147941906604343\n",
      "2023-12-16 21:11:41 - utils.metrics - INFO - Level9 - 0.21704250015958493\n",
      "2023-12-16 21:11:43 - __main__ - INFO - 1830 - wspl: 0.21428417854389606\n",
      "2023-12-16 21:11:46 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1858/temp_submissions/\n",
      "2023-12-16 21:12:05 - utils.metrics - INFO - reading weights file\n",
      "2023-12-16 21:12:05 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-12-16 21:12:31 - utils.metrics - INFO - entering loop ...\n",
      "2023-12-16 21:12:37 - utils.metrics - INFO - Level1 - 0.11732598389823425\n",
      "2023-12-16 21:12:38 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:12:43 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:13:00 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:13:01 - utils.metrics - INFO - Level2 - 0.13381448436151389\n",
      "2023-12-16 21:13:01 - utils.metrics - INFO - Level3 - 0.16554805611855508\n",
      "2023-12-16 21:13:01 - utils.metrics - INFO - Level4 - 0.18993872651710067\n",
      "2023-12-16 21:13:01 - utils.metrics - INFO - Level5 - 0.1846963133852523\n",
      "2023-12-16 21:13:01 - utils.metrics - INFO - Level6 - 0.16312960745134492\n",
      "2023-12-16 21:13:01 - utils.metrics - INFO - Level7 - 0.18394834352760164\n",
      "2023-12-16 21:13:01 - utils.metrics - INFO - Level8 - 0.1810594299401598\n",
      "2023-12-16 21:13:02 - utils.metrics - INFO - Level9 - 0.1980060760603481\n",
      "2023-12-16 21:13:04 - __main__ - INFO - 1858 - wspl: 0.16860744680667897\n",
      "2023-12-16 21:13:07 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1886/temp_submissions/\n",
      "2023-12-16 21:13:26 - utils.metrics - INFO - reading weights file\n",
      "2023-12-16 21:13:26 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-12-16 21:13:53 - utils.metrics - INFO - entering loop ...\n",
      "2023-12-16 21:13:59 - utils.metrics - INFO - Level1 - 0.09950652277919664\n",
      "2023-12-16 21:14:00 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:14:05 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:14:23 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:14:24 - utils.metrics - INFO - Level2 - 0.10886077646210317\n",
      "2023-12-16 21:14:24 - utils.metrics - INFO - Level3 - 0.12148916358344793\n",
      "2023-12-16 21:14:24 - utils.metrics - INFO - Level4 - 0.12109629080584583\n",
      "2023-12-16 21:14:24 - utils.metrics - INFO - Level5 - 0.1336203131833986\n",
      "2023-12-16 21:14:24 - utils.metrics - INFO - Level6 - 0.12582693336299977\n",
      "2023-12-16 21:14:24 - utils.metrics - INFO - Level7 - 0.15656452383222522\n",
      "2023-12-16 21:14:24 - utils.metrics - INFO - Level8 - 0.14501657810752416\n",
      "2023-12-16 21:14:25 - utils.metrics - INFO - Level9 - 0.17113599213710243\n",
      "2023-12-16 21:14:27 - __main__ - INFO - 1886 - wspl: 0.13145745491709376\n",
      "2023-12-16 21:14:30 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1914/temp_submissions/\n",
      "2023-12-16 21:14:51 - utils.metrics - INFO - reading weights file\n",
      "2023-12-16 21:14:51 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-12-16 21:15:20 - utils.metrics - INFO - entering loop ...\n",
      "2023-12-16 21:15:25 - utils.metrics - INFO - Level1 - 0.15897269048648155\n",
      "2023-12-16 21:15:26 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:15:31 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:15:49 - utils.metrics - ERROR - Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "2023-12-16 21:15:50 - utils.metrics - INFO - Level2 - 0.15455154096677387\n",
      "2023-12-16 21:15:50 - utils.metrics - INFO - Level3 - 0.16504350711306404\n",
      "2023-12-16 21:15:50 - utils.metrics - INFO - Level4 - 0.18664701917377247\n",
      "2023-12-16 21:15:50 - utils.metrics - INFO - Level5 - 0.17999460367575493\n",
      "2023-12-16 21:15:50 - utils.metrics - INFO - Level6 - 0.16350156687534548\n",
      "2023-12-16 21:15:50 - utils.metrics - INFO - Level7 - 0.18589644869641997\n",
      "2023-12-16 21:15:50 - utils.metrics - INFO - Level8 - 0.1718541966618605\n",
      "2023-12-16 21:15:50 - utils.metrics - INFO - Level9 - 0.19308073254577604\n",
      "2023-12-16 21:15:52 - __main__ - INFO - 1914 - wspl: 0.17328247846613876\n",
      "2023-12-16 21:15:52 - __main__ - INFO - 1914 - mean wspl: 0.17900849333582897 +/- 0.029843395894028367\n",
      "2023-12-16 21:15:52 - __main__ - INFO - 1914 - raw results: [0.20741090794533734, 0.21428417854389606, 0.16860744680667897, 0.13145745491709376, 0.17328247846613876]\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME_ALL_RESULTS = '../data/uncertainty/all_results.json'\n",
    "USE_ALL = False\n",
    "FOLDER = 'temp_submissions/'\n",
    "\n",
    "TEST_NUMB = 0\n",
    "TEST_NUMBER = 9\n",
    "\n",
    "# load dict to store results in\n",
    "from utils.utils import load_results_as_json\n",
    "results = load_results_as_json(FILE_NAME_ALL_RESULTS)\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = []\n",
    "logger.info('start evaluating exclude columns')\n",
    "for EXCLUDE_COLUMNS in EXCLUDE_COLUMNS_LIST:\n",
    "    if 'exclude_' + ' '.join(EXCLUDE_COLUMNS) not in results.keys():\n",
    "        results['exclude_' + ' '.join(EXCLUDE_COLUMNS)] = {}\n",
    "    logger.info('--------------- ' + str(EXCLUDE_COLUMNS) + ' ---------------')\n",
    "    res = []\n",
    "    for D_CV_START in D_CROSS_VAL_START_LIST:\n",
    "        mean_wspl, res_dict = perform_cv(\n",
    "            _down_cast(d)[d_int < (D_CV_START + DAYS)], \n",
    "            read_concat_predictions(\n",
    "                fold_name = D_CV_START, \n",
    "                exclude_columns = EXCLUDE_COLUMNS,\n",
    "                include_columns = None,\n",
    "                use_all=USE_ALL,\n",
    "                load_submissions_path=FOLDER\n",
    "            )\n",
    "        )\n",
    "        res.append(mean_wspl)\n",
    "        results['exclude_' + ' '.join(EXCLUDE_COLUMNS)]['fold_' + str(D_CV_START)] = res_dict \n",
    "        logger.info(str(D_CV_START) + ' - wspl: ' + str(mean_wspl))\n",
    "\n",
    "    logger.info(' - mean wspl: ' + str(np.mean(res)) + ' +/- ' + str(np.std(res)))\n",
    "    logger.info(str(D_CV_START) + ' - raw results: ' + str(res))\n",
    "\n",
    "logger.info('start evaluating include columns')\n",
    "for INCLUDE_COLUMNS in INCLUDE_COLUMNS_LIST:\n",
    "    if 'kbest' in INCLUDE_COLUMNS:\n",
    "        INCLUDE_COLUMNS = ['k_best']\n",
    "    if 'include_' + ' '.join(INCLUDE_COLUMNS) not in results.keys():\n",
    "        results['include_' + ' '.join(INCLUDE_COLUMNS)] = {}\n",
    "    logger.info('--------------- ' + str(INCLUDE_COLUMNS) + ' ---------------')\n",
    "    res = []\n",
    "    for D_CV_START in D_CROSS_VAL_START_LIST:\n",
    "        mean_wspl, res_dict = perform_cv(\n",
    "            _down_cast(d)[d_int < (D_CV_START + DAYS)], \n",
    "            read_concat_predictions(\n",
    "                fold_name = D_CV_START, \n",
    "                exclude_columns = [], \n",
    "                include_columns = INCLUDE_COLUMNS,\n",
    "                use_all=USE_ALL,\n",
    "                load_submissions_path=FOLDER\n",
    "            )\n",
    "        )\n",
    "        res.append(mean_wspl)\n",
    "        results['include_' + ' '.join(INCLUDE_COLUMNS)]['fold_' + str(D_CV_START)] = res_dict \n",
    "        logger.info(str(D_CV_START) + ' - wspl: ' + str(mean_wspl))\n",
    "\n",
    "    logger.info(str(D_CV_START) + ' - mean wspl: ' + str(np.mean(res)) + ' +/- ' + str(np.std(res)))\n",
    "    logger.info(str(D_CV_START) + ' - raw results: ' + str(res))\n",
    "\n",
    "from utils.utils import store_results_as_json\n",
    "store_results_as_json(results, FILE_NAME_ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Beneath can be used to create submission template\n",
    "The submission template can be used to quickly insert your predictions.\n",
    "It also contains all other (historical) sales to be able to compute the WRMSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales_validation = pd.read_csv(DATA_BASE_PATH + SALES_VALIDATION)\n",
    "# sales_evaluation = pd.read_csv(DATA_BASE_PATH + SALES_EVALUATION)\n",
    "# calendar = pd.read_csv(DATA_BASE_PATH + CALENDAR)\n",
    "# sell_prices = pd.read_csv(DATA_BASE_PATH + SELL_PRICES)\n",
    "\n",
    "# df_val, submission_idx_val = data_preprocessing(sales_validation, calendar, sell_prices)\n",
    "# del sales_validation\n",
    "# df_eval, submission_idx_eval = data_preprocessing(sales_evaluation, calendar, sell_prices)\n",
    "# del sales_evaluation\n",
    "\n",
    "# df_val_after_release = df_val[(df_val.wm_yr_wk > df_val.release)]# & (df_val[\"sold\"].notna())]\n",
    "# del df_val\n",
    "# df_eval_after_release = df_eval[(df_eval.wm_yr_wk > df_eval.release)]# & (df_eval[\"sold\"].notna())]\n",
    "# del df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = []\n",
    "# df_eval_after_release['revenue'] = df_eval_after_release['sold'] * df_eval_after_release['sell_price']\n",
    "# for level in list(AGG_LEVEL_COLUMNS.keys()):\n",
    "#     c = AGG_LEVEL_COLUMNS[level]\n",
    "#     logger.info(level)\n",
    "#     agg_dict = {\n",
    "#         'sold': 'sum',\n",
    "#         'revenue': 'sum'\n",
    "#     }\n",
    "#     d1 = df_eval_after_release.groupby(c + ['d']).agg(agg_dict).reset_index(drop=False)\n",
    "#     d = pd.DataFrame({\n",
    "#         'd': d1['d'],\n",
    "#         'sold': d1['sold'],\n",
    "#         'revenue': d1['revenue']\n",
    "#     })\n",
    "#     if len(c) == 0:\n",
    "#         d['agg_column1'] = 'Total'\n",
    "#         d['agg_column2'] = 'X'\n",
    "#     elif len(c) == 1:\n",
    "#         d['agg_column1'] = d1[c[0]]\n",
    "#         d['agg_column2'] = 'X'\n",
    "#     else:\n",
    "#         d['agg_column1'] = d1[c[0]]\n",
    "#         d['agg_column2'] = d1[c[1]]\n",
    "#     d['id_merge'] = d['agg_column1'] + '_' + d['agg_column2']\n",
    "#     d['Level'] = level\n",
    "#     dfs.append(d[['Level', 'agg_column1', 'agg_column2', 'd', 'sold', 'revenue', 'id_merge']])\n",
    "# d = pd.concat(dfs)\n",
    "# d.head(50)\n",
    "# d.to_parquet('temp.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
