{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import lightgbm as lgb\n",
    "from utils.utils import _down_cast, data_preprocessing, diff_lists, log_status\n",
    "from utils.utils import ensemble_submissions, ensemble_submissions_uncertainty\n",
    "from utils.metrics import WSPL\n",
    "from utils.configure_logger import configure_logger\n",
    "from utils.utils import prefixes_in_column\n",
    "from utils import constants\n",
    "\n",
    "configure_logger()\n",
    "from logging import getLogger\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_PATH = constants.DATA_BASE_PATH\n",
    "DATA_BASE_PATH_UNCERTAINTY = constants.DATA_BASE_PATH_UNCERTAINTY\n",
    "SALES_EVALUATION = constants.SALES_EVALUATION\n",
    "SALES_VALIDATION = constants.SALES_VALIDATION\n",
    "CALENDAR = constants.CALENDAR\n",
    "SAMPLE_SUBMISSION = constants.SAMPLE_SUBMISSION \n",
    "SELL_PRICES = constants.SELL_PRICES\n",
    "\n",
    "PRECOMPUTED_BASE_PATH = constants.PRECOMPUTED_BASE_PATH\n",
    "\n",
    "DAYS: int = constants.DAYS\n",
    "QUANTILES: int = constants.QUANTILES \n",
    "\n",
    "AGG_LEVEL_COLUMNS = constants.AGG_LEVEL_COLUMNS\n",
    "D_CROSS_VAL_START_LIST = constants.D_CROSS_VAL_START_LIST\n",
    "\n",
    "# to simple get the precomputed name\n",
    "precomputed_name = lambda store, eval_val: f'processed_{store}_{eval_val}.pkl'\n",
    "\n",
    "TEST_PATH = constants.TEST_PATH#'test/'\n",
    "PREDICTION_BASE_PATH = constants.PREDICTION_BASE_PATH\n",
    "SUBMISSION_BASE_PATH = constants.SUBMISSION_BASE_PATH\n",
    "\n",
    "SUB_D_START_VAL: int = constants.SUB_D_START_VAL\n",
    "SUB_D_START_EVAL: int = constants.SUB_D_START_EVAL\n",
    "\n",
    "# the columns are always included after feature processing\n",
    "# because they are required in the training and submission format\n",
    "DROP_FEATURE_COLUMNS: list = constants.DROP_FEATURE_COLUMNS #['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'd', 'sold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GridSearch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_status\n",
    "def grid_search(\n",
    "    params: dict,\n",
    "    param_grid: dict,\n",
    "    features: pd.DataFrame, \n",
    "    targets: pd.DataFrame, \n",
    "    n_folds: int = 1,\n",
    "    fig: plt.Figure = None,\n",
    "    ax: plt.Axes = None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Given a grid with hyperparameters, train LightGBM for all possible combinations.\n",
    "    Returns the parameter set with the best score and the dictionary with all results.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    # to be sure\n",
    "    features = features.reset_index(drop=True)\n",
    "    targets = targets.reset_index(drop=True)\n",
    "\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "    results = {}\n",
    "    \n",
    "    if PLOT_EVAL and not (fig and ax):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "\n",
    "    for i, param_combination in enumerate(param_combinations,1):\n",
    "        \n",
    "        # create dictionary with all parameters\n",
    "        param_combination = {k:v for k,v in zip(param_grid.keys(), param_combination)}\n",
    "        param_combination.update(params)\n",
    "                \n",
    "        # init dict\n",
    "        results[f\"combination_{i}\"] = {\n",
    "            'params': param_combination,\n",
    "            'res': []\n",
    "        }\n",
    "        \n",
    "        # perform n_folds\n",
    "        for j in range(n_folds):\n",
    "            \n",
    "            # compute fold\n",
    "            features_train, features_validation, targets_train, targets_validation =\\\n",
    "                train_test_split(features, targets, train_size = .8, random_state=43 if n_folds == 1 else None)\n",
    "\n",
    "            # train lgb model\n",
    "            temp_dict = {} # this dict object will be used to add all (intermediate) evaluation scores during the training process\n",
    "            mod: lgb.Booster = lgb.train(param_combination, \n",
    "                train_set = lgb.Dataset(features_train, targets_train),\n",
    "                valid_sets = lgb.Dataset(features_validation, targets_validation),\n",
    "                evals_result = temp_dict,\n",
    "                verbose_eval=False\n",
    "            )\n",
    "\n",
    "            # plot results\n",
    "            if PLOT_EVAL:\n",
    "                # if not ax:\n",
    "                evals = temp_dict['valid_0']['quantile']\n",
    "                ax.plot(range(1,len(evals)+1), np.log(evals), label = 'lr: ' + str(param_combination['learning_rate']))\n",
    "                ax.set_xlim(-100, len(evals)+100)\n",
    "                \n",
    "            # store results\n",
    "            results[f\"combination_{i}\"]['res']\\\n",
    "                .append(temp_dict[\"valid_0\"][\"quantile\"][-1],\n",
    "                )\n",
    "\n",
    "        # compute average results\n",
    "        results[f\"combination_{i}\"]['validation_score'] = \\\n",
    "            np.mean(results[f\"combination_{i}\"]['res'])\n",
    "            \n",
    "        # REMOVE\n",
    "        p = results[f\"combination_{i}\"]['params']\n",
    "        logger.info(f\"{p['learning_rate']} - {p['num_leaves']} - {p['n_estimators']}\" + ' - score: ' + str(np.mean(results[f\"combination_{i}\"]['res'])) + ' ' + str(np.std(results[f\"combination_{i}\"]['res'])))\n",
    "        # REMOVE\n",
    "        \n",
    "    # sort the results based on evaluation score\n",
    "    sorted_results = dict(sorted(results.items(), key=lambda item: item[1][\"validation_score\"]))\n",
    "    return list(sorted_results.values())[0], results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoadData\n",
    "This class is used to load data much faster. The class implementation prevents reloading and processing the features over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData:\n",
    "    \"\"\" Class to load data quickly (and prevent reloading) \"\"\"\n",
    "    def __init__(self):\n",
    "        self.level = None\n",
    "        \n",
    "    def prep_data(self,level, sub_d_start):\n",
    "        \"\"\" read the precomputed features and targets for specified aggregation level,  \"\"\"\n",
    "        # define params\n",
    "        agg_level = level\n",
    "        # sub_d_start: int = int(1886)\n",
    "        exclude_columns = []\n",
    "        test = False\n",
    "        type_of = 'val'\n",
    "\n",
    "        # read file\n",
    "        agg_columns = AGG_LEVEL_COLUMNS[agg_level]\n",
    "        if len(agg_columns) == 0:\n",
    "            agg_str: str = 'Total_X'\n",
    "        elif len(agg_columns) == 1:\n",
    "            agg_str: str = f'{agg_columns[0]}_X'\n",
    "        else:\n",
    "            agg_str: str = '_'.join(agg_columns)\n",
    "\n",
    "        # if level already loaded\n",
    "        if self.level == level:\n",
    "            pass\n",
    "        else:\n",
    "            self.level = level\n",
    "            logger.info('(re)loading features')\n",
    "            features = pd.read_parquet(f'../data/uncertainty/fold_{sub_d_start}/features/' + (TEST_PATH if test else '') + f'features_{type_of}_{agg_str}.parquet')\n",
    "            features = _down_cast(features)\n",
    "\n",
    "            group_columns = agg_columns\n",
    "            exclude_prefix_list = exclude_columns # unconditional, auto, momentum, seasonal\n",
    "            \n",
    "            features_gr = features.copy()\n",
    "            features_gr = features_gr[[c for c in features_gr if c.split('_')[0] not in exclude_prefix_list]]\n",
    "\n",
    "            # preparations\n",
    "            train_idx = features_gr['sold'].notna() & features_gr['d'].isin([f'd_{sub_d_start - 1 - i}' for i in range(1460)])\n",
    "            df_train = features_gr[train_idx]\n",
    "            features_train: pd.DataFrame = df_train.drop(DROP_FEATURE_COLUMNS, axis = 1, errors = 'ignore')\n",
    "            targets_train: pd.Series = df_train['sold']\n",
    "            self.features_train = features_train\n",
    "            self.targets_train = targets_train\n",
    "        \n",
    "    def get_prep_data(self):\n",
    "        return self.features_train, self.targets_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Training a Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 16:53:52 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['auto_sold_56',\n",
       " 'auto_sold_1',\n",
       " 'auto_sold_2',\n",
       " 'auto_sold_28',\n",
       " 'auto_sold_7',\n",
       " 'auto_sold_14',\n",
       " 'auto_sold_qtile_168_0.75',\n",
       " 'auto_sold_qtile_112_0.99',\n",
       " 'auto_sold_qtile_14_0.25',\n",
       " 'auto_sold_qtile_14_0.75',\n",
       " 'auto_sold_ewm_56',\n",
       " 'auto_sold_ewm_7',\n",
       " 'auto_sold_qtile_7_0.25',\n",
       " 'auto_sold_qtile_112_0.5',\n",
       " 'auto_sold_qtile_14_0.1',\n",
       " 'auto_sold_qtile_56_0.75',\n",
       " 'auto_sold_qtile_168_0.99',\n",
       " 'auto_sold_qtile_7_0.75',\n",
       " 'auto_sold_std_168',\n",
       " 'auto_sold_ewm_3',\n",
       " 'auto_sold_qtile_56_0.25',\n",
       " 'auto_sold_qtile_168_0.01',\n",
       " 'auto_sold_ma_3',\n",
       " 'auto_sold_qtile_14_0.5',\n",
       " 'auto_sold_qtile_56_0.5',\n",
       " 'auto_sold_ewm_14',\n",
       " 'auto_sold_ewm_168',\n",
       " 'auto_sold_ma_21',\n",
       " 'auto_sold_qtile_3_0.5',\n",
       " 'auto_sold_ewm_28',\n",
       " 'auto_sold_qtile_21_0.75',\n",
       " 'auto_sold_qtile_168_0.1',\n",
       " 'auto_sold_qtile_112_0.01',\n",
       " 'auto_sold_qtile_168_0.9',\n",
       " 'auto_sold_qtile_28_0.75',\n",
       " 'auto_sold_qtile_112_0.75',\n",
       " 'auto_sold_std_3',\n",
       " 'auto_sold_qtile_21_0.9',\n",
       " 'auto_sold_qtile_21_0.25',\n",
       " 'auto_sold_ma_168',\n",
       " 'auto_sold_qtile_21_0.1',\n",
       " 'auto_sold_ma_14',\n",
       " 'auto_sold_qtile_168_0.5',\n",
       " 'auto_sold_qtile_56_0.1',\n",
       " 'auto_sold_qtile_21_0.5',\n",
       " 'auto_sold_std_7',\n",
       " 'auto_sold_qtile_112_0.25',\n",
       " 'auto_sold_qtile_28_0.1',\n",
       " 'auto_sold_std_21',\n",
       " 'auto_sold_qtile_28_0.5',\n",
       " 'auto_sold_std_14',\n",
       " 'auto_sold_std_28',\n",
       " 'auto_sold_ma_28',\n",
       " 'auto_sold_ewm_112',\n",
       " 'auto_sold_qtile_56_0.9',\n",
       " 'auto_sold_qtile_112_0.1',\n",
       " 'auto_sold_qtile_14_0.9',\n",
       " 'auto_sold_qtile_168_0.25',\n",
       " 'auto_sold_ma_112',\n",
       " 'auto_sold_qtile_112_0.9',\n",
       " 'auto_sold_std_56',\n",
       " 'auto_sold_qtile_7_0.5',\n",
       " 'auto_sold_ma_56',\n",
       " 'auto_sold_ewm_21',\n",
       " 'auto_sold_qtile_28_0.25',\n",
       " 'auto_sold_ma_7',\n",
       " 'auto_sold_qtile_28_0.9',\n",
       " 'auto_sold_std_112',\n",
       " 'price_momentum_w',\n",
       " 'price_momentum_m',\n",
       " 'price_momentum_y',\n",
       " 'price_auto_std_28',\n",
       " 'price_auto_std_56',\n",
       " 'price_auto_std_112',\n",
       " 'seasonal_weekday',\n",
       " 'seasonal_monthday',\n",
       " 'seasonal_month',\n",
       " 'days_fwd']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data example, to investigate which features are computed, among other things\n",
    "level = 'Level1'\n",
    "dataLoader = LoadData()\n",
    "dataLoader.prep_data(level, 1914)\n",
    "features, targets = dataLoader.get_prep_data()\n",
    "list(features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold\n",
    "prefixes = ['seasonal', 'auto_sold_ewm']\n",
    "features_train, features_validation, targets_train, targets_validation =\\\n",
    "    train_test_split(features, targets, test_size = 28, shuffle=False, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    # 'metric': 'quantile',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -100,\n",
    "    'n_jobs': 4,\n",
    "    \"num_leaves\": 30,\n",
    "    \"min_child_weight\": .1,\n",
    "    \"min_child_samples\": 4,\n",
    "    \"hist_pool_size\": 1000,\n",
    "    'feature_fraction': 0.9,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"n_estimators\": 2000,\n",
    "    \"max_depth\": 10,\n",
    "    'alpha': .25,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# UNCOMMENT FOR TEST RUN OF TRAINING A MODEL FOR ALL QUANTILES    \n",
    "# for q in [0.005, 0.025, 0.135, 0.25, 0.5, 0.75, 0.865, 0.975, 0.995]:\n",
    "#     params['alpha'] = q \n",
    "#     temp_dict = {}\n",
    "#     mod: lgb.Booster = lgb.train(params, \n",
    "#         train_set = lgb.Dataset(features_train, targets_train),\n",
    "#         valid_sets = lgb.Dataset(features_validation, targets_validation),\n",
    "#         evals_result = temp_dict,\n",
    "#         verbose_eval = False\n",
    "#     )\n",
    "#     plt.plot(mod.predict(features_validation), label = f'{q}')\n",
    "# plt.scatter(range(len(targets_validation.index)), targets_validation, label = 'true', s = 10)\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    # 'metric': 'quantile',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': 4,\n",
    "    'hist_pool_size': 1000,\n",
    "}\n",
    "param_grid = {\n",
    "    'max_depth': [10],\n",
    "    'n_estimators': [200, 800],\n",
    "    'min_child_samples': [4],\n",
    "    'min_child_weight': [0.1 ],\n",
    "    'num_leaves': [30], # 50, 70, 90, ],\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.02],         \n",
    "    'subsample': [ 0.9, 1],\n",
    "    'subsample_freq': [1],\n",
    "}\n",
    "\n",
    "# UNCOMMENT FOR TEST RUN OF GRID SEARCH\n",
    "# # test grid search for all quantiles\n",
    "# for q in QUANTILES[:1]:\n",
    "#     # of course, update quantile in params\n",
    "#     params['alpha'] = q\n",
    "#     best_res, res = grid_search(params, param_grid, features_train, targets_train, 1)\n",
    "#     logger.info(best_res['params'])\n",
    "\n",
    "#     mod = lgb.train(best_res['params'],\n",
    "#         train_set = lgb.Dataset(features_train, targets_train)\n",
    "#     )\n",
    "#     predictions = mod.predict(features_validation)\n",
    "#     plt.plot(predictions, label = str(q))\n",
    "\n",
    "# plt.scatter(range(len(targets_validation)), targets_validation)\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model for all quantiles for specific fold + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_level_all_quantiles(\n",
    "    agg_level: str, \n",
    "    type_of: str, \n",
    "    sub_d_start: int, \n",
    "    exclude_columns: list = [], \n",
    "    include_columns: list = None,\n",
    "    test: bool = False, \n",
    "    do_grid_search: bool = False, \n",
    "    store_submissions_path: str = None, \n",
    "    normalize: bool = False,\n",
    "):\n",
    "    \"\"\" \n",
    "    Train, for a specific aggregation level, models for all quantiles.\n",
    "    For aggregation levels 10, 11 and 12, undersampling is used to drastically reduce training time.\n",
    "    Options are to first do a grid search. Also possible to select kbest features by providing \n",
    "    'kbest' in the include_columns list.\n",
    "    Not the prettiest method but it works.\n",
    "    \"\"\"\n",
    "    if PLOT_EVAL and PLOT_PREDICTIONS:\n",
    "        raise ValueError('PLOT_EVAL and PLOT_PREDICTIONS cannot be both True')\n",
    "    \n",
    "    ALWAYS_KEEP_COLUMNS = ['days_fwd', 'sold', 'd']\n",
    "    \n",
    "    # transform 'level{i}' to agg columns concatenated\n",
    "    agg_columns = AGG_LEVEL_COLUMNS[agg_level]\n",
    "    if len(agg_columns) == 0:\n",
    "        agg_str: str = 'Total_X'\n",
    "    elif len(agg_columns) == 1:\n",
    "        agg_str: str = f'{agg_columns[0]}_X'\n",
    "    else:\n",
    "        agg_str: str = '_'.join(agg_columns)\n",
    "\n",
    "    # load feature set\n",
    "    logger.info('loading features')\n",
    "    features = pd.read_parquet(f'../data/uncertainty/fold_{sub_d_start}/features/' + (TEST_PATH if test else '') + f'features_{type_of}_{agg_str}.parquet')\n",
    "    features = _down_cast(features)\n",
    "    features_gr = features.copy()\n",
    "    \n",
    "    # seperate train/pred indices\n",
    "    train_idx = features_gr['sold'].notna() & features_gr['d'].isin([f'd_{sub_d_start - 1 - i}' for i in range(1300)])\n",
    "    pred_idx = features_gr['d'].isin([f'd_{sub_d_start + i}' for i in range(DAYS)])\n",
    "\n",
    "    group_columns = agg_columns\n",
    "    res: list = []\n",
    "    \n",
    "    def check_any_prefix_matches(column, prefixes):\n",
    "        \"\"\" Return true if any prefix is in column \"\"\"\n",
    "        for prefix in prefixes:\n",
    "            if prefix in column:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # select features\n",
    "    if USE_ALL or 'kbest' in include_columns:\n",
    "        columns = features_gr.columns\n",
    "    elif SPARSE_FEATURES:\n",
    "        columns = [c for c in features_gr.columns if c in SPARSE_FEATURES]\n",
    "    elif include_columns == None:\n",
    "        exclude_prefix_list = exclude_columns \n",
    "        columns = [c for c in features_gr.columns if not check_any_prefix_matches(c, exclude_prefix_list)]\n",
    "    elif isinstance(include_columns, list):\n",
    "        include_prefix_list = include_columns\n",
    "        columns = [c for c in features_gr.columns if check_any_prefix_matches(c, include_prefix_list)]\n",
    "\n",
    "    # add always keep columns to selected features\n",
    "    for column in ALWAYS_KEEP_COLUMNS + group_columns:\n",
    "        if column not in columns:\n",
    "            columns.append(column)\n",
    "            \n",
    "    # get final dataframes\n",
    "    features_gr = features_gr[columns]\n",
    "    df_pred = features_gr[pred_idx]\n",
    "    df_train = features_gr[train_idx]\n",
    "    # drop days of extremely low sales in high aggregation levels\n",
    "    # this is very likely a store closure or something else\n",
    "    if agg_level not in ['Level9', 'Level10', 'Level11', 'Level12']:\n",
    "        df_train = df_train[df_train['sold'] >= 20]\n",
    "\n",
    "    from copy import deepcopy\n",
    "    temp_drop_feature_columns = deepcopy(DROP_FEATURE_COLUMNS)\n",
    "    if not USE_ALL and 'kbest' not in include_columns:\n",
    "        if 'state_id' in include_prefix_list:\n",
    "            temp_drop_feature_columns.remove('state_id')\n",
    "        if 'store_id' in include_prefix_list:\n",
    "            temp_drop_feature_columns.remove('store_id')\n",
    "    if USE_ALL or 'kbest' in include_columns:\n",
    "        temp_drop_feature_columns.remove('state_id')\n",
    "        temp_drop_feature_columns.remove('store_id')\n",
    "        \n",
    "    features_train: pd.DataFrame = df_train.drop(temp_drop_feature_columns, axis = 1, errors = 'ignore')\n",
    "    targets_train: pd.Series = df_train['sold']\n",
    "    features_predict: pd.DataFrame = df_pred.drop(temp_drop_feature_columns, axis = 1, errors = 'ignore')\n",
    "    targets_test: pd.Series = df_pred['sold']\n",
    "    \n",
    "    if 'kbest' in include_columns:\n",
    "        # cannot do selectkbest for category variables\n",
    "        # others of these should always be kept\n",
    "        exclude_from_kbest = [\n",
    "            'state_id', 'store_id',\n",
    "            'seasonal_weekday', 'seasonal_monthday', 'seasonal_month', \n",
    "            'days_fwd'\n",
    "        ]\n",
    "        temp_drop_idx = features_train.drop(exclude_from_kbest, axis=1, errors='ignore').fillna(0).notna().all(axis=1)\n",
    "        from sklearn import metrics\n",
    "        from sklearn import feature_selection\n",
    "        fit = SelectKBest(\n",
    "                k=5,\n",
    "                score_func=feature_selection.f_regression\n",
    "            ).fit(\n",
    "                features_train.drop(exclude_from_kbest, axis=1, errors='ignore').fillna(0)[temp_drop_idx], \n",
    "                targets_train[temp_drop_idx]\n",
    "            )\n",
    "        # print(fit.get_feature_names_out())\n",
    "        features_keep = list(fit.get_feature_names_out())\n",
    "        for c in exclude_from_kbest:\n",
    "            if c in features_train.columns:\n",
    "                features_keep.append(c)\n",
    "        print(features_keep)\n",
    "        features_train = features_train[features_keep]\n",
    "        features_predict = features_predict[features_keep]\n",
    "    \n",
    "    # undersample data\n",
    "    if agg_level in undersampling_dict.keys() and HIGH_UNDERSAMPLING:\n",
    "        undersampling_pct = undersampling_dict[agg_level]\n",
    "        features_train, _, targets_train, _ = train_test_split(features_train, targets_train, train_size = undersampling_pct, shuffle=True, random_state=43)\n",
    "\n",
    "    # normalise targets\n",
    "    if normalize:\n",
    "        logger.info('scaling targets')\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        targets_train = scaler.fit_transform(targets_train.values.reshape(-1,1))\n",
    "        \n",
    "    if PLOT_PREDICTIONS:\n",
    "        fig, ax = plt.subplots(1,1, figsize = (10,5))\n",
    "        aaa = [i for i in range(targets_test.shape[0])]\n",
    "        \n",
    "    # train model for all quantiles\n",
    "    for quantile in QUANTILES:\n",
    "        \n",
    "        # perform grid search for best parameters\n",
    "        if do_grid_search == True:\n",
    "            # split data to training and testing\n",
    "            logger.info('perform gridsearch')\n",
    "            params['alpha'] = quantile\n",
    "            if PLOT_EVAL:\n",
    "                fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "                ax.set_title(f'LightGBM Out-of-Sample Pinball-Loss - {agg_level.capitalize()} - q: {quantile}')\n",
    "            best_combination, results = grid_search(params, param_grid, features_train, targets_train, n_folds = 1, fig = fig, ax = ax)\n",
    "            # del train_data; del validation_data\n",
    "            params_grid_train = best_combination[\"params\"]\n",
    "            logger.info(f'q: {quantile} - cv best params: {params_grid_train}')\n",
    "            \n",
    "            if PLOT_EVAL:\n",
    "                exclude_names = 'None' if len(include_prefix_list) == 0 else '_'.join(include_prefix_list)\n",
    "                ax.set_xlabel('Number of Trained Trees')\n",
    "                ax.set_ylabel('Log(Pinball-loss)')\n",
    "                ax.legend()\n",
    "                ax.grid()\n",
    "                fig.tight_layout()\n",
    "                fig.savefig('../figure/results/' + f'training_iteration_f_{sub_d_start}_include_{exclude_names}_q={quantile}.png', dpi=300)\n",
    "                plt.show()\n",
    "        \n",
    "        else:\n",
    "            params_grid_train = PARAM_GRID_TRAIN\n",
    "            params_grid_train['alpha'] = quantile\n",
    "\n",
    "        # train_best_model\n",
    "        mod = lgb.train(params_grid_train,\n",
    "            train_set = lgb.Dataset(features_train, targets_train)\n",
    "        )\n",
    "        # create filepath to store model in\n",
    "        group_names = '_'.join(group_columns)\n",
    "        if group_names == '':\n",
    "            group_names = 'Total_X'\n",
    "        if USE_ALL:\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + 'models/' + f'lgb_{type_of}_nt_{group_names}_use_all_q={quantile}.joblib'\n",
    "        elif 'kbest' in include_columns:\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + 'models/' + f'lgb_{type_of}_nt_{group_names}_include_k_best_q={quantile}.joblib'\n",
    "        elif SPARSE_FEATURES:\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + 'models/' + f'lgb_{type_of}_nt_{group_names}_sparse_q={quantile}.joblib' \n",
    "        elif include_columns == None:\n",
    "            exclude_names = 'None' if len(exclude_prefix_list) == 0 else '_'.join(exclude_prefix_list)\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + 'models/' + f'lgb_{type_of}_nt_{group_names}_exclude_{exclude_names}_q={quantile}.joblib'\n",
    "        elif isinstance(include_columns, list):\n",
    "            exclude_names = 'None' if len(include_prefix_list) == 0 else '_'.join(include_prefix_list)\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + 'models/' + f'lgb_{type_of}_nt_{group_names}_include_{exclude_names}_q={quantile}.joblib'\n",
    "\n",
    "        # save model under filepath\n",
    "        import joblib\n",
    "        joblib.dump(mod, file_path)\n",
    "        \n",
    "        # make predictions\n",
    "        predictions = mod.predict(features_predict)\n",
    "        if normalize:\n",
    "            predictions = scaler.inverse_transform(predictions.reshape(-1,1)).reshape(-1,)\n",
    "        \n",
    "        if PLOT_PREDICTIONS:\n",
    "            ax.plot(aaa, predictions, label = f'{quantile}')\n",
    "        \n",
    "        # store predictions\n",
    "        df_p = pd.DataFrame(\n",
    "            {\n",
    "                'pred': predictions,\n",
    "                'd': df_pred['d'],\n",
    "            }\n",
    "        )\n",
    "        df_p['quantile'] = quantile\n",
    "        df_p['Level'] = agg_level\n",
    "        df_p['type_of'] = 'validation' if type_of == 'val' else 'evaluation'\n",
    "        if len(agg_columns) == 0:\n",
    "            df_p['agg_column1'] = 'Total'\n",
    "            df_p['agg_column2'] = 'X'\n",
    "        elif len(agg_columns) == 1:\n",
    "            df_p['agg_column1'] = df_pred[agg_columns[0]].values\n",
    "            df_p['agg_column2'] = 'X'\n",
    "        else:\n",
    "            df_p['agg_column1'] = df_pred[agg_columns[0]].values\n",
    "            df_p['agg_column2'] = df_pred[agg_columns[1]].values\n",
    "            \n",
    "        df_p = df_p[['Level', 'agg_column1', 'agg_column2', 'd', 'quantile', 'pred', 'type_of']]\n",
    "        \n",
    "        res.append(_down_cast(df_p))\n",
    "        \n",
    "    # REMOVE THIS\n",
    "    if PLOT_PREDICTIONS:\n",
    "        plt.show()\n",
    "    # REMOVE THIS\n",
    "        \n",
    "    # remove to reduce memory usage asap\n",
    "    del features\n",
    "        \n",
    "    # storing predictions in specified file + folder\n",
    "    df_sub_val = pd.concat(res)\n",
    "    group_names = '_'.join(group_columns)\n",
    "    if group_names == '':\n",
    "        group_names = 'Total_X'\n",
    "\n",
    "    if store_submissions_path:\n",
    "        if USE_ALL:\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_{type_of}_nt_{group_names}_use_all.csv'\n",
    "        elif 'kbest' in include_columns:\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_{type_of}_nt_{group_names}_include_k_best.csv'\n",
    "        elif SPARSE_FEATURES:\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_{type_of}_nt_{group_names}_sparse.csv'  \n",
    "        elif include_columns == None:\n",
    "            exclude_names = 'None' if len(exclude_prefix_list) == 0 else '_'.join(exclude_prefix_list)\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_{type_of}_nt_{group_names}_exclude_{exclude_names}.csv'\n",
    "        elif isinstance(include_columns, list):\n",
    "            exclude_names = 'None' if len(include_prefix_list) == 0 else '_'.join(include_prefix_list)\n",
    "            file_path = f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_{type_of}_nt_{group_names}_include_{exclude_names}.csv'\n",
    "\n",
    "        df_sub_val.to_csv(file_path, index = False)\n",
    "        logger.info('saved under: ' + file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seasonal',\n",
       " 'state vs. store',\n",
       " 'ewm vs. ma',\n",
       " 'quantiles vs. std',\n",
       " 'price auto/momentum',\n",
       " 'best models',\n",
       " 'full vs. sparse ma',\n",
       " 'sparse vs. kbest',\n",
       " 'full vs. sparse']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENTS_DICT = {\n",
    "    \"seasonal\": {\n",
    "        \"BASE\": [],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold_ewm'],\n",
    "            ['seasonal_weekday','auto_sold_ewm'],\n",
    "            ['seasonal_monthday','auto_sold_ewm'],\n",
    "            ['seasonal_weekday','seasonal_monthday','auto_sold_ewm'],\n",
    "            ['seasonal','auto_sold_ewm'],\n",
    "        ]\n",
    "    },\n",
    "    \"state vs. store\": {\n",
    "        \"BASE\": ['seasonal', 'auto_sold_ma'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            [],\n",
    "            ['state_id',],\n",
    "            ['store_id',],\n",
    "            ['state_id', 'store_id']\n",
    "        ]\n",
    "    },\n",
    "    \"ewm vs. ma\": {\n",
    "        \"BASE\": ['seasonal'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold_ewm'],\n",
    "            ['auto_sold_ma'],\n",
    "            ['auto_sold_ewm', 'auto_sold_ma'],\n",
    "        ]\n",
    "    },\n",
    "    \"quantiles vs. std\": {\n",
    "        \"BASE\": ['seasonal', 'auto_sold_ma'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            [],\n",
    "            ['auto_sold_qtile'],\n",
    "            ['auto_sold_std'],\n",
    "            ['auto_sold_qtile','auto_sold_std'],   \n",
    "        ]\n",
    "    },\n",
    "    \"price auto/momentum\": {\n",
    "        \"BASE\": ['seasonal', 'auto_sold_ma'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            [],\n",
    "            ['price_auto_std'],\n",
    "            ['price_momentum'],\n",
    "            ['price_uncond'],\n",
    "            ['price_auto_std', 'price_momentum'],\n",
    "            ['price_auto_std', 'price_momentum', 'price_uncond']\n",
    "        ]\n",
    "    },\n",
    "    \"best models\": {\n",
    "        \"BASE\": ['seasonal'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold_ma', 'state_id', 'store_id'],\n",
    "            ['auto_sold_ma', 'auto_sold_std', 'state_id', 'store_id'],\n",
    "        ]\n",
    "    },\n",
    "    \"full vs. sparse ma\" : {\n",
    "        \"BASE\": ['seasonal'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold_ma', 'auto_sold_std', 'auto_sold_qtile', 'auto_sold_ewm', 'state_id', 'store_id'],\n",
    "            ['auto_sold_ma_28', 'auto_sold_ma_56', 'auto_sold_ma_168', 'state_id', 'store_id']\n",
    "        ]\n",
    "    },\n",
    "    \"sparse vs. kbest\": {\n",
    "        \"BASE\": ['seasonal', 'state_id', 'store_id'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold', 'price', 'kbest'],\n",
    "            ['auto_sold_ewm_112', 'auto_sold_ewm_28',\n",
    "             'auto_sold_qtile_28_0.5', 'auto_sold_ma_28', \n",
    "             'auto_sold_qtile_28_0.9',],\n",
    "        ]\n",
    "    },\n",
    "    'full vs. sparse': {\n",
    "        \"BASE\": ['seasonal'],\n",
    "        \"INCLUDE_COLUMNS_LIST\": [\n",
    "            ['auto_sold_ma', 'auto_sold_std', 'auto_sold_qtile', 'auto_sold_ewm', 'state_id', 'store_id'],\n",
    "            ['auto_sold_ma_28', 'auto_sold_ma_56', 'auto_sold_ma_168', 'state_id', 'store_id'],\n",
    "            ['auto_sold_std_3', 'auto_sold_std_56', 'auto_sold_std_168', \n",
    "            'auto_sold_ma_7',  'auto_sold_ma_28', 'auto_sold_ma_56', \n",
    "            'auto_sold_qtile_28_0.25', 'auto_sold_qtile_168_0.25', 'auto_sold_qtile_56_0.1', \n",
    "            'state_id', 'store_id'],\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "list(EXPERIMENTS_DICT.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_ALL = False\n",
    "SPARSE_FEATURES = None\n",
    "PLOT_PREDICTIONS = False\n",
    "\n",
    "undersampling_dict = {\n",
    "    'Level10': .1, #.001\n",
    "    'Level11': .1, #.0001\n",
    "    'Level12': .1 #.00001\n",
    "}\n",
    "\n",
    "HIGH_UNDERSAMPLING = True\n",
    "TEST_NUMBER = 9 # 9\n",
    "TEST_NUMB = 0 # 0\n",
    "PARAM_GRID_TRAIN = {\n",
    "    'objective': 'quantile',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': 4,\n",
    "    \"num_leaves\": 10, # 30\n",
    "    \"hist_pool_size\": 300,\n",
    "    \"learning_rate\": .01, # .01\n",
    "    \"n_estimators\": 1000, #1000\n",
    "    \"max_depth\": 10, #10\n",
    "}\n",
    "PARAM_GRID_TRAIN_HIGH_LEVEL = {\n",
    "    'objective': 'quantile',\n",
    "    # 'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': 4,\n",
    "    \"num_leaves\": 30,\n",
    "    \"hist_pool_size\": 300,\n",
    "    # 'feature_fraction': 0.9, #.5\n",
    "    # 'bagging_fraction': .8,\n",
    "    \"learning_rate\": .01, # .01 always\n",
    "    \"n_estimators\": 3000, # 3000 always\n",
    "    \"max_depth\": 10,\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    # 'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -100,\n",
    "    'n_jobs': 4,\n",
    "    # 'eval_at': 10,\n",
    "    'hist_pool_size': 300,\n",
    "    'verbose_eval': -100,\n",
    "}\n",
    "param_grid = {\n",
    "    'max_depth': [10,],\n",
    "    'n_estimators': [3000],#[200, 500, 1000, 2000],\n",
    "    # 'min_child_samples': [4],\n",
    "    # 'min_child_weight': [0,0.1],\n",
    "    'num_leaves': [30], #[10, 30, 90]\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.02]# [.001, .005, .01, .02],#[0.04, 0.07, 0.1],   # 0.02, 0.03,        \n",
    "    # 'subsample': [ 0.9, 1 ],\n",
    "    # 'subsample_freq': [1],\n",
    "}\n",
    "\n",
    "# ALL_PREFIXES = ['auto_sold', 'auto_sold_ma', 'auto_sold_std', 'auto_sold_ewm', 'auto_sold_qtile',\n",
    "#     'price_momentum', 'price_uncond', 'price_auto_std','seasonal_', 'state_', 'store_',\n",
    "# ]\n",
    "\n",
    "experiment_name = 'seasonal'\n",
    "experiment_name = 'full vs. sparse'\n",
    "experiment_specs = EXPERIMENTS_DICT[experiment_name]\n",
    "BASE = experiment_specs['BASE']\n",
    "INCLUDE_COLUMNS_LIST = experiment_specs['INCLUDE_COLUMNS_LIST']\n",
    "\n",
    "INCLUDE_COLUMNS_LIST = [BASE + i for i in INCLUDE_COLUMNS_LIST]\n",
    "DO_GRID_SEARCH = False\n",
    "PLOT_EVAL = False\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = ()\n",
    "logger.info('starting with all EXCLUDE_COLUMNS')\n",
    "for exclude_columns in EXCLUDE_COLUMNS_LIST: # for each specified feature combination\n",
    "    logger.info(f'Exclude columns: {str(exclude_columns)}')\n",
    "    for sub_d_start in D_CROSS_VAL_START_LIST:\n",
    "        for agg_level in list(AGG_LEVEL_COLUMNS.keys())[TEST_NUMB:TEST_NUMBER]: # for each aggregation level\n",
    "            logger.info(f'starting with agg_level: {agg_level}')\n",
    "            train_level_all_quantiles(\n",
    "                agg_level,\n",
    "                sub_d_start=sub_d_start,\n",
    "                type_of='val', \n",
    "                exclude_columns=exclude_columns,\n",
    "                do_grid_search=DO_GRID_SEARCH,\n",
    "                store_submissions_path=None#'temp_submissions/',\n",
    "            )\n",
    "logger.info('finished all EXCLUDE_COLUMNS')\n",
    "\n",
    "logger.info('---------------------------------')            \n",
    "logger.info('starting with all INCLUDE_COLUMNS')            \n",
    "for include_columns in INCLUDE_COLUMNS_LIST: # for each specified feature combination\n",
    "    logger.info(f'Include columns: {str(include_columns)}')\n",
    "    for sub_d_start in D_CROSS_VAL_START_LIST:\n",
    "        for agg_level in list(AGG_LEVEL_COLUMNS.keys())[TEST_NUMB:TEST_NUMBER]: # for each aggregation level\n",
    "            logger.info(f'starting with agg_level: {agg_level}')\n",
    "            train_level_all_quantiles(\n",
    "                agg_level,\n",
    "                sub_d_start=sub_d_start,\n",
    "                type_of='val', \n",
    "                exclude_columns=None,\n",
    "                include_columns=include_columns,\n",
    "                do_grid_search=DO_GRID_SEARCH,\n",
    "                store_submissions_path=None#'temp_submissions/',\n",
    "            )\n",
    "logger.info('finished all INCLUDE_COLUMNS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load val + eval prediction files and merge to one submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_concat_predictions(fold_name: int, exclude_columns: list = [], include_columns: list = [], sparse = False, use_all = False, load_submissions_path: str = 'temp_submissions/'):\n",
    "    \"\"\" \n",
    "    For specified fold, read the predictions for all aggregation levels \n",
    "    and stack them together in one dataframe.\n",
    "    \"\"\"\n",
    "    if fold_name not in constants.D_CROSS_VAL_START_LIST:\n",
    "        raise ValueError('fold_name must be a value in D_CV_START_LIST')\n",
    "        \n",
    "    exclude_columns = '_'.join(exclude_columns)\n",
    "    if exclude_columns == '':\n",
    "        exclude_columns = 'None'\n",
    "\n",
    "    logger.info('loading files under path:' + f'../data/uncertainty/fold_{fold_name}/' + load_submissions_path)\n",
    "\n",
    "    dfs: list = []\n",
    "    for level in list(AGG_LEVEL_COLUMNS.keys())[TEST_NUMB:TEST_NUMBER]:\n",
    "        agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "        group_names = '_'.join(agg_columns)\n",
    "        if group_names == '':\n",
    "            group_names = 'Total_X'\n",
    "        \n",
    "        file_path = f'../data/uncertainty/fold_{str(fold_name)}/' + load_submissions_path \n",
    "        file_path += f'lgb_val_nt_{group_names}_'\n",
    "        if use_all:\n",
    "            file_path += f'use_all.csv'  \n",
    "        elif include_columns == None:\n",
    "            file_path += f'exclude_{\"_\".join(exclude_columns)}.csv'            \n",
    "        elif isinstance(include_columns, list):\n",
    "            file_path += f'include_{\"_\".join(include_columns)}.csv'\n",
    "        \n",
    "        dfs.append(file_path)\n",
    "    return ensemble_submissions_uncertainty(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Validation Prediction, we can compute WRMSSE locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these variables are used later on\n",
    "FORCE_RELOAD = False\n",
    "try:\n",
    "    # simple code to check if variable exists\n",
    "    d_int + 1\n",
    "    if FORCE_RELOAD:\n",
    "        raise Exception()\n",
    "except:\n",
    "    # if not, load again\n",
    "    # takes about 2-3 minutes to reload and parse\n",
    "    # not the most beautiful method but it works\n",
    "    d = pd.read_parquet('../data/uncertainty/cv_template/temp.parquet')\n",
    "    try:\n",
    "        d_int = pd.read_parquet('../data/uncertainty/cv_template/temp_d_int.parquet')['d_int']\n",
    "    except:\n",
    "        d_int = d['d'].apply(lambda x: int(x.split('_')[1]))\n",
    "        d_int.to_frame('d_int').to_parquet('../data/uncertainty/cv_template/temp_d_int.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv(df: pd.DataFrame, df_sub: pd.DataFrame):\n",
    "    \n",
    "    # to be able to merge\n",
    "    df_sub['id_merge'] = df_sub['id']\\\n",
    "        .apply(lambda x: x.split('.')[0])\n",
    "    df_sub['quantile'] = df_sub['id']\\\n",
    "        .apply(\n",
    "            lambda x: float(\n",
    "                '.'.join([\n",
    "                x.split('.')[-2], \n",
    "                x.split('.')[-1].split('_')[0]\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # merge predictions in cv template\n",
    "    p = pd.merge(\n",
    "        df,\n",
    "        df_sub,\n",
    "        how='left',\n",
    "        on=['id_merge', 'd']\n",
    "    )\n",
    "    # del df; del df_sub_val\n",
    "    p['id_merge'] = p['id_merge'].astype(str)\n",
    "\n",
    "    for c in ['sold', 'revenue']:\n",
    "        p[c] = p[c].astype(np.float32)\n",
    "    # d = d[d_int < (D_CV_START + 28)]\n",
    "\n",
    "    return WSPL(p, [f'd_{i}' for i in range(D_CV_START, D_CV_START + 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['seasonal', 'state vs. store', 'ewm vs. ma', 'quantiles vs. std', 'price auto/momentum', 'best models', 'full vs. sparse ma', 'sparse vs. kbest', 'full vs. sparse'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENTS_DICT.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME_ALL_RESULTS = '../data/uncertainty/all_results.json'\n",
    "USE_ALL = False\n",
    "FOLDER = 'temp_submissions/'\n",
    "\n",
    "TEST_NUMB = 0\n",
    "TEST_NUMBER = 9\n",
    "\n",
    "experiment_name = 'price auto/momentum'\n",
    "experiment_specs = EXPERIMENTS_DICT[experiment_name]\n",
    "BASE = experiment_specs['BASE']\n",
    "INCLUDE_COLUMNS_LIST = experiment_specs['INCLUDE_COLUMNS_LIST']\n",
    "INCLUDE_COLUMNS_LIST = [BASE + i for i in INCLUDE_COLUMNS_LIST]\n",
    "\n",
    "# load dict to store results in\n",
    "from utils.utils import load_results_as_json\n",
    "results = load_results_as_json(FILE_NAME_ALL_RESULTS)\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = []\n",
    "logger.info('start evaluating exclude columns')\n",
    "for EXCLUDE_COLUMNS in EXCLUDE_COLUMNS_LIST:\n",
    "    if 'exclude_' + ' '.join(EXCLUDE_COLUMNS) not in results.keys():\n",
    "        results['exclude_' + ' '.join(EXCLUDE_COLUMNS)] = {}\n",
    "    logger.info('--------------- ' + str(EXCLUDE_COLUMNS) + ' ---------------')\n",
    "    res = []\n",
    "    for D_CV_START in D_CROSS_VAL_START_LIST:\n",
    "        mean_wspl, res_dict = perform_cv(\n",
    "            _down_cast(d)[d_int < (D_CV_START + DAYS)], \n",
    "            read_concat_predictions(\n",
    "                fold_name = D_CV_START, \n",
    "                exclude_columns = EXCLUDE_COLUMNS,\n",
    "                include_columns = None,\n",
    "                use_all=USE_ALL,\n",
    "                load_submissions_path=FOLDER\n",
    "            )\n",
    "        )\n",
    "        res.append(mean_wspl)\n",
    "        results['exclude_' + ' '.join(EXCLUDE_COLUMNS)]['fold_' + str(D_CV_START)] = res_dict \n",
    "        logger.info(str(D_CV_START) + ' - wspl: ' + str(mean_wspl))\n",
    "\n",
    "    logger.info(' - mean wspl: ' + str(np.mean(res)) + ' +/- ' + str(np.std(res)))\n",
    "    logger.info(str(D_CV_START) + ' - raw results: ' + str(res))\n",
    "\n",
    "logger.info('start evaluating include columns')\n",
    "for INCLUDE_COLUMNS in INCLUDE_COLUMNS_LIST:\n",
    "    if 'kbest' in INCLUDE_COLUMNS:\n",
    "        INCLUDE_COLUMNS = ['k_best']\n",
    "    if 'include_' + ' '.join(INCLUDE_COLUMNS) not in results.keys():\n",
    "        results['include_' + ' '.join(INCLUDE_COLUMNS)] = {}\n",
    "    logger.info('--------------- ' + str(INCLUDE_COLUMNS) + ' ---------------')\n",
    "    res = []\n",
    "    for D_CV_START in D_CROSS_VAL_START_LIST:\n",
    "        mean_wspl, res_dict = perform_cv(\n",
    "            _down_cast(d)[d_int < (D_CV_START + DAYS)], \n",
    "            read_concat_predictions(\n",
    "                fold_name = D_CV_START, \n",
    "                exclude_columns = [], \n",
    "                include_columns = INCLUDE_COLUMNS,\n",
    "                use_all=USE_ALL,\n",
    "                load_submissions_path=FOLDER\n",
    "            )\n",
    "        )\n",
    "        res.append(mean_wspl)\n",
    "        results['include_' + ' '.join(INCLUDE_COLUMNS)]['fold_' + str(D_CV_START)] = res_dict \n",
    "        logger.info(str(D_CV_START) + ' - wspl: ' + str(mean_wspl))\n",
    "\n",
    "    logger.info(str(D_CV_START) + ' - mean wspl: ' + str(np.mean(res)) + ' +/- ' + str(np.std(res)))\n",
    "    logger.info(str(D_CV_START) + ' - raw results: ' + str(res))\n",
    "\n",
    "from utils.utils import store_results_as_json\n",
    "store_results_as_json(results, FILE_NAME_ALL_RESULTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
