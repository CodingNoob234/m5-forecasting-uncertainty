{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, math, gc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import pickle as pkl\n",
    "from utils.utils import merge_eval_sold_on_df, sort_df_on_d, WRMSSE, RMSSE, _down_cast, data_preprocessing, diff_lists, log_status\n",
    "from utils.utils import customIter, cross_validation_on_validation_set, ensemble_submissions, ensemble_submissions_uncertainty\n",
    "from utils.metrics import WSPL\n",
    "from utils.configure_logger import configure_logger\n",
    "from utils import constants\n",
    "\n",
    "configure_logger()\n",
    "from logging import getLogger\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_PATH = constants.DATA_BASE_PATH #'../data/m5-forecasting-accuracy/'\n",
    "DATA_BASE_PATH_UNCERTAINTY = constants.DATA_BASE_PATH_UNCERTAINTY #'../data/m5-forecasting-uncertainty/'\n",
    "SALES_EVALUATION = constants.SALES_EVALUATION #'sales_train_evaluation.csv'\n",
    "SALES_VALIDATION = constants.SALES_VALIDATION #'sales_train_validation.csv'\n",
    "CALENDAR = constants.CALENDAR #'calendar.csv'\n",
    "SAMPLE_SUBMISSION = constants.SAMPLE_SUBMISSION #'sample_submission.csv'\n",
    "SELL_PRICES = constants.SELL_PRICES #'sell_prices.csv'\n",
    "\n",
    "PRECOMPUTED_BASE_PATH = constants.PRECOMPUTED_BASE_PATH #'../data/uncertainty/features/'\n",
    "\n",
    "DAYS: int = constants.DAYS #28\n",
    "QUANTILES: int = constants.QUANTILES #[0.005, 0.025, 0.165, 0.25, 0.50, 0.75, 0.835, 0.975, 0.995]\n",
    "\n",
    "AGG_LEVEL_COLUMNS = constants.AGG_LEVEL_COLUMNS\n",
    "D_CROSS_VAL_START_LIST = constants.D_CROSS_VAL_START_LIST #[1802, 1830, 1858, 1886, 1914]\n",
    "\n",
    "# to simple get the precomputed name\n",
    "precomputed_name = lambda store, eval_val: f'processed_{store}_{eval_val}.pkl'\n",
    "\n",
    "TEST_PATH = constants.TEST_PATH#'test/'\n",
    "PREDICTION_BASE_PATH = constants.PREDICTION_BASE_PATH #'../data/uncertainty/temp_submissions/'\n",
    "SUBMISSION_BASE_PATH = constants.SUBMISSION_BASE_PATH #'../data/uncertainty/final_submissions/'\n",
    "\n",
    "SUB_D_START_VAL: int = constants.SUB_D_START_VAL #1914\n",
    "SUB_D_START_EVAL: int = constants.SUB_D_START_EVAL #1914 + 28\n",
    "\n",
    "# the columns are always included after feature processing\n",
    "# because they are required in the training and submission format\n",
    "DROP_FEATURE_COLUMNS: list = constants.DROP_FEATURE_COLUMNS #['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'd', 'sold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GridSearch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_status\n",
    "def grid_search(params: dict, param_grid: dict, features, targets, n_folds: int = 1):\n",
    "    \"\"\" \n",
    "    Given a grid with parameters, train lgb model for all possible combinations.\n",
    "    Returns the parameter set with the best score and the dictionary with all results.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    # to be sure\n",
    "    features = features.reset_index(drop=True)\n",
    "    targets = targets.reset_index(drop=True)\n",
    "\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "    results = {}\n",
    "    for i, param_combination in enumerate(param_combinations,1):\n",
    "        \n",
    "        # create dictionary with all parameters\n",
    "        param_combination = {k:v for k,v in zip(param_grid.keys(), param_combination)}\n",
    "        param_combination.update(params)\n",
    "        \n",
    "        # init dict\n",
    "        results[f\"combination_{i}\"] = {\n",
    "            'params': param_combination,\n",
    "            'res': []\n",
    "        }\n",
    "        \n",
    "        # perform n_folds\n",
    "        # from sklearn.model_selection import KFold\n",
    "        # kfold = KFold(n_splits=n_folds)\n",
    "        # for j, (train_idx, validation_idx) in enumerate(kfold.split(features)):\n",
    "        \n",
    "        for j in range(n_folds):\n",
    "            \n",
    "            # kfold\n",
    "            features_train, features_validation, targets_train, targets_validation =\\\n",
    "                train_test_split(features, targets, train_size = .8, shuffle=True, random_state=42)\n",
    "        \n",
    "            # # split data for fold\n",
    "            # features_train, features_validation = features.loc[train_idx], features.loc[validation_idx]\n",
    "            # targets_train, targets_validation = targets.loc[train_idx], targets.loc[validation_idx]\n",
    "\n",
    "            # normalize\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            \n",
    "            targets_train = scaler\\\n",
    "                .fit_transform(targets_train.values.reshape(-1,1))\\\n",
    "                .reshape(-1)\n",
    "            targets_validation = scaler\\\n",
    "                .transform(targets_validation.values.reshape(-1,1))\\\n",
    "                .reshape(-1)\n",
    "\n",
    "            # train lgb model        \n",
    "            temp_dict = {} # this dict object will be used to add all (intermediate) evaluation scores during the training process\n",
    "            mod: lgb.Booster = lgb.train(param_combination, \n",
    "                train_set = lgb.Dataset(features_train, targets_train),\n",
    "                valid_sets = lgb.Dataset(features_validation, targets_validation),\n",
    "                evals_result = temp_dict\n",
    "            )\n",
    "            \n",
    "            # store results\n",
    "            results[f\"combination_{i}\"]['res']\\\n",
    "                .append(temp_dict[\"valid_0\"][\"quantile\"][-1],\n",
    "            )\n",
    "\n",
    "        # compute average results\n",
    "        results[f\"combination_{i}\"]['validation_score'] = \\\n",
    "            np.mean(results[f\"combination_{i}\"]['res'])\n",
    "        \n",
    "    # sort the results based on evaluation score\n",
    "    sorted_results = dict(sorted(results.items(), key=lambda item: item[1][\"validation_score\"]))\n",
    "    return list(sorted_results.values())[-1], results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData:\n",
    "    def __init__(self):\n",
    "        self.level = None\n",
    "        \n",
    "    def prep_data(self,level):\n",
    "        \"\"\" read the precomputed features and targets for specified aggregation level,  \"\"\"\n",
    "        # define params\n",
    "        agg_level = level\n",
    "        sub_d_start: int = int(1886)\n",
    "        exclude_columns = []\n",
    "        test = False\n",
    "        type_of = 'val'\n",
    "\n",
    "        # read file\n",
    "        agg_columns = AGG_LEVEL_COLUMNS[agg_level]\n",
    "        if len(agg_columns) == 0:\n",
    "            agg_str: str = 'Total_X'\n",
    "        elif len(agg_columns) == 1:\n",
    "            agg_str: str = f'{agg_columns[0]}_X'\n",
    "        else:\n",
    "            agg_str: str = '_'.join(agg_columns)\n",
    "\n",
    "        if self.level == level:\n",
    "            pass\n",
    "        else:\n",
    "            logger.info('(re)loading features')\n",
    "            features = pd.read_parquet(f'../data/uncertainty/fold_{sub_d_start}/features/' + (TEST_PATH if test else '') + f'features_{type_of}_{agg_str}.parquet')\n",
    "            features = _down_cast(features)\n",
    "\n",
    "        group_columns = agg_columns\n",
    "        exclude_prefix_list = exclude_columns # unconditional, auto, momentum, seasonal\n",
    "\n",
    "        features_gr = features.copy()\n",
    "        features_gr = features_gr[[c for c in features_gr if c.split('_')[0] not in exclude_prefix_list]]\n",
    "\n",
    "        # preparations\n",
    "        train_idx = features_gr['sold'].notna() & features_gr['d'].isin([f'd_{sub_d_start - 1 - i}' for i in range(1460)])\n",
    "        df_train = features_gr[train_idx]\n",
    "        features_train: pd.DataFrame = df_train.drop(DROP_FEATURE_COLUMNS, axis = 1, errors = 'ignore')\n",
    "        targets_train: pd.Series = df_train['sold']\n",
    "        return features_train, targets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 22:41:37 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto_sold_7</th>\n",
       "      <th>auto_sold_14</th>\n",
       "      <th>auto_sold_2</th>\n",
       "      <th>auto_sold_1</th>\n",
       "      <th>auto_sold_21</th>\n",
       "      <th>auto_sold_ma_180</th>\n",
       "      <th>auto_sold_ma_60</th>\n",
       "      <th>auto_sold_ma_28</th>\n",
       "      <th>auto_sold_ma_std_7</th>\n",
       "      <th>auto_sold_ma_std_60</th>\n",
       "      <th>...</th>\n",
       "      <th>seasonal_3</th>\n",
       "      <th>seasonal_9</th>\n",
       "      <th>seasonal_2</th>\n",
       "      <th>seasonal_5</th>\n",
       "      <th>seasonal_Monday</th>\n",
       "      <th>seasonal_Wednesday</th>\n",
       "      <th>seasonal_Tuesday</th>\n",
       "      <th>seasonal_12</th>\n",
       "      <th>seasonal_Saturday</th>\n",
       "      <th>seasonal_d_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13337</th>\n",
       "      <td>1247.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1567.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>342.50</td>\n",
       "      <td>280.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13338</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>346.75</td>\n",
       "      <td>282.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13339</th>\n",
       "      <td>1272.0</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>352.50</td>\n",
       "      <td>285.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13340</th>\n",
       "      <td>1511.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>1832.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>358.00</td>\n",
       "      <td>280.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13341</th>\n",
       "      <td>1887.0</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>1904.0</td>\n",
       "      <td>1567.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>291.00</td>\n",
       "      <td>278.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10220 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       auto_sold_7  auto_sold_14  auto_sold_2  auto_sold_1  auto_sold_21  \\\n",
       "2              NaN           NaN          NaN          NaN           NaN   \n",
       "3              NaN           NaN          NaN          NaN           NaN   \n",
       "4              NaN           NaN          NaN          NaN           NaN   \n",
       "5              NaN           NaN          NaN          NaN           NaN   \n",
       "6              NaN           NaN          NaN          NaN           NaN   \n",
       "...            ...           ...          ...          ...           ...   \n",
       "13337       1247.0        1280.0       1963.0       1192.0        1260.0   \n",
       "13338       1257.0        1304.0       1192.0       1117.0        1309.0   \n",
       "13339       1272.0        1431.0       1117.0       1217.0        1412.0   \n",
       "13340       1511.0        1171.0       1217.0       1213.0        1832.0   \n",
       "13341       1887.0        1812.0       1213.0       1246.0        1904.0   \n",
       "\n",
       "       auto_sold_ma_180  auto_sold_ma_60  auto_sold_ma_28  auto_sold_ma_std_7  \\\n",
       "2                   NaN              NaN              NaN                 NaN   \n",
       "3                   NaN              NaN              NaN                 NaN   \n",
       "4                   NaN              NaN              NaN                 NaN   \n",
       "5                   NaN              NaN              NaN                 NaN   \n",
       "6                   NaN              NaN              NaN                 NaN   \n",
       "...                 ...              ...              ...                 ...   \n",
       "13337            1567.0           1535.0           1496.0              342.50   \n",
       "13338            1566.0           1528.0           1484.0              346.75   \n",
       "13339            1565.0           1521.0           1456.0              352.50   \n",
       "13340            1566.0           1509.0           1435.0              358.00   \n",
       "13341            1567.0           1503.0           1420.0              291.00   \n",
       "\n",
       "       auto_sold_ma_std_60  ...  seasonal_3  seasonal_9  seasonal_2  \\\n",
       "2                      NaN  ...         0.0         0.0         0.0   \n",
       "3                      NaN  ...         0.0         0.0         0.0   \n",
       "4                      NaN  ...         0.0         0.0         0.0   \n",
       "5                      NaN  ...         0.0         0.0         0.0   \n",
       "6                      NaN  ...         0.0         0.0         0.0   \n",
       "...                    ...  ...         ...         ...         ...   \n",
       "13337               280.00  ...         0.0         0.0         0.0   \n",
       "13338               282.50  ...         0.0         0.0         0.0   \n",
       "13339               285.00  ...         0.0         0.0         0.0   \n",
       "13340               280.50  ...         0.0         0.0         0.0   \n",
       "13341               278.25  ...         0.0         0.0         0.0   \n",
       "\n",
       "       seasonal_5  seasonal_Monday  seasonal_Wednesday  seasonal_Tuesday  \\\n",
       "2             0.0              0.0                 0.0               0.0   \n",
       "3             0.0              0.0                 0.0               0.0   \n",
       "4             0.0              0.0                 0.0               0.0   \n",
       "5             0.0              0.0                 0.0               0.0   \n",
       "6             0.0              1.0                 0.0               0.0   \n",
       "...           ...              ...                 ...               ...   \n",
       "13337         0.0              0.0                 0.0               0.0   \n",
       "13338         0.0              0.0                 0.0               0.0   \n",
       "13339         0.0              1.0                 0.0               0.0   \n",
       "13340         0.0              0.0                 0.0               1.0   \n",
       "13341         0.0              0.0                 1.0               0.0   \n",
       "\n",
       "       seasonal_12  seasonal_Saturday  seasonal_d_int  \n",
       "2              0.0                0.0          1000.0  \n",
       "3              0.0                0.0          1001.0  \n",
       "4              0.0                1.0          1002.0  \n",
       "5              0.0                0.0          1003.0  \n",
       "6              0.0                0.0          1004.0  \n",
       "...            ...                ...             ...  \n",
       "13337          0.0                1.0           995.0  \n",
       "13338          0.0                0.0           996.0  \n",
       "13339          0.0                0.0           997.0  \n",
       "13340          0.0                0.0           998.0  \n",
       "13341          0.0                0.0           999.0  \n",
       "\n",
       "[10220 rows x 63 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level = 'Level5'\n",
    "q = .5\n",
    "n_est = 200 # 200\n",
    "lr = .07 #.2\n",
    "\n",
    "def prefixes_in_column(column, prefixes):\n",
    "    s = 0\n",
    "    for prefix in prefixes:\n",
    "        s += prefix_in_column(column, prefix)\n",
    "    return True if s>0 else False\n",
    "\n",
    "def prefix_in_column(column, prefix):\n",
    "    return 1 if prefix in column else 0\n",
    "\n",
    "dataLoader = LoadData()\n",
    "features, targets = dataLoader.prep_data(level)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autoquantiles_sold_ma_180_0.25</th>\n",
       "      <th>autoquantiles_sold_ma_180_0.995</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.995</th>\n",
       "      <th>autoquantiles_sold_ma_180_0.005</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.025</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.75</th>\n",
       "      <th>autoquantiles_sold_ma_180_0.75</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.995</th>\n",
       "      <th>autoquantiles_sold_ma_180_0.975</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.005</th>\n",
       "      <th>...</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.5</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.025</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.165</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.5</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.25</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.25</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.975</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.005</th>\n",
       "      <th>autoquantiles_sold_ma_30_0.835</th>\n",
       "      <th>autoquantiles_sold_ma_60_0.835</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13337</th>\n",
       "      <td>1357.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>1872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13338</th>\n",
       "      <td>1357.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>1872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13339</th>\n",
       "      <td>1355.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>1872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13340</th>\n",
       "      <td>1355.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>1842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13341</th>\n",
       "      <td>1357.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>1842.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10220 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       autoquantiles_sold_ma_180_0.25  autoquantiles_sold_ma_180_0.995  \\\n",
       "2                                 NaN                              NaN   \n",
       "3                                 NaN                              NaN   \n",
       "4                                 NaN                              NaN   \n",
       "5                                 NaN                              NaN   \n",
       "6                                 NaN                              NaN   \n",
       "...                               ...                              ...   \n",
       "13337                          1357.0                           2194.0   \n",
       "13338                          1357.0                           2194.0   \n",
       "13339                          1355.0                           2194.0   \n",
       "13340                          1355.0                           2194.0   \n",
       "13341                          1357.0                           2194.0   \n",
       "\n",
       "       autoquantiles_sold_ma_60_0.995  autoquantiles_sold_ma_180_0.005  \\\n",
       "2                                 NaN                              NaN   \n",
       "3                                 NaN                              NaN   \n",
       "4                                 NaN                              NaN   \n",
       "5                                 NaN                              NaN   \n",
       "6                                 NaN                              NaN   \n",
       "...                               ...                              ...   \n",
       "13337                          2084.0                           1075.0   \n",
       "13338                          2084.0                           1075.0   \n",
       "13339                          2084.0                           1075.0   \n",
       "13340                          2084.0                           1078.0   \n",
       "13341                          2084.0                           1078.0   \n",
       "\n",
       "       autoquantiles_sold_ma_30_0.025  autoquantiles_sold_ma_30_0.75  \\\n",
       "2                                 NaN                            NaN   \n",
       "3                                 NaN                            NaN   \n",
       "4                                 NaN                            NaN   \n",
       "5                                 NaN                            NaN   \n",
       "6                                 NaN                            NaN   \n",
       "...                               ...                            ...   \n",
       "13337                          1156.0                         1827.0   \n",
       "13338                          1156.0                         1827.0   \n",
       "13339                          1156.0                         1827.0   \n",
       "13340                          1156.0                         1827.0   \n",
       "13341                          1156.0                         1737.0   \n",
       "\n",
       "       autoquantiles_sold_ma_180_0.75  autoquantiles_sold_ma_30_0.995  \\\n",
       "2                                 NaN                             NaN   \n",
       "3                                 NaN                             NaN   \n",
       "4                                 NaN                             NaN   \n",
       "5                                 NaN                             NaN   \n",
       "6                                 NaN                             NaN   \n",
       "...                               ...                             ...   \n",
       "13337                          1760.0                          2013.0   \n",
       "13338                          1760.0                          2013.0   \n",
       "13339                          1760.0                          2013.0   \n",
       "13340                          1760.0                          2013.0   \n",
       "13341                          1760.0                          2011.0   \n",
       "\n",
       "       autoquantiles_sold_ma_180_0.975  autoquantiles_sold_ma_60_0.005  ...  \\\n",
       "2                                  NaN                             NaN  ...   \n",
       "3                                  NaN                             NaN  ...   \n",
       "4                                  NaN                             NaN  ...   \n",
       "5                                  NaN                             NaN  ...   \n",
       "6                                  NaN                             NaN  ...   \n",
       "...                                ...                             ...  ...   \n",
       "13337                           2096.0                          1133.0  ...   \n",
       "13338                           2096.0                          1133.0  ...   \n",
       "13339                           2096.0                          1133.0  ...   \n",
       "13340                           2096.0                          1133.0  ...   \n",
       "13341                           2096.0                          1133.0  ...   \n",
       "\n",
       "       autoquantiles_sold_ma_60_0.5  autoquantiles_sold_ma_60_0.025  \\\n",
       "2                               NaN                             NaN   \n",
       "3                               NaN                             NaN   \n",
       "4                               NaN                             NaN   \n",
       "5                               NaN                             NaN   \n",
       "6                               NaN                             NaN   \n",
       "...                             ...                             ...   \n",
       "13337                        1458.0                          1181.0   \n",
       "13338                        1442.0                          1181.0   \n",
       "13339                        1430.0                          1181.0   \n",
       "13340                        1420.0                          1181.0   \n",
       "13341                        1420.0                          1181.0   \n",
       "\n",
       "       autoquantiles_sold_ma_60_0.165  autoquantiles_sold_ma_30_0.5  \\\n",
       "2                                 NaN                           NaN   \n",
       "3                                 NaN                           NaN   \n",
       "4                                 NaN                           NaN   \n",
       "5                                 NaN                           NaN   \n",
       "6                                 NaN                           NaN   \n",
       "...                               ...                           ...   \n",
       "13337                          1262.0                        1319.0   \n",
       "13338                          1259.0                        1319.0   \n",
       "13339                          1256.0                        1307.0   \n",
       "13340                          1252.0                        1304.0   \n",
       "13341                          1252.0                        1304.0   \n",
       "\n",
       "       autoquantiles_sold_ma_60_0.25  autoquantiles_sold_ma_30_0.25  \\\n",
       "2                                NaN                            NaN   \n",
       "3                                NaN                            NaN   \n",
       "4                                NaN                            NaN   \n",
       "5                                NaN                            NaN   \n",
       "6                                NaN                            NaN   \n",
       "...                              ...                            ...   \n",
       "13337                         1296.0                         1263.0   \n",
       "13338                         1279.0                         1263.0   \n",
       "13339                         1276.0                         1258.0   \n",
       "13340                         1270.0                         1250.0   \n",
       "13341                         1270.0                         1250.0   \n",
       "\n",
       "       autoquantiles_sold_ma_60_0.975  autoquantiles_sold_ma_30_0.005  \\\n",
       "2                                 NaN                             NaN   \n",
       "3                                 NaN                             NaN   \n",
       "4                                 NaN                             NaN   \n",
       "5                                 NaN                             NaN   \n",
       "6                                 NaN                             NaN   \n",
       "...                               ...                             ...   \n",
       "13337                          2042.0                          1125.0   \n",
       "13338                          2042.0                          1125.0   \n",
       "13339                          2042.0                          1125.0   \n",
       "13340                          2042.0                          1125.0   \n",
       "13341                          2042.0                          1125.0   \n",
       "\n",
       "       autoquantiles_sold_ma_30_0.835  autoquantiles_sold_ma_60_0.835  \n",
       "2                                 NaN                             NaN  \n",
       "3                                 NaN                             NaN  \n",
       "4                                 NaN                             NaN  \n",
       "5                                 NaN                             NaN  \n",
       "6                                 NaN                             NaN  \n",
       "...                               ...                             ...  \n",
       "13337                          1871.0                          1872.0  \n",
       "13338                          1871.0                          1872.0  \n",
       "13339                          1871.0                          1872.0  \n",
       "13340                          1871.0                          1842.0  \n",
       "13341                          1840.0                          1842.0  \n",
       "\n",
       "[10220 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixes = ['autoquantiles_']\n",
    "features[[c for c in features.columns if prefixes_in_column(c, prefixes)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's quantile: 1729.91\n",
      "[2]\tvalid_0's quantile: 1694.05\n",
      "[3]\tvalid_0's quantile: 1650.63\n",
      "[4]\tvalid_0's quantile: 1605.27\n",
      "[5]\tvalid_0's quantile: 1577.66\n",
      "[6]\tvalid_0's quantile: 1499.68\n",
      "[7]\tvalid_0's quantile: 1475.53\n",
      "[8]\tvalid_0's quantile: 1449.38\n",
      "[9]\tvalid_0's quantile: 1427.01\n",
      "[10]\tvalid_0's quantile: 1362.98\n",
      "[11]\tvalid_0's quantile: 1300.71\n",
      "[12]\tvalid_0's quantile: 1262.49\n",
      "[13]\tvalid_0's quantile: 1246.82\n",
      "[14]\tvalid_0's quantile: 1222.83\n",
      "[15]\tvalid_0's quantile: 1190.92\n",
      "[16]\tvalid_0's quantile: 1152.73\n",
      "[17]\tvalid_0's quantile: 1125.6\n",
      "[18]\tvalid_0's quantile: 1086.98\n",
      "[19]\tvalid_0's quantile: 1049.39\n",
      "[20]\tvalid_0's quantile: 1014.72\n",
      "[21]\tvalid_0's quantile: 1005.85\n",
      "[22]\tvalid_0's quantile: 990.35\n",
      "[23]\tvalid_0's quantile: 982.928\n",
      "[24]\tvalid_0's quantile: 976.946\n",
      "[25]\tvalid_0's quantile: 953.159\n",
      "[26]\tvalid_0's quantile: 946.767\n",
      "[27]\tvalid_0's quantile: 924.104\n",
      "[28]\tvalid_0's quantile: 917.64\n",
      "[29]\tvalid_0's quantile: 902.987\n",
      "[30]\tvalid_0's quantile: 881.133\n",
      "[31]\tvalid_0's quantile: 863.997\n",
      "[32]\tvalid_0's quantile: 853.943\n",
      "[33]\tvalid_0's quantile: 846.812\n",
      "[34]\tvalid_0's quantile: 833.272\n",
      "[35]\tvalid_0's quantile: 830.76\n",
      "[36]\tvalid_0's quantile: 825.642\n",
      "[37]\tvalid_0's quantile: 822.522\n",
      "[38]\tvalid_0's quantile: 819.969\n",
      "[39]\tvalid_0's quantile: 817.771\n",
      "[40]\tvalid_0's quantile: 818.621\n",
      "[41]\tvalid_0's quantile: 818.156\n",
      "[42]\tvalid_0's quantile: 817.018\n",
      "[43]\tvalid_0's quantile: 812.17\n",
      "[44]\tvalid_0's quantile: 810.928\n",
      "[45]\tvalid_0's quantile: 809.01\n",
      "[46]\tvalid_0's quantile: 808.512\n",
      "[47]\tvalid_0's quantile: 799.723\n",
      "[48]\tvalid_0's quantile: 799.36\n",
      "[49]\tvalid_0's quantile: 799.834\n",
      "[50]\tvalid_0's quantile: 799.563\n",
      "[51]\tvalid_0's quantile: 798.746\n",
      "[52]\tvalid_0's quantile: 799.744\n",
      "[53]\tvalid_0's quantile: 798.885\n",
      "[54]\tvalid_0's quantile: 795.327\n",
      "[55]\tvalid_0's quantile: 797.537\n",
      "[56]\tvalid_0's quantile: 790.694\n",
      "[57]\tvalid_0's quantile: 785.887\n",
      "[58]\tvalid_0's quantile: 786.092\n",
      "[59]\tvalid_0's quantile: 783.732\n",
      "[60]\tvalid_0's quantile: 785.813\n",
      "[61]\tvalid_0's quantile: 785.387\n",
      "[62]\tvalid_0's quantile: 780.944\n",
      "[63]\tvalid_0's quantile: 781.214\n",
      "[64]\tvalid_0's quantile: 782.247\n",
      "[65]\tvalid_0's quantile: 782.541\n",
      "[66]\tvalid_0's quantile: 782.272\n",
      "[67]\tvalid_0's quantile: 781.811\n",
      "[68]\tvalid_0's quantile: 781.806\n",
      "[69]\tvalid_0's quantile: 782.199\n",
      "[70]\tvalid_0's quantile: 780.749\n",
      "[71]\tvalid_0's quantile: 779.841\n",
      "[72]\tvalid_0's quantile: 780.582\n",
      "[73]\tvalid_0's quantile: 780.97\n",
      "[74]\tvalid_0's quantile: 781.837\n",
      "[75]\tvalid_0's quantile: 782.3\n",
      "[76]\tvalid_0's quantile: 782.47\n",
      "[77]\tvalid_0's quantile: 781.892\n",
      "[78]\tvalid_0's quantile: 781.572\n",
      "[79]\tvalid_0's quantile: 781.091\n",
      "[80]\tvalid_0's quantile: 780.5\n",
      "[81]\tvalid_0's quantile: 780.342\n",
      "[82]\tvalid_0's quantile: 779.951\n",
      "[83]\tvalid_0's quantile: 779.911\n",
      "[84]\tvalid_0's quantile: 780.102\n",
      "[85]\tvalid_0's quantile: 780.386\n",
      "[86]\tvalid_0's quantile: 780.427\n",
      "[87]\tvalid_0's quantile: 780.264\n",
      "[88]\tvalid_0's quantile: 780.805\n",
      "[89]\tvalid_0's quantile: 780.548\n",
      "[90]\tvalid_0's quantile: 781.22\n",
      "[91]\tvalid_0's quantile: 779.886\n",
      "[92]\tvalid_0's quantile: 779.798\n",
      "[93]\tvalid_0's quantile: 779.692\n",
      "[94]\tvalid_0's quantile: 779.798\n",
      "[95]\tvalid_0's quantile: 778.97\n",
      "[96]\tvalid_0's quantile: 780.109\n",
      "[97]\tvalid_0's quantile: 780.122\n",
      "[98]\tvalid_0's quantile: 780.322\n",
      "[99]\tvalid_0's quantile: 780.737\n",
      "[100]\tvalid_0's quantile: 780.849\n",
      "[101]\tvalid_0's quantile: 780.997\n",
      "[102]\tvalid_0's quantile: 781.108\n",
      "[103]\tvalid_0's quantile: 781.204\n",
      "[104]\tvalid_0's quantile: 781.889\n",
      "[105]\tvalid_0's quantile: 782.193\n",
      "[106]\tvalid_0's quantile: 782.724\n",
      "[107]\tvalid_0's quantile: 783.155\n",
      "[108]\tvalid_0's quantile: 783.373\n",
      "[109]\tvalid_0's quantile: 783.85\n",
      "[110]\tvalid_0's quantile: 784.098\n",
      "[111]\tvalid_0's quantile: 784.568\n",
      "[112]\tvalid_0's quantile: 784.621\n",
      "[113]\tvalid_0's quantile: 785.012\n",
      "[114]\tvalid_0's quantile: 785.449\n",
      "[115]\tvalid_0's quantile: 786.241\n",
      "[116]\tvalid_0's quantile: 786.572\n",
      "[117]\tvalid_0's quantile: 786.233\n",
      "[118]\tvalid_0's quantile: 786.858\n",
      "[119]\tvalid_0's quantile: 787.346\n",
      "[120]\tvalid_0's quantile: 789.189\n",
      "[121]\tvalid_0's quantile: 789.281\n",
      "[122]\tvalid_0's quantile: 789.94\n",
      "[123]\tvalid_0's quantile: 789.611\n",
      "[124]\tvalid_0's quantile: 789.825\n",
      "[125]\tvalid_0's quantile: 790.077\n",
      "[126]\tvalid_0's quantile: 789.981\n",
      "[127]\tvalid_0's quantile: 789.884\n",
      "[128]\tvalid_0's quantile: 789.81\n",
      "[129]\tvalid_0's quantile: 789.828\n",
      "[130]\tvalid_0's quantile: 790.198\n",
      "[131]\tvalid_0's quantile: 790.101\n",
      "[132]\tvalid_0's quantile: 790.135\n",
      "[133]\tvalid_0's quantile: 790.024\n",
      "[134]\tvalid_0's quantile: 790.163\n",
      "[135]\tvalid_0's quantile: 790.089\n",
      "[136]\tvalid_0's quantile: 790.701\n",
      "[137]\tvalid_0's quantile: 790.521\n",
      "[138]\tvalid_0's quantile: 790.757\n",
      "[139]\tvalid_0's quantile: 790.812\n",
      "[140]\tvalid_0's quantile: 790.628\n",
      "[141]\tvalid_0's quantile: 790.568\n",
      "[142]\tvalid_0's quantile: 790.456\n",
      "[143]\tvalid_0's quantile: 790.497\n",
      "[144]\tvalid_0's quantile: 790.809\n",
      "[145]\tvalid_0's quantile: 790.782\n",
      "[146]\tvalid_0's quantile: 790.766\n",
      "[147]\tvalid_0's quantile: 790.851\n",
      "[148]\tvalid_0's quantile: 790.799\n",
      "[149]\tvalid_0's quantile: 789.914\n",
      "[150]\tvalid_0's quantile: 789.772\n",
      "[151]\tvalid_0's quantile: 789.775\n",
      "[152]\tvalid_0's quantile: 789.332\n",
      "[153]\tvalid_0's quantile: 791.646\n",
      "[154]\tvalid_0's quantile: 791.897\n",
      "[155]\tvalid_0's quantile: 791.425\n",
      "[156]\tvalid_0's quantile: 791.393\n",
      "[157]\tvalid_0's quantile: 792.187\n",
      "[158]\tvalid_0's quantile: 792.165\n",
      "[159]\tvalid_0's quantile: 792.383\n",
      "[160]\tvalid_0's quantile: 792.463\n",
      "[161]\tvalid_0's quantile: 792.66\n",
      "[162]\tvalid_0's quantile: 793.606\n",
      "[163]\tvalid_0's quantile: 793.48\n",
      "[164]\tvalid_0's quantile: 793.877\n",
      "[165]\tvalid_0's quantile: 793.852\n",
      "[166]\tvalid_0's quantile: 793.954\n",
      "[167]\tvalid_0's quantile: 794.067\n",
      "[168]\tvalid_0's quantile: 794.523\n",
      "[169]\tvalid_0's quantile: 794.844\n",
      "[170]\tvalid_0's quantile: 794.648\n",
      "[171]\tvalid_0's quantile: 794.756\n",
      "[172]\tvalid_0's quantile: 795.676\n",
      "[173]\tvalid_0's quantile: 795.664\n",
      "[174]\tvalid_0's quantile: 795.775\n",
      "[175]\tvalid_0's quantile: 795.804\n",
      "[176]\tvalid_0's quantile: 795.841\n",
      "[177]\tvalid_0's quantile: 795.874\n",
      "[178]\tvalid_0's quantile: 797.514\n",
      "[179]\tvalid_0's quantile: 796.967\n",
      "[180]\tvalid_0's quantile: 796.728\n",
      "[181]\tvalid_0's quantile: 796.666\n",
      "[182]\tvalid_0's quantile: 796.79\n",
      "[183]\tvalid_0's quantile: 796.958\n",
      "[184]\tvalid_0's quantile: 797.141\n",
      "[185]\tvalid_0's quantile: 797.052\n",
      "[186]\tvalid_0's quantile: 797.118\n",
      "[187]\tvalid_0's quantile: 797.126\n",
      "[188]\tvalid_0's quantile: 797.119\n",
      "[189]\tvalid_0's quantile: 797.027\n",
      "[190]\tvalid_0's quantile: 797.468\n",
      "[191]\tvalid_0's quantile: 797.741\n",
      "[192]\tvalid_0's quantile: 797.564\n",
      "[193]\tvalid_0's quantile: 797.591\n",
      "[194]\tvalid_0's quantile: 797.788\n",
      "[195]\tvalid_0's quantile: 797.698\n",
      "[196]\tvalid_0's quantile: 797.993\n",
      "[197]\tvalid_0's quantile: 797.93\n",
      "[198]\tvalid_0's quantile: 798.129\n",
      "[199]\tvalid_0's quantile: 798.103\n",
      "[200]\tvalid_0's quantile: 798.115\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# kfold\n",
    "prefixes = ['autoquantiles_']\n",
    "features_train, features_validation, targets_train, targets_validation =\\\n",
    "    train_test_split(features[[c for c in features.columns if prefixes_in_column(c, prefixes)]], targets, train_size = .8, shuffle=True, random_state=42)\n",
    "\n",
    "# undersample training features\n",
    "under_sample_pct = .01\n",
    "features_train, _, targets_train, _ = train_test_split(features_train, targets_train, train_size=under_sample_pct, shuffle=True, random_state=42)\n",
    "\n",
    "# define params\n",
    "n_est = 200\n",
    "lr = .001\n",
    "# params = {\n",
    "#     'objective': 'quantile',\n",
    "#     'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'random_state': 43,\n",
    "#     'verbose': -1,\n",
    "#     'n_jobs': 4,\n",
    "#     'subsample': .5,#.5\n",
    "#     'subsample_freq': 1,\n",
    "#     \"num_leaves\": 2**8-1,#2**8-1,\n",
    "#     # 'min_data_in_leaf': 15,#2**8-1,\n",
    "#     'feature_fraction': 1, #.5\n",
    "#     'bagging_fraction': .8,\n",
    "#     \"learning_rate\": lr,\n",
    "#     \"n_estimators\": n_est,#100\n",
    "#     # \"max_bin\": 100,\n",
    "#     'boost_from_average': False,\n",
    "#     # \"tweedie_variance_power\": 1.1, # Set the Tweedie variance power (1 <= p <= 2)\n",
    "    \n",
    "#     'reg_sqrt': True,\n",
    "#     'alpha': q,\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    # 'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': 4,\n",
    "    'subsample': .9,\n",
    "    'subsample_freq': 1,\n",
    "    \"num_leaves\": 30,\n",
    "    \"min_child_weight\": .1,\n",
    "    \"min_child_samples\": 4,\n",
    "    \"hist_pool_size\": 1000,\n",
    "    # 'feature_fraction': 0.5, #.5\n",
    "    # 'bagging_fraction': .8,\n",
    "    \"learning_rate\": 0.07,\n",
    "    \"n_estimators\": 200,#100\n",
    "    \"max_depth\": 10,\n",
    "    # 'reg_sqrt': True,\n",
    "    # 'req_lambda': .00001,\n",
    "    # 'reg_alpha': .00001,\n",
    "    'alpha': q,\n",
    "}\n",
    "\n",
    "# # normalize\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# targets_train = scaler\\\n",
    "#     .fit_transform(targets_train.values.reshape(-1,1))\\\n",
    "#     .reshape(-1)\n",
    "# targets_validation = scaler\\\n",
    "#     .transform(targets_validation.values.reshape(-1,1))\\\n",
    "#     .reshape(-1)\n",
    "\n",
    "# train lgb model        \n",
    "temp_dict = {}\n",
    "mod: lgb.Booster = lgb.train(params, \n",
    "    train_set = lgb.Dataset(features_train, targets_train),\n",
    "    valid_sets = lgb.Dataset(features_validation, targets_validation),\n",
    "    evals_result = temp_dict\n",
    ")\n",
    "\n",
    "# plot distribution of residuals, should have roughly q*n values on the left, and (1-q)*n values on the right\n",
    "plt.hist(mod.predict(features_validation) - targets_validation, bins=200)\n",
    "plt.show()\n",
    "\n",
    "# plot prediction vs. true outcome (with quantile regression, this should correspond to confidence bounds)\n",
    "n = 100\n",
    "idx = targets_validation[:n].index\n",
    "plt.scatter(idx, mod.predict(features_validation)[:n], label = 'pred')\n",
    "plt.scatter(idx, targets_validation[:n], label = 'true')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# plot histogram of targets \n",
    "plt.hist(targets)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# plot log(loss) of training iterations to get insights in convergence\n",
    "plt.plot(np.log(temp_dict[\"valid_0\"][\"quantile\"]))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['auto_sold_7', 'auto_sold_14', 'auto_sold_2', 'auto_sold_1',\n",
       "       'auto_sold_21', 'auto_sold_ma_180', 'auto_sold_ma_60',\n",
       "       'auto_sold_ma_28', 'auto_sold_ma_std_7', 'auto_sold_ma_std_60',\n",
       "       'auto_sold_ma_7', 'auto_sold_ma_std_180', 'auto_sold_ma_std_28',\n",
       "       'autoquantiles_sold_ma_180_0.25', 'autoquantiles_sold_ma_180_0.995',\n",
       "       'autoquantiles_sold_ma_60_0.995', 'autoquantiles_sold_ma_180_0.005',\n",
       "       'autoquantiles_sold_ma_30_0.025', 'autoquantiles_sold_ma_30_0.75',\n",
       "       'autoquantiles_sold_ma_180_0.75', 'autoquantiles_sold_ma_30_0.995',\n",
       "       'autoquantiles_sold_ma_180_0.975', 'autoquantiles_sold_ma_60_0.005',\n",
       "       'autoquantiles_sold_ma_30_0.975', 'autoquantiles_sold_ma_60_0.75',\n",
       "       'autoquantiles_sold_ma_180_0.165', 'autoquantiles_sold_ma_30_0.165',\n",
       "       'autoquantiles_sold_ma_180_0.835', 'autoquantiles_sold_ma_180_0.025',\n",
       "       'autoquantiles_sold_ma_180_0.5', 'autoquantiles_sold_ma_60_0.5',\n",
       "       'autoquantiles_sold_ma_60_0.025', 'autoquantiles_sold_ma_60_0.165',\n",
       "       'autoquantiles_sold_ma_30_0.5', 'autoquantiles_sold_ma_60_0.25',\n",
       "       'autoquantiles_sold_ma_30_0.25', 'autoquantiles_sold_ma_60_0.975',\n",
       "       'autoquantiles_sold_ma_30_0.005', 'autoquantiles_sold_ma_30_0.835',\n",
       "       'autoquantiles_sold_ma_60_0.835', 'momentum_sell_price_m',\n",
       "       'momentum_sell_price_w', 'momentum_sell_price_y', 'seasonal_8',\n",
       "       'seasonal_10', 'seasonal_1', 'seasonal_Friday', 'seasonal_4',\n",
       "       'seasonal_Sunday', 'seasonal_11', 'seasonal_Thursday', 'seasonal_7',\n",
       "       'seasonal_6', 'seasonal_3', 'seasonal_9', 'seasonal_2', 'seasonal_5',\n",
       "       'seasonal_Monday', 'seasonal_Wednesday', 'seasonal_Tuesday',\n",
       "       'seasonal_12', 'seasonal_Saturday', 'seasonal_d_int'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Run for Testing Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total ~280 seconds\n",
    "params = {\n",
    "    'objective': 'quantile',\n",
    "    'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 43,\n",
    "    'verbose': 1,\n",
    "    'n_jobs': 4,\n",
    "    'eval_at': 100,\n",
    "    # 'verbose_eval': 0\n",
    "    'subsample': 0.5,\n",
    "    'subsample_freq': 1,\n",
    "    'feature_fraction': 0.5,\n",
    "    'boost_from_average': False,\n",
    "    'alpha': .975\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"num_leaves\": [255], #[int(2**i) for i in [5, 6, 8]],\n",
    "    'min_data_in_leaf': [255], #[int(2**i -1) for i in [5, 6, 8]]\n",
    "    \"learning_rate\": [0.01],#[0.04, 0.02, 0.01, 0.005],\n",
    "    \"n_estimators\": [5000], # [5000, 500, 100]\n",
    "    # \"tweedie_variance_power\": [1.1], # Set the Tweedie variance power (1 <= p <= 2)\n",
    "    # 'max_bin': [100]\n",
    "}\n",
    "\n",
    "features_train, targets_train = prep_data('Level5')\n",
    "grid_search(params, param_grid, features_train, targets_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train + Predict submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_level_all_quantiles(agg_level: str, type_of: str, sub_d_start: int, exclude_columns: list = [], test: bool = False, do_grid_search: bool = False, store_submissions_path: str = 'temp_submissions/'):\n",
    "    \"\"\" \n",
    "    Train, for a specific aggregation level, models for all quantiles.\n",
    "    For aggregation levels 10, 11 and 12, undersampling is used to drastically reduce training time.\n",
    "    \"\"\"\n",
    "\n",
    "    # type_of = 'val'\n",
    "    # test = False\n",
    "    # agg_level = 'Level1'\n",
    "    \n",
    "    agg_columns = AGG_LEVEL_COLUMNS[agg_level]\n",
    "    if len(agg_columns) == 0:\n",
    "        agg_str: str = 'Total_X'\n",
    "    elif len(agg_columns) == 1:\n",
    "        agg_str: str = f'{agg_columns[0]}_X'\n",
    "    else:\n",
    "        agg_str: str = '_'.join(agg_columns)\n",
    "\n",
    "    try:\n",
    "        features = pd.DataFrame(features)\n",
    "    except Exception:\n",
    "        logger.info('(re)loading features')\n",
    "        features = pd.read_parquet(f'../data/uncertainty/fold_{sub_d_start}/features/' + (TEST_PATH if test else '') + f'features_{type_of}_{agg_str}.parquet')\n",
    "        features = _down_cast(features)\n",
    "        \n",
    "    features_gr = features.copy()\n",
    "\n",
    "    group_columns = agg_columns\n",
    "    res: list = []\n",
    "\n",
    "    exclude_prefix_list = exclude_columns # unconditional, auto, momentum, seasonal\n",
    "    columns = [c for c in features_gr if c.split('_')[0] not in exclude_prefix_list]\n",
    "    features_gr = features_gr[columns]\n",
    "    \n",
    "    # preparations\n",
    "    # sub_d_start = SUB_D_START_VAL if type_of == 'val' else SUB_D_START_EVAL\n",
    "    train_idx = features_gr['sold'].notna() & features_gr['d'].isin([f'd_{sub_d_start - 1 - i}' for i in range(1460)])\n",
    "    pred_idx = features_gr['d'].isin([f'd_{sub_d_start + i}' for i in range(28)])\n",
    "    df_train = features_gr[train_idx]\n",
    "    df_pred = features_gr[pred_idx]\n",
    "    features_train: pd.DataFrame = df_train.drop(DROP_FEATURE_COLUMNS, axis = 1, errors = 'ignore')\n",
    "    targets_train: pd.Series = df_train['sold']\n",
    "    features_predict: pd.DataFrame = df_pred.drop(DROP_FEATURE_COLUMNS, axis = 1, errors = 'ignore')\n",
    "    \n",
    "    undersampling_dict = {\n",
    "        'Level3': .5,\n",
    "        'Level4': .5,\n",
    "        'Level5': .5,\n",
    "        'Level6': .3,\n",
    "        'Level7': .3,\n",
    "        'Level8': .3,\n",
    "        'Level9': .2,\n",
    "        'Level10': .2,\n",
    "        'Level11': .05,\n",
    "        'Level12': .01\n",
    "    }\n",
    "    if agg_level in undersampling_dict:\n",
    "        undersampling_pct = undersampling_dict[agg_level]\n",
    "        features_train, _, targets_train, _ = train_test_split(features_train, targets_train, train_size = undersampling_pct, shuffle=True, random_state=43)\n",
    "\n",
    "    # normalise targets\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    targets_train = scaler.fit_transform(targets_train.values.reshape(-1,1))\n",
    "        \n",
    "    # train model for all quantiles\n",
    "    for quantile in QUANTILES:\n",
    "        \n",
    "        # perform grid search for best parameters\n",
    "        if do_grid_search == True:\n",
    "            # split data to training and testing\n",
    "            logger.info('divide for cross validation')\n",
    "            x_train, x_test, y_train, y_test = train_test_split(features_train, targets_train, train_size=.8, shuffle=False, random_state=42)\n",
    "            train_data = lgb.Dataset(x_train, y_train)\n",
    "            validation_data = lgb.Dataset(x_test, y_test)\n",
    "            logger.info('perform gridsearch')\n",
    "            best_combination, results = grid_search(params, param_grid, train_data = train_data, validation_data = validation_data)\n",
    "            del train_data; del validation_data\n",
    "            params_grid_train = best_combination[\"params\"]\n",
    "        else:\n",
    "            params_grid_train = {\n",
    "                'objective': 'quantile',\n",
    "                # 'metric': 'quantile', # Use Root Mean Squared Error (RMSE) as the evaluation metric\n",
    "                'boosting_type': 'gbdt',\n",
    "                'random_state': 43,\n",
    "                'verbose': -1,\n",
    "                'n_jobs': 4,\n",
    "                'subsample': .9,\n",
    "                'subsample_freq': 1,\n",
    "                \"num_leaves\": 30,\n",
    "                \"min_child_weight\": .1,\n",
    "                \"min_child_samples\": 4,\n",
    "                \"hist_pool_size\": 1000,\n",
    "                # 'feature_fraction': 0.5, #.5\n",
    "                # 'bagging_fraction': .8,\n",
    "                \"learning_rate\": 0.07,\n",
    "                \"n_estimators\": 200,#100\n",
    "                \"max_depth\": 10,\n",
    "                # 'reg_sqrt': True,\n",
    "                # 'req_lambda': .00001,\n",
    "                # 'reg_alpha': .00001,\n",
    "                'alpha': quantile,\n",
    "            }\n",
    "\n",
    "        # train_best_model\n",
    "        mod = lgb.train(params_grid_train,\n",
    "            train_set = lgb.Dataset(features_train, targets_train)\n",
    "        )\n",
    "        predictions = mod.predict(features_predict)\n",
    "        predictions = scaler.inverse_transform(predictions.reshape(-1,1)).reshape(-1,)\n",
    "        \n",
    "        # store predictions\n",
    "        df_p = pd.DataFrame(\n",
    "            {\n",
    "                'pred': predictions,\n",
    "                'd': df_pred['d'],\n",
    "            }\n",
    "        )\n",
    "        df_p['quantile'] = quantile\n",
    "        df_p['Level'] = agg_level\n",
    "        df_p['type_of'] = 'validation' if type_of == 'val' else 'evaluation'\n",
    "        if len(agg_columns) == 0:\n",
    "            df_p['agg_column1'] = 'Total'\n",
    "            df_p['agg_column2'] = 'X'\n",
    "        elif len(agg_columns) == 1:\n",
    "            df_p['agg_column1'] = df_pred[agg_columns[0]].values\n",
    "            df_p['agg_column2'] = 'X'\n",
    "        else:\n",
    "            df_p['agg_column1'] = df_pred[agg_columns[0]].values\n",
    "            df_p['agg_column2'] = df_pred[agg_columns[1]].values\n",
    "            \n",
    "        df_p = df_p[['Level', 'agg_column1', 'agg_column2', 'd', 'quantile', 'pred', 'type_of']]\n",
    "        \n",
    "        res.append(_down_cast(df_p))\n",
    "        \n",
    "    # remove to reduce memory usage asap\n",
    "    del features\n",
    "        \n",
    "    # storing predictions in specified file + folder\n",
    "    df_sub_val = pd.concat(res)\n",
    "    group_names = '_'.join(group_columns)\n",
    "    if group_names == '':\n",
    "        group_names = 'Total_X'\n",
    "    exclude_names = 'None' if len(exclude_prefix_list) == 0 else '_'.join(exclude_prefix_list)\n",
    "    df_sub_val.to_csv(f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_multivariate_{type_of}_non_transposed_{group_names}_exclude_{exclude_names}.csv', index = False)\n",
    "    logger.info('saved under: ' + f'../data/uncertainty/fold_{str(sub_d_start)}/' + store_submissions_path + f'lgb_multivariate_{type_of}_non_transposed_{group_names}_exclude_{exclude_names}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:15:02 - __main__ - INFO - starting with agg_level: Level1\n",
      "2023-11-08 18:15:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:15:10 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_Total_X_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:15:10 - __main__ - INFO - starting with agg_level: Level2\n",
      "2023-11-08 18:15:10 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:15:35 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:15:35 - __main__ - INFO - starting with agg_level: Level3\n",
      "2023-11-08 18:15:35 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:16:19 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:16:19 - __main__ - INFO - starting with agg_level: Level4\n",
      "2023-11-08 18:16:19 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:16:36 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:16:36 - __main__ - INFO - starting with agg_level: Level5\n",
      "2023-11-08 18:16:36 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:17:02 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:17:02 - __main__ - INFO - starting with agg_level: Level6\n",
      "2023-11-08 18:17:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:17:23 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:17:23 - __main__ - INFO - starting with agg_level: Level7\n",
      "2023-11-08 18:17:23 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:18:12 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:18:12 - __main__ - INFO - starting with agg_level: Level8\n",
      "2023-11-08 18:18:12 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:19:00 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:19:00 - __main__ - INFO - starting with agg_level: Level9\n",
      "2023-11-08 18:19:00 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:20:02 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:20:02 - __main__ - INFO - starting with agg_level: Level10\n",
      "2023-11-08 18:20:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:24:14 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_item_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:24:14 - __main__ - INFO - starting with agg_level: Level11\n",
      "2023-11-08 18:24:14 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:28:35 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_item_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:28:35 - __main__ - INFO - starting with agg_level: Level12\n",
      "2023-11-08 18:28:35 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:34:08 - __main__ - INFO - saved under: ../data/uncertainty/fold_1802/temp_submissions_research/lgb_multivariate_val_non_transposed_item_id_store_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:34:08 - __main__ - INFO - starting with agg_level: Level1\n",
      "2023-11-08 18:34:08 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:34:15 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_Total_X_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:34:15 - __main__ - INFO - starting with agg_level: Level2\n",
      "2023-11-08 18:34:15 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:34:39 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:34:39 - __main__ - INFO - starting with agg_level: Level3\n",
      "2023-11-08 18:34:39 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:35:13 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:35:13 - __main__ - INFO - starting with agg_level: Level4\n",
      "2023-11-08 18:35:13 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:35:24 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:35:24 - __main__ - INFO - starting with agg_level: Level5\n",
      "2023-11-08 18:35:24 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:35:55 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:35:55 - __main__ - INFO - starting with agg_level: Level6\n",
      "2023-11-08 18:35:55 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:36:15 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:36:15 - __main__ - INFO - starting with agg_level: Level7\n",
      "2023-11-08 18:36:15 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:37:05 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_state_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:37:05 - __main__ - INFO - starting with agg_level: Level8\n",
      "2023-11-08 18:37:05 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:37:57 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_cat_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:37:57 - __main__ - INFO - starting with agg_level: Level9\n",
      "2023-11-08 18:37:57 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 18:39:02 - __main__ - INFO - saved under: ../data/uncertainty/fold_1830/temp_submissions_research/lgb_multivariate_val_non_transposed_store_id_dept_id_exclude_seasonal_auto_momentum.csv\n",
      "2023-11-08 18:39:02 - __main__ - INFO - starting with agg_level: Level10\n",
      "2023-11-08 18:39:02 - __main__ - INFO - (re)loading features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m agg_level \u001b[39min\u001b[39;00m AGG_LEVEL_COLUMNS: \u001b[39m# for each aggregation level\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstarting with agg_level: \u001b[39m\u001b[39m{\u001b[39;00magg_level\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     train_level_all_quantiles(\n\u001b[1;32m     27\u001b[0m         agg_level, \n\u001b[1;32m     28\u001b[0m         sub_d_start\u001b[39m=\u001b[39;49msub_d_start,\n\u001b[1;32m     29\u001b[0m         type_of\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     30\u001b[0m         exclude_columns\u001b[39m=\u001b[39;49mexclude_columns,\n\u001b[1;32m     31\u001b[0m         do_grid_search\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     32\u001b[0m         store_submissions_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtemp_submissions_research/\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     33\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[32], line 112\u001b[0m, in \u001b[0;36mtrain_level_all_quantiles\u001b[0;34m(agg_level, type_of, sub_d_start, exclude_columns, test, do_grid_search, store_submissions_path)\u001b[0m\n\u001b[1;32m     88\u001b[0m     params_grid_train \u001b[39m=\u001b[39m {\n\u001b[1;32m     89\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mquantile\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     90\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mquantile\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m# Use Root Mean Squared Error (RMSE) as the evaluation metric\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m: quantile,\n\u001b[1;32m    109\u001b[0m     }\n\u001b[1;32m    111\u001b[0m \u001b[39m# train_best_model\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m mod \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(params_grid_train,\n\u001b[1;32m    113\u001b[0m     train_set \u001b[39m=\u001b[39;49m lgb\u001b[39m.\u001b[39;49mDataset(features_train, targets_train)\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m predictions \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39mpredict(features_predict)\n\u001b[1;32m    116\u001b[0m predictions \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(predictions\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_tf_env/lib/python3.9/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_tf_env/lib/python3.9/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# all groups: seasonal, auto, autoquantiles, momentum\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    # [],\n",
    "    # ['seasonal'],\n",
    "    # ['auto'],\n",
    "    # ['autoquantiles'],\n",
    "    # ['momentum'],\n",
    "    ['seasonal', 'auto', 'momentum'] # only autocorrelated quantiles\n",
    ")\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    # [],\n",
    "    # ['seasonal'],\n",
    "    # ['momentum'],\n",
    "    # ['autoquantiles'],\n",
    "    # ['auto'],\n",
    "    ['seasonal', 'auto', 'momentum'],\n",
    "    # ['auto', 'momentum']\n",
    ")\n",
    "\n",
    "SPARSE_FEATURES = [\n",
    "    'dayofweek', 'dayofmonth', 'qs_30d_ewm', 'qs_100d_ewm', 'qs_median_28d', 'qs_mean_28d', 'state_id', 'qs_qtile_90_28d', 'pct_nonzero_days_28d', 'days_fwd'\n",
    "]\n",
    "\n",
    "sparse_features = ['dayofweek', 'dayofmonth', \n",
    "                     'qs_30d_ewm', 'qs_100d_ewm',\n",
    "                    'qs_median_28d', 'qs_mean_28d',# 'qs_stdev_28d',\n",
    "                    'state_id',\n",
    "               #     'store_id',\n",
    "                   'qs_qtile90_28d',\n",
    "                    'pct_nonzero_days_28d',\n",
    "                    'days_fwd'\n",
    "                    ]\n",
    "\n",
    "HIGH_UNDERSAMPLING = True\n",
    "\n",
    "for exclude_columns in EXCLUDE_COLUMNS_LIST: # for each specified feature combination\n",
    "    for sub_d_start in D_CROSS_VAL_START_LIST: # for each fold\n",
    "        for agg_level in AGG_LEVEL_COLUMNS: # for each aggregation level\n",
    "            logger.info(f'starting with agg_level: {agg_level}')\n",
    "            train_level_all_quantiles(\n",
    "                agg_level, \n",
    "                sub_d_start=sub_d_start,\n",
    "                type_of='val', \n",
    "                exclude_columns=exclude_columns,\n",
    "                do_grid_search=False,\n",
    "                store_submissions_path='temp_submissions_research/'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load val + eval prediction files and merge to one submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_columns = '_'.join([])\n",
    "# if exclude_columns == '':\n",
    "#     exclude_columns = 'None'\n",
    "\n",
    "# dfs: list = []\n",
    "# for level in AGG_LEVEL_COLUMNS:\n",
    "#     agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "#     group_names = '_'.join(agg_columns)\n",
    "#     if group_names == '':\n",
    "#         group_names = 'Total_X'\n",
    "#     i = str(1802)\n",
    "#     dfs.append(\n",
    "#         f'../data/uncertainty/fold_{i}/temp_submissions/' + f'lgb_multivariate_val_non_transposed_{group_names}_exclude_{exclude_columns}.csv',\n",
    "#     )\n",
    "\n",
    "# df_sub_val = ensemble_submissions_uncertainty(dfs)\n",
    "# transpose = True\n",
    "# if transpose == True:\n",
    "#     sub_validation = df_sub_val.pivot(index='id', columns='d', values='pred').reset_index(drop=False)\n",
    "#     sub_validation.columns = [\"id\"] + [f\"F{i}\" for i in range(1,DAYS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_concat_predictions(fold_name: int, exclude_columns: list = []):\n",
    "    \"\"\" \n",
    "    For specified fold, read the predictions for all aggregation levels and stack them together in one dataframe.\n",
    "    \"\"\"\n",
    "    # D_CV_START_LIST\n",
    "    # if fold_name not in D_CV_START_LIST:\n",
    "        # raise ValueError('fold_name must be a value in D_CV_START_LIST')\n",
    "        \n",
    "    exclude_columns = '_'.join(exclude_columns)\n",
    "    if exclude_columns == '':\n",
    "        exclude_columns = 'None'\n",
    "\n",
    "    logger.info('loading files under path:' + f'../data/uncertainty/fold_{fold_name}/temp_submissions/')\n",
    "\n",
    "    dfs: list = []\n",
    "    for level in AGG_LEVEL_COLUMNS:\n",
    "        agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "        group_names = '_'.join(agg_columns)\n",
    "        if group_names == '':\n",
    "            group_names = 'Total_X'\n",
    "\n",
    "        dfs.append(\n",
    "            f'../data/uncertainty/fold_{fold_name}/temp_submissions/' + f'lgb_multivariate_val_non_transposed_{group_names}_exclude_{exclude_columns}.csv',\n",
    "        )\n",
    "\n",
    "    return ensemble_submissions_uncertainty(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_columns = '_'.join([])\n",
    "# if exclude_columns == '':\n",
    "#     exclude_columns = 'None'\n",
    "\n",
    "# dfs: list = []\n",
    "# for level in AGG_LEVEL_COLUMNS:\n",
    "#     agg_columns = AGG_LEVEL_COLUMNS[level]\n",
    "#     group_names = '_'.join(agg_columns)\n",
    "#     if group_names == '':\n",
    "#         group_names = 'Total_X'\n",
    "        \n",
    "#     dfs.append(\n",
    "#         PREDICTION_BASE_PATH + f'lgb_multivariate_eval_non_transposed_{group_names}_exclude_{exclude_columns}.csv',\n",
    "#     )\n",
    "\n",
    "# df_sub_eval = ensemble_submissions_uncertainty(dfs)\n",
    "# transpose = True\n",
    "# if transpose == True:\n",
    "#     sub_evaluation = df_sub_eval.pivot(index='id', columns='d', values='pred').reset_index(drop=False)\n",
    "#     sub_evaluation.columns = [\"id\"] + [f\"F{i}\" for i in range(1,DAYS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sub_evaluation = pd.read_csv('../submissions/submission_baseline_evaluation.csv').drop(['Unnamed: 0'], axis=1)\n",
    "# pd.concat([sub_validation, sub_evaluation]).to_csv(SUBMISSION_BASE_PATH + f'submission_lgb_ensemble{exclude_columns}.csv', index=False)\n",
    "# del sub_validation; del sub_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Validation Prediction, we can compute WRMSSE locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these variables are used later on\n",
    "d = pd.read_parquet('../data/uncertainty/cv_template/temp.parquet')\n",
    "d_int = d['d'].str.split('_').apply(lambda x: int(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv(df: pd.DataFrame, df_sub: pd.DataFrame):\n",
    "    \n",
    "    # to be able to merge\n",
    "    df_sub['id_merge'] = df_sub['id'].str.split('.')\\\n",
    "        .apply(lambda x: x[0])\n",
    "    df_sub['quantile'] = df_sub['id'].str.split('.')\\\n",
    "        .apply(lambda x: float('.'.join([x[-2], x[-1].split('_')[0]])))\n",
    "\n",
    "    # merge predictions in cv template\n",
    "    p = pd.merge(\n",
    "        df,\n",
    "        df_sub,\n",
    "        how='left',\n",
    "        on=['id_merge', 'd']\n",
    "    )\n",
    "    # del df; del df_sub_val\n",
    "    p['id_merge'] = p['id_merge'].astype(str)\n",
    "\n",
    "    for c in ['sold', 'revenue']:\n",
    "        p[c] = p[c].astype(np.float32)\n",
    "    # d = d[d_int < (D_CV_START + 28)]\n",
    "\n",
    "    return WSPL(p, [f'd_{i}' for i in range(D_CV_START, D_CV_START + 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 11:01:20 - __main__ - INFO - --------------- ['seasonal', 'auto', 'momentum'] ---------------\n",
      "2023-08-23 11:01:32 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1802/temp_submissions/\n",
      "2023-08-23 11:02:23 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:02:23 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:02:55 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:03:02 - utils.metrics - INFO - Level1 - 0.5094243163667926\n",
      "2023-08-23 11:03:13 - utils.metrics - INFO - Level10 - 0.2974691040013057\n",
      "2023-08-23 11:03:47 - utils.metrics - INFO - Level11 - 0.2925593341513246\n",
      "2023-08-23 11:05:44 - utils.metrics - INFO - Level12 - 0.28617993644852113\n",
      "2023-08-23 11:05:44 - utils.metrics - INFO - Level2 - 0.41335436599424047\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level3 - 0.39246218255236165\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level4 - 0.4088971129355237\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level5 - 0.4194056690547897\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level6 - 0.4375510311627534\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level7 - 0.3907954511737379\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level8 - 0.36553621833229316\n",
      "2023-08-23 11:05:45 - utils.metrics - INFO - Level9 - 0.34526050295601973\n",
      "2023-08-23 11:05:52 - __main__ - INFO - 1802 - wspl: 0.3799079354274719\n",
      "2023-08-23 11:05:57 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1830/temp_submissions/\n",
      "2023-08-23 11:06:56 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:06:56 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:07:32 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:07:39 - utils.metrics - INFO - Level1 - 0.5415997159891802\n",
      "2023-08-23 11:07:50 - utils.metrics - INFO - Level10 - 0.3118867521987879\n",
      "2023-08-23 11:08:25 - utils.metrics - INFO - Level11 - 0.2937851951226946\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level12 - 0.3050911166458399\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level2 - 0.32010568198709466\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level3 - 0.36978150314645747\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level4 - 0.41060458902628244\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level5 - 0.3687130828653947\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level6 - 0.33081491808106106\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level7 - 0.3366365987835377\n",
      "2023-08-23 11:10:28 - utils.metrics - INFO - Level8 - 0.3047925519792386\n",
      "2023-08-23 11:10:29 - utils.metrics - INFO - Level9 - 0.33237765317725315\n",
      "2023-08-23 11:10:36 - __main__ - INFO - 1830 - wspl: 0.35218244658356856\n",
      "2023-08-23 11:10:40 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1858/temp_submissions/\n",
      "2023-08-23 11:11:38 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:11:38 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:12:12 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:12:20 - utils.metrics - INFO - Level1 - 0.2943017381600151\n",
      "2023-08-23 11:12:31 - utils.metrics - INFO - Level10 - 0.30288826775160727\n",
      "2023-08-23 11:13:06 - utils.metrics - INFO - Level11 - 0.28620971054666\n",
      "2023-08-23 11:15:07 - utils.metrics - INFO - Level12 - 0.29991271990272766\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level2 - 0.3624579924102846\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level3 - 0.36798301448813125\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level4 - 0.433688849398041\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level5 - 0.37661763889814726\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level6 - 0.3422735822692424\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level7 - 0.33408616146152786\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level8 - 0.32576719136307347\n",
      "2023-08-23 11:15:08 - utils.metrics - INFO - Level9 - 0.3308348820850935\n",
      "2023-08-23 11:15:16 - __main__ - INFO - 1858 - wspl: 0.3380851457278793\n",
      "2023-08-23 11:15:19 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1886/temp_submissions/\n",
      "2023-08-23 11:16:15 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:16:15 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:16:50 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:16:57 - utils.metrics - INFO - Level1 - 0.3633308108190663\n",
      "2023-08-23 11:17:09 - utils.metrics - INFO - Level10 - 0.2933981539888825\n",
      "2023-08-23 11:17:43 - utils.metrics - INFO - Level11 - 0.2862304002976008\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level12 - 0.3001748469437216\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level2 - 0.3515288970251534\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level3 - 0.34772943533066003\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level4 - 0.40403379344921475\n",
      "2023-08-23 11:19:41 - utils.metrics - INFO - Level5 - 0.41064645143106027\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level6 - 0.34449343445455327\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level7 - 0.3578890637811169\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level8 - 0.34057884237815733\n",
      "2023-08-23 11:19:42 - utils.metrics - INFO - Level9 - 0.319121427300331\n",
      "2023-08-23 11:19:48 - __main__ - INFO - 1886 - wspl: 0.3432629630999598\n",
      "2023-08-23 11:19:52 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1914/temp_submissions/\n",
      "2023-08-23 11:20:47 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:20:47 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:21:22 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:21:30 - utils.metrics - INFO - Level1 - 0.26114931458459384\n",
      "2023-08-23 11:21:41 - utils.metrics - INFO - Level10 - 0.27791292735675954\n",
      "2023-08-23 11:22:15 - utils.metrics - INFO - Level11 - 0.26659250693078723\n",
      "2023-08-23 11:24:15 - utils.metrics - INFO - Level12 - 0.26632866263415017\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level2 - 0.3465961818505697\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level3 - 0.3042461454413001\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level4 - 0.3767883544669268\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level5 - 0.3823450135491447\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level6 - 0.3260881519253884\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level7 - 0.3190495612495478\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level8 - 0.3053848606748176\n",
      "2023-08-23 11:24:16 - utils.metrics - INFO - Level9 - 0.3054618531816178\n",
      "2023-08-23 11:24:25 - __main__ - INFO - 1914 - wspl: 0.31149529448713364\n",
      "2023-08-23 11:24:25 - __main__ - INFO - 1914 - mean wspl: 0.34498675706520265 +/- 0.022106779123872475\n",
      "2023-08-23 11:24:25 - __main__ - INFO - 1914 - raw results: [0.3799079354274719, 0.35218244658356856, 0.3380851457278793, 0.3432629630999598, 0.31149529448713364]\n",
      "2023-08-23 11:24:25 - __main__ - INFO - --------------- ['auto', 'momentum'] ---------------\n",
      "2023-08-23 11:24:28 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1802/temp_submissions/\n",
      "2023-08-23 11:25:25 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:25:25 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:25:59 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:26:06 - utils.metrics - INFO - Level1 - 0.2317026538574037\n",
      "2023-08-23 11:26:17 - utils.metrics - INFO - Level10 - 0.2916661536097424\n",
      "2023-08-23 11:26:52 - utils.metrics - INFO - Level11 - 0.2810585579919864\n",
      "2023-08-23 11:28:50 - utils.metrics - INFO - Level12 - 0.28678906783182223\n",
      "2023-08-23 11:28:50 - utils.metrics - INFO - Level2 - 0.24638947981969986\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level3 - 0.27387834259810706\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level4 - 0.21760546479644452\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level5 - 0.3150004599099869\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level6 - 0.3223399679356197\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level7 - 0.3052157822001202\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level8 - 0.3248847597012523\n",
      "2023-08-23 11:28:51 - utils.metrics - INFO - Level9 - 0.31693789527120697\n",
      "2023-08-23 11:28:57 - __main__ - INFO - 1802 - wspl: 0.2844557154602827\n",
      "2023-08-23 11:29:01 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1830/temp_submissions/\n",
      "2023-08-23 11:29:56 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:29:56 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:30:30 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:30:37 - utils.metrics - INFO - Level1 - 0.3435708185799468\n",
      "2023-08-23 11:30:50 - utils.metrics - INFO - Level10 - 0.2956243926117087\n",
      "2023-08-23 11:31:29 - utils.metrics - INFO - Level11 - 0.2818383519765543\n",
      "2023-08-23 11:33:40 - utils.metrics - INFO - Level12 - 0.3022776377212882\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level2 - 0.21084223804123034\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level3 - 0.2466268074848912\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level4 - 0.28273583945890507\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level5 - 0.30446196777497203\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level6 - 0.2328859251735203\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level7 - 0.285448351669116\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level8 - 0.2434190031700636\n",
      "2023-08-23 11:33:41 - utils.metrics - INFO - Level9 - 0.2743202918565348\n",
      "2023-08-23 11:33:48 - __main__ - INFO - 1830 - wspl: 0.27533763545989426\n",
      "2023-08-23 11:33:51 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1858/temp_submissions/\n",
      "2023-08-23 11:34:50 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:34:50 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:35:27 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:35:36 - utils.metrics - INFO - Level1 - 0.23428793547877136\n",
      "2023-08-23 11:35:49 - utils.metrics - INFO - Level10 - 0.29087867349207874\n",
      "2023-08-23 11:36:27 - utils.metrics - INFO - Level11 - 0.27918063739859594\n",
      "2023-08-23 11:38:40 - utils.metrics - INFO - Level12 - 0.2917579925634804\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level2 - 0.19805506533240552\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level3 - 0.24963856529600328\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level4 - 0.3703047682737021\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level5 - 0.2525415131891123\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level6 - 0.25632805882106985\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level7 - 0.22537108993797045\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level8 - 0.24489828034780925\n",
      "2023-08-23 11:38:41 - utils.metrics - INFO - Level9 - 0.26215668873090453\n",
      "2023-08-23 11:38:49 - __main__ - INFO - 1858 - wspl: 0.2629499390718253\n",
      "2023-08-23 11:38:52 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1886/temp_submissions/\n",
      "2023-08-23 11:39:58 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:39:58 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:40:38 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:40:47 - utils.metrics - INFO - Level1 - 0.1459219538539635\n",
      "2023-08-23 11:41:00 - utils.metrics - INFO - Level10 - 0.28023551447133943\n",
      "2023-08-23 11:41:41 - utils.metrics - INFO - Level11 - 0.27478866565103244\n",
      "2023-08-23 11:43:53 - utils.metrics - INFO - Level12 - 0.29078434392245056\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level2 - 0.16200958782912497\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level3 - 0.18771726531764124\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level4 - 0.3917470835366255\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level5 - 0.275308420388723\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level6 - 0.21760255413399807\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level7 - 0.21181521773055875\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level8 - 0.20985644502367476\n",
      "2023-08-23 11:43:54 - utils.metrics - INFO - Level9 - 0.23140371950460617\n",
      "2023-08-23 11:44:01 - __main__ - INFO - 1886 - wspl: 0.2399325642803115\n",
      "2023-08-23 11:44:05 - __main__ - INFO - loading files under path:../data/uncertainty/fold_1914/temp_submissions/\n",
      "2023-08-23 11:45:05 - utils.metrics - INFO - reading weights file\n",
      "2023-08-23 11:45:05 - utils.metrics - INFO - sorting df on d ...\n",
      "2023-08-23 11:45:47 - utils.metrics - INFO - entering loop ...\n",
      "2023-08-23 11:45:55 - utils.metrics - INFO - Level1 - 0.2513019360922543\n",
      "2023-08-23 11:46:07 - utils.metrics - INFO - Level10 - 0.26614146227268104\n",
      "2023-08-23 11:46:45 - utils.metrics - INFO - Level11 - 0.26127442458183503\n",
      "2023-08-23 11:48:53 - utils.metrics - INFO - Level12 - 0.26483872317408663\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level2 - 0.22494925554743278\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level3 - 0.23965821903255716\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level4 - 0.30132737675378357\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level5 - 0.30201066262965093\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level6 - 0.24959331723936853\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level7 - 0.25191802585809314\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level8 - 0.256621755920822\n",
      "2023-08-23 11:48:54 - utils.metrics - INFO - Level9 - 0.2549035258115886\n",
      "2023-08-23 11:49:02 - __main__ - INFO - 1914 - wspl: 0.26037822374284614\n",
      "2023-08-23 11:49:02 - __main__ - INFO - 1914 - mean wspl: 0.264610815603032 +/- 0.015090222978074668\n",
      "2023-08-23 11:49:02 - __main__ - INFO - 1914 - raw results: [0.2844557154602827, 0.27533763545989426, 0.2629499390718253, 0.2399325642803115, 0.26037822374284614]\n"
     ]
    }
   ],
   "source": [
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    [],\n",
    "    ['seasonal'],\n",
    "    ['auto'],\n",
    "    ['autoquantiles'],\n",
    "    ['momentum'],\n",
    ")\n",
    "\n",
    "EXCLUDE_COLUMNS_LIST = (\n",
    "    # ['seasonal'],\n",
    "    # ['momentum'],\n",
    "    # ['autoquantiles'],\n",
    "    ['seasonal', 'auto', 'momentum'],\n",
    "    ['auto', 'momentum'],\n",
    ")\n",
    "\n",
    "for EXCLUDE_COLUMNS in EXCLUDE_COLUMNS_LIST:\n",
    "    logger.info('--------------- ' + str(EXCLUDE_COLUMNS) + ' ---------------')\n",
    "    res = []\n",
    "    for D_CV_START in D_CROSS_VAL_START_LIST:\n",
    "        mean_wspl = perform_cv(_down_cast(d)[d_int < (D_CV_START + 28)], read_concat_predictions(D_CV_START, EXCLUDE_COLUMNS))\n",
    "        res.append(mean_wspl)\n",
    "        logger.info(str(D_CV_START) + ' - wspl: ' + str(mean_wspl))\n",
    "        \n",
    "    logger.info(str(D_CV_START) + ' - mean wspl: ' + str(np.mean(res)) + ' +/- ' + str(np.std(res)))\n",
    "    logger.info(str(D_CV_START) + ' - raw results: ' + str(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Beneath can be used to create submission template\n",
    "The submission template can be used to quickly insert your predictions.\n",
    "It also contains all other (historical) sales to be able to compute the WRMSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_validation = pd.read_csv(DATA_BASE_PATH + SALES_VALIDATION)\n",
    "sales_evaluation = pd.read_csv(DATA_BASE_PATH + SALES_EVALUATION)\n",
    "calendar = pd.read_csv(DATA_BASE_PATH + CALENDAR)\n",
    "sell_prices = pd.read_csv(DATA_BASE_PATH + SELL_PRICES)\n",
    "\n",
    "df_val, submission_idx_val = data_preprocessing(sales_validation, calendar, sell_prices)\n",
    "del sales_validation\n",
    "df_eval, submission_idx_eval = data_preprocessing(sales_evaluation, calendar, sell_prices)\n",
    "del sales_evaluation\n",
    "\n",
    "df_val_after_release = df_val[(df_val.wm_yr_wk > df_val.release)]# & (df_val[\"sold\"].notna())]\n",
    "del df_val\n",
    "df_eval_after_release = df_eval[(df_eval.wm_yr_wk > df_eval.release)]# & (df_eval[\"sold\"].notna())]\n",
    "del df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 17:27:39 - __main__ - INFO - Level1\n",
      "2023-08-17 17:27:40 - __main__ - INFO - Level2\n",
      "2023-08-17 17:27:44 - __main__ - INFO - Level3\n",
      "2023-08-17 17:27:48 - __main__ - INFO - Level4\n",
      "2023-08-17 17:27:51 - __main__ - INFO - Level5\n",
      "2023-08-17 17:27:55 - __main__ - INFO - Level6\n",
      "2023-08-17 17:28:00 - __main__ - INFO - Level7\n",
      "2023-08-17 17:28:05 - __main__ - INFO - Level8\n",
      "2023-08-17 17:28:10 - __main__ - INFO - Level9\n",
      "2023-08-17 17:28:15 - __main__ - INFO - Level10\n",
      "2023-08-17 17:28:21 - __main__ - INFO - Level11\n",
      "2023-08-17 17:28:33 - __main__ - INFO - Level12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>agg_column1</th>\n",
       "      <th>agg_column2</th>\n",
       "      <th>d</th>\n",
       "      <th>sold</th>\n",
       "      <th>revenue</th>\n",
       "      <th>id_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_10</td>\n",
       "      <td>24858.0</td>\n",
       "      <td>63029.78</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_100</td>\n",
       "      <td>23653.0</td>\n",
       "      <td>65665.71</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1000</td>\n",
       "      <td>29241.0</td>\n",
       "      <td>82351.45</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1001</td>\n",
       "      <td>33804.0</td>\n",
       "      <td>93975.55</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1002</td>\n",
       "      <td>42447.0</td>\n",
       "      <td>118961.96</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1003</td>\n",
       "      <td>40647.0</td>\n",
       "      <td>116052.48</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1004</td>\n",
       "      <td>32039.0</td>\n",
       "      <td>89314.17</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1005</td>\n",
       "      <td>29501.0</td>\n",
       "      <td>81688.96</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1006</td>\n",
       "      <td>31117.0</td>\n",
       "      <td>85754.15</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1007</td>\n",
       "      <td>27018.0</td>\n",
       "      <td>74244.86</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1008</td>\n",
       "      <td>39707.0</td>\n",
       "      <td>108637.04</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1009</td>\n",
       "      <td>47082.0</td>\n",
       "      <td>128940.24</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_101</td>\n",
       "      <td>24982.0</td>\n",
       "      <td>68908.04</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1010</td>\n",
       "      <td>48360.0</td>\n",
       "      <td>133218.73</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1011</td>\n",
       "      <td>32930.0</td>\n",
       "      <td>92274.15</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1012</td>\n",
       "      <td>33990.0</td>\n",
       "      <td>92743.98</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1013</td>\n",
       "      <td>32956.0</td>\n",
       "      <td>90505.80</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1014</td>\n",
       "      <td>31862.0</td>\n",
       "      <td>87172.76</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1015</td>\n",
       "      <td>35365.0</td>\n",
       "      <td>95702.83</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1016</td>\n",
       "      <td>45705.0</td>\n",
       "      <td>125791.89</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1017</td>\n",
       "      <td>43898.0</td>\n",
       "      <td>123256.45</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1018</td>\n",
       "      <td>36385.0</td>\n",
       "      <td>100212.69</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1019</td>\n",
       "      <td>32258.0</td>\n",
       "      <td>87909.01</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_102</td>\n",
       "      <td>22196.0</td>\n",
       "      <td>60000.65</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1020</td>\n",
       "      <td>29242.0</td>\n",
       "      <td>81367.81</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1021</td>\n",
       "      <td>29452.0</td>\n",
       "      <td>79956.86</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1022</td>\n",
       "      <td>35763.0</td>\n",
       "      <td>97645.15</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1023</td>\n",
       "      <td>44579.0</td>\n",
       "      <td>123721.42</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1024</td>\n",
       "      <td>42582.0</td>\n",
       "      <td>121478.81</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1025</td>\n",
       "      <td>32102.0</td>\n",
       "      <td>89627.71</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1026</td>\n",
       "      <td>28521.0</td>\n",
       "      <td>78796.16</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1027</td>\n",
       "      <td>27904.0</td>\n",
       "      <td>78144.16</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1028</td>\n",
       "      <td>28693.0</td>\n",
       "      <td>78581.27</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1029</td>\n",
       "      <td>32847.0</td>\n",
       "      <td>91347.72</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_103</td>\n",
       "      <td>22117.0</td>\n",
       "      <td>61407.00</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1030</td>\n",
       "      <td>40046.0</td>\n",
       "      <td>114533.56</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1031</td>\n",
       "      <td>38445.0</td>\n",
       "      <td>111826.12</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1032</td>\n",
       "      <td>28603.0</td>\n",
       "      <td>81092.24</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1033</td>\n",
       "      <td>31247.0</td>\n",
       "      <td>87799.42</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1034</td>\n",
       "      <td>36053.0</td>\n",
       "      <td>97214.80</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1035</td>\n",
       "      <td>19783.0</td>\n",
       "      <td>53456.88</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1036</td>\n",
       "      <td>26041.0</td>\n",
       "      <td>75086.93</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1037</td>\n",
       "      <td>31539.0</td>\n",
       "      <td>91356.80</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1038</td>\n",
       "      <td>38182.0</td>\n",
       "      <td>108919.39</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1039</td>\n",
       "      <td>37079.0</td>\n",
       "      <td>97503.03</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_104</td>\n",
       "      <td>22347.0</td>\n",
       "      <td>60736.91</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1040</td>\n",
       "      <td>38010.0</td>\n",
       "      <td>100557.02</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1041</td>\n",
       "      <td>31513.0</td>\n",
       "      <td>83895.82</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1042</td>\n",
       "      <td>35139.0</td>\n",
       "      <td>93359.95</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Level1</td>\n",
       "      <td>Total</td>\n",
       "      <td>X</td>\n",
       "      <td>d_1043</td>\n",
       "      <td>36894.0</td>\n",
       "      <td>99430.98</td>\n",
       "      <td>Total_X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Level agg_column1 agg_column2       d     sold    revenue id_merge\n",
       "0   Level1       Total           X    d_10  24858.0   63029.78  Total_X\n",
       "1   Level1       Total           X   d_100  23653.0   65665.71  Total_X\n",
       "2   Level1       Total           X  d_1000  29241.0   82351.45  Total_X\n",
       "3   Level1       Total           X  d_1001  33804.0   93975.55  Total_X\n",
       "4   Level1       Total           X  d_1002  42447.0  118961.96  Total_X\n",
       "5   Level1       Total           X  d_1003  40647.0  116052.48  Total_X\n",
       "6   Level1       Total           X  d_1004  32039.0   89314.17  Total_X\n",
       "7   Level1       Total           X  d_1005  29501.0   81688.96  Total_X\n",
       "8   Level1       Total           X  d_1006  31117.0   85754.15  Total_X\n",
       "9   Level1       Total           X  d_1007  27018.0   74244.86  Total_X\n",
       "10  Level1       Total           X  d_1008  39707.0  108637.04  Total_X\n",
       "11  Level1       Total           X  d_1009  47082.0  128940.24  Total_X\n",
       "12  Level1       Total           X   d_101  24982.0   68908.04  Total_X\n",
       "13  Level1       Total           X  d_1010  48360.0  133218.73  Total_X\n",
       "14  Level1       Total           X  d_1011  32930.0   92274.15  Total_X\n",
       "15  Level1       Total           X  d_1012  33990.0   92743.98  Total_X\n",
       "16  Level1       Total           X  d_1013  32956.0   90505.80  Total_X\n",
       "17  Level1       Total           X  d_1014  31862.0   87172.76  Total_X\n",
       "18  Level1       Total           X  d_1015  35365.0   95702.83  Total_X\n",
       "19  Level1       Total           X  d_1016  45705.0  125791.89  Total_X\n",
       "20  Level1       Total           X  d_1017  43898.0  123256.45  Total_X\n",
       "21  Level1       Total           X  d_1018  36385.0  100212.69  Total_X\n",
       "22  Level1       Total           X  d_1019  32258.0   87909.01  Total_X\n",
       "23  Level1       Total           X   d_102  22196.0   60000.65  Total_X\n",
       "24  Level1       Total           X  d_1020  29242.0   81367.81  Total_X\n",
       "25  Level1       Total           X  d_1021  29452.0   79956.86  Total_X\n",
       "26  Level1       Total           X  d_1022  35763.0   97645.15  Total_X\n",
       "27  Level1       Total           X  d_1023  44579.0  123721.42  Total_X\n",
       "28  Level1       Total           X  d_1024  42582.0  121478.81  Total_X\n",
       "29  Level1       Total           X  d_1025  32102.0   89627.71  Total_X\n",
       "30  Level1       Total           X  d_1026  28521.0   78796.16  Total_X\n",
       "31  Level1       Total           X  d_1027  27904.0   78144.16  Total_X\n",
       "32  Level1       Total           X  d_1028  28693.0   78581.27  Total_X\n",
       "33  Level1       Total           X  d_1029  32847.0   91347.72  Total_X\n",
       "34  Level1       Total           X   d_103  22117.0   61407.00  Total_X\n",
       "35  Level1       Total           X  d_1030  40046.0  114533.56  Total_X\n",
       "36  Level1       Total           X  d_1031  38445.0  111826.12  Total_X\n",
       "37  Level1       Total           X  d_1032  28603.0   81092.24  Total_X\n",
       "38  Level1       Total           X  d_1033  31247.0   87799.42  Total_X\n",
       "39  Level1       Total           X  d_1034  36053.0   97214.80  Total_X\n",
       "40  Level1       Total           X  d_1035  19783.0   53456.88  Total_X\n",
       "41  Level1       Total           X  d_1036  26041.0   75086.93  Total_X\n",
       "42  Level1       Total           X  d_1037  31539.0   91356.80  Total_X\n",
       "43  Level1       Total           X  d_1038  38182.0  108919.39  Total_X\n",
       "44  Level1       Total           X  d_1039  37079.0   97503.03  Total_X\n",
       "45  Level1       Total           X   d_104  22347.0   60736.91  Total_X\n",
       "46  Level1       Total           X  d_1040  38010.0  100557.02  Total_X\n",
       "47  Level1       Total           X  d_1041  31513.0   83895.82  Total_X\n",
       "48  Level1       Total           X  d_1042  35139.0   93359.95  Total_X\n",
       "49  Level1       Total           X  d_1043  36894.0   99430.98  Total_X"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "df_eval_after_release['revenue'] = df_eval_after_release['sold'] * df_eval_after_release['sell_price']\n",
    "for level in list(AGG_LEVEL_COLUMNS.keys()):\n",
    "    c = AGG_LEVEL_COLUMNS[level]\n",
    "    logger.info(level)\n",
    "    agg_dict = {\n",
    "        'sold': 'sum',\n",
    "        'revenue': 'sum'\n",
    "    }\n",
    "    d1 = df_eval_after_release.groupby(c + ['d']).agg(agg_dict).reset_index(drop=False)\n",
    "    d = pd.DataFrame({\n",
    "        'd': d1['d'],\n",
    "        'sold': d1['sold'],\n",
    "        'revenue': d1['revenue']\n",
    "    })\n",
    "    if len(c) == 0:\n",
    "        d['agg_column1'] = 'Total'\n",
    "        d['agg_column2'] = 'X'\n",
    "    elif len(c) == 1:\n",
    "        d['agg_column1'] = d1[c[0]]\n",
    "        d['agg_column2'] = 'X'\n",
    "    else:\n",
    "        d['agg_column1'] = d1[c[0]]\n",
    "        d['agg_column2'] = d1[c[1]]\n",
    "    d['id_merge'] = d['agg_column1'] + '_' + d['agg_column2']\n",
    "    d['Level'] = level\n",
    "    dfs.append(d[['Level', 'agg_column1', 'agg_column2', 'd', 'sold', 'revenue', 'id_merge']])\n",
    "d = pd.concat(dfs)\n",
    "d.head(50)\n",
    "d.to_parquet('temp.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open('test.txt')\n",
    "# file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
