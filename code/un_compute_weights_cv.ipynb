{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.utils import _down_cast, data_preprocessing\n",
    "from utils import constants\n",
    "\n",
    "from utils.configure_logger import configure_logger\n",
    "configure_logger()\n",
    "from logging import getLogger\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_PATH = constants.DATA_BASE_PATH #'../data/m5-forecasting-accuracy/'\n",
    "DATA_BASE_PATH_UNCERTAINTY = constants.DATA_BASE_PATH_UNCERTAINTY #'../data/m5-forecasting-uncertainty/'\n",
    "SALES_EVALUATION = constants.SALES_EVALUATION #'sales_train_evaluation.csv'\n",
    "SALES_VALIDATION = constants.SALES_VALIDATION #'sales_train_validation.csv'\n",
    "CALENDAR = constants.CALENDAR #'calendar.csv'\n",
    "SAMPLE_SUBMISSION = constants.SAMPLE_SUBMISSION #'sample_submission.csv'\n",
    "SELL_PRICES = constants.SELL_PRICES #'sell_prices.csv'\n",
    "\n",
    "PRECOMPUTED_BASE_PATH = constants.PRECOMPUTED_BASE_PATH #'../data/uncertainty/features/'\n",
    "\n",
    "DAYS: int = constants.DAYS #28\n",
    "QUANTILES: int = constants.QUANTILES #[0.005, 0.025, 0.165, 0.25, 0.50, 0.75, 0.835, 0.975, 0.995]\n",
    "AGG_LEVEL_COLUMNS = constants.AGG_LEVEL_COLUMNS\n",
    "D_CV_START_LIST = constants.D_CROSS_VAL_START_LIST#[1802, 1830, 1858, 1886, 1914]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all data\n",
    "sales_validation: pd.DataFrame = _down_cast(pd.read_csv(DATA_BASE_PATH + SALES_VALIDATION))\n",
    "# sales_evaluation: pd.DataFrame = _down_cast(pd.read_csv(DATA_BASE_PATH + SALES_EVALUATION))\n",
    "calendar: pd.DataFrame = _down_cast(pd.read_csv(DATA_BASE_PATH + CALENDAR))\n",
    "sample_submission: pd.DataFrame = _down_cast(pd.read_csv(DATA_BASE_PATH + SAMPLE_SUBMISSION))\n",
    "sell_prices: pd.DataFrame = _down_cast(pd.read_csv(DATA_BASE_PATH + SELL_PRICES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, submission_idx = data_preprocessing(\n",
    "    sales_validation,\n",
    "    calendar,\n",
    "    sell_prices\n",
    ")\n",
    "df = df[(df.wm_yr_wk > df.release)]\n",
    "del sales_validation; del calendar; del sample_submission; del sell_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(df: pd.DataFrame, d_cv_start: int = 1914):\n",
    "    \"\"\" \n",
    "    weights: pd.DataFrame\n",
    "    columns = [Level, agg_column1, agg_column2, weight]\n",
    "    \"\"\"\n",
    "    weights_df: list = list()\n",
    "    df['revenue'] = df['sold'] * df['sell_price']\n",
    "    \n",
    "    d_cv_weights = [f'd_{i}' for i in range(d_cv_start-DAYS, d_cv_start)]\n",
    "    df = df[df['d'].isin(d_cv_weights)]\n",
    "    \n",
    "    for agg_level in AGG_LEVEL_COLUMNS:\n",
    "        logger.info(agg_level)\n",
    "        agg_columns = AGG_LEVEL_COLUMNS[agg_level]\n",
    "        if agg_level == 'Level1':          \n",
    "            weights = pd.Series([1])\n",
    "        else:\n",
    "            grouped_revenue = df.groupby(agg_columns)['revenue'].sum().reset_index(drop=False, )\n",
    "            weights = grouped_revenue['revenue'] / grouped_revenue['revenue'].sum()\n",
    "            \n",
    "        data = {\n",
    "            'Level_id': agg_level,\n",
    "            'Weight': weights\n",
    "        }\n",
    "        if agg_level == 'Level1':\n",
    "            data['Agg_Level_1'] = 'Total'\n",
    "            data['Agg_Level_2'] = 'X'\n",
    "        elif len(agg_columns) == 1:\n",
    "            data['Agg_Level_1'] = grouped_revenue[agg_columns[0]]\n",
    "            data['Agg_Level_2'] = 'X'\n",
    "        else:\n",
    "            data['Agg_Level_1'] = grouped_revenue[agg_columns[0]]\n",
    "            data['Agg_Level_2'] = grouped_revenue[agg_columns[1]]\n",
    "        \n",
    "        weights_df.append(pd.DataFrame(data))\n",
    "    return pd.concat(weights_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 19:34:46 - __main__ - INFO - d_cv_start: 1802\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level1\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level2\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level3\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level4\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level5\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level6\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level7\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level8\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level9\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level10\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level11\n",
      "2023-08-21 19:34:47 - __main__ - INFO - Level12\n",
      "2023-08-21 19:34:47 - __main__ - INFO - d_cv_start: 1830\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level1\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level2\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level3\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level4\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level5\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level6\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level7\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level8\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level9\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level10\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level11\n",
      "2023-08-21 19:34:48 - __main__ - INFO - Level12\n",
      "2023-08-21 19:34:48 - __main__ - INFO - d_cv_start: 1858\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level1\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level2\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level3\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level4\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level5\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level6\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level7\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level8\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level9\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level10\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level11\n",
      "2023-08-21 19:34:49 - __main__ - INFO - Level12\n",
      "2023-08-21 19:34:49 - __main__ - INFO - d_cv_start: 1886\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level1\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level2\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level3\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level4\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level5\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level6\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level7\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level8\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level9\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level10\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level11\n",
      "2023-08-21 19:34:50 - __main__ - INFO - Level12\n",
      "2023-08-21 19:34:50 - __main__ - INFO - d_cv_start: 1914\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level1\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level2\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level3\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level4\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level5\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level6\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level7\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level8\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level9\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level10\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level11\n",
      "2023-08-21 19:34:51 - __main__ - INFO - Level12\n"
     ]
    }
   ],
   "source": [
    "for D_CV_START in D_CV_START_LIST:\n",
    "    logger.info('d_cv_start: ' + str(D_CV_START))\n",
    "    \n",
    "    weights = compute_weights(df, D_CV_START)\n",
    "    weights.to_csv(f'../data/uncertainty/fold_{D_CV_START}/' + f'weights_validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate if weights per level sum up to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for D_CV_START in D_CV_START_LIST:\n",
    "    weights = pd.read_csv(f'../data/uncertainty/fold_{D_CV_START}/weights_validation.csv')\n",
    "    for id, weight_level in weights.groupby(['Level_id']):\n",
    "        \n",
    "        # rounding due to some decimal errors\n",
    "        assert round(weight_level['Weight'].sum(), 7) == 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
